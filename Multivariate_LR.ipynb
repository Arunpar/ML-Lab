{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Multivariate LR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arunpar/ML-Lab/blob/master/Multivariate_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkRJzpAZfUTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLinearRegression:\n",
        "    def __init__(self, weight1=0,weight2=0, bias=20, learning_rate=0.01,\n",
        "                 iterations=3000):\n",
        "        self.weight1 = weight1\n",
        "        self.weight2 = weight2\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, xfeature, zfeature):\n",
        "        predicted_set = []\n",
        "        for i in range(len(xfeature)):\n",
        "            predicted_value = self.weight2 * zfeature[i] + self.weight1 * xfeature[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, xfeature, yfeature, zfeature):\n",
        "        count = len(xfeature)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (yfeature[i] - ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, xfeature, yfeature, zfeature):\n",
        "        weight_deriv1 = 0\n",
        "        weight_deriv2 = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(xfeature)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv1 += -2 * xfeature[i] * (yfeature[i] -\n",
        "                                                ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                                 self.bias))\n",
        "            weight_deriv2 += -2 * zfeature[i] * (yfeature[i] -\n",
        "                                                ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                                 self.bias))\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (yfeature[i] - ( self.weight2 * zfeature[i] + self.weight1 * xfeature[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight1 -= (weight_deriv1 / count) * self.learning_rate\n",
        "        self.weight2 -= (weight_deriv2 / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, xfeature, yfeature, zfeature):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(xfeature, yfeature , zfeature)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(xfeature, yfeature, zfeature)\n",
        "            self.cost_trend.append(self.cost)\n",
        "            #if i % 10000 == 0:\n",
        "            print(\"Iteration: {}\\t Weight1: {}\\t Weight2: {}\\t Bias: {}\\t Cost: {}\".\n",
        "            format(i, self.weight1, self.weight2, self.bias, self.cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjoNDjuqXh7b",
        "colab_type": "text"
      },
      "source": [
        "It is noted that the learning rate when increased with high iterations the model could not work properly and give monotonous result. Hence the learning rate was reduced to 0.01 and iteration's value was made 2000 (high) so that we could get a perfect line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhPdTtHoEjN",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIhWZzM2fUTN",
        "colab_type": "code",
        "outputId": "793dc91e-f9eb-4330-9902-757507f98b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8],\n",
        "         'Subjects':[1,3,2,4,2,1,5,3,4,1,4,3,2,2,1,5,1,1,2,2,1,2,2,2,4], \n",
        "        'Scores':[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Subjects</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>4</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9.2</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.3</td>\n",
              "      <td>4</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7.7</td>\n",
              "      <td>4</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.3</td>\n",
              "      <td>2</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.9</td>\n",
              "      <td>5</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.5</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7.4</td>\n",
              "      <td>2</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.8</td>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3.8</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>6.9</td>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.8</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Hours  Subjects  Scores\n",
              "0     2.5         1      21\n",
              "1     5.1         3      47\n",
              "2     3.2         2      27\n",
              "3     8.5         4      75\n",
              "4     3.5         2      30\n",
              "5     1.5         1      20\n",
              "6     9.2         5      88\n",
              "7     5.5         3      60\n",
              "8     8.3         4      81\n",
              "9     2.7         1      25\n",
              "10    7.7         4      85\n",
              "11    5.9         3      62\n",
              "12    4.5         2      41\n",
              "13    3.3         2      42\n",
              "14    1.1         1      17\n",
              "15    8.9         5      95\n",
              "16    2.5         1      30\n",
              "17    1.9         1      24\n",
              "18    6.1         2      67\n",
              "19    7.4         2      69\n",
              "20    2.7         1      30\n",
              "21    4.8         2      54\n",
              "22    3.8         2      35\n",
              "23    6.9         2      76\n",
              "24    7.8         4      86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6qrJrPfUTY",
        "colab_type": "code",
        "outputId": "7415c42a-0e3c-48ea-aab4-b1512b5227c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, : 1].values\n",
        "z = studentscores.iloc[:, 1:2].values\n",
        "y = studentscores.iloc[:, 2].values\n",
        "print(X)\n",
        "print(y)\n",
        "print(z)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.5]\n",
            " [5.1]\n",
            " [3.2]\n",
            " [8.5]\n",
            " [3.5]\n",
            " [1.5]\n",
            " [9.2]\n",
            " [5.5]\n",
            " [8.3]\n",
            " [2.7]\n",
            " [7.7]\n",
            " [5.9]\n",
            " [4.5]\n",
            " [3.3]\n",
            " [1.1]\n",
            " [8.9]\n",
            " [2.5]\n",
            " [1.9]\n",
            " [6.1]\n",
            " [7.4]\n",
            " [2.7]\n",
            " [4.8]\n",
            " [3.8]\n",
            " [6.9]\n",
            " [7.8]]\n",
            "[21 47 27 75 30 20 88 60 81 25 85 62 41 42 17 95 30 24 67 69 30 54 35 76\n",
            " 86]\n",
            "[[1]\n",
            " [3]\n",
            " [2]\n",
            " [4]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [3]\n",
            " [4]\n",
            " [1]\n",
            " [4]\n",
            " [3]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [5]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZSgOgXhQO7n",
        "colab_type": "code",
        "outputId": "6b1df2af-d760-4f7c-c4e8-a87442b72b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.5]\n",
            " [5.1]\n",
            " [3.2]\n",
            " [8.5]\n",
            " [3.5]\n",
            " [1.5]\n",
            " [9.2]\n",
            " [5.5]\n",
            " [8.3]\n",
            " [2.7]\n",
            " [7.7]\n",
            " [5.9]\n",
            " [4.5]\n",
            " [3.3]\n",
            " [1.1]\n",
            " [8.9]\n",
            " [2.5]\n",
            " [1.9]\n",
            " [6.1]\n",
            " [7.4]\n",
            " [2.7]\n",
            " [4.8]\n",
            " [3.8]\n",
            " [6.9]\n",
            " [7.8]]\n",
            "[21 47 27 75 30 20 88 60 81 25 85 62 41 42 17 95 30 24 67 69 30 54 35 76\n",
            " 86]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxSazDuOfUTg",
        "colab_type": "code",
        "outputId": "1f6c0a85-7a8c-4b74-fd97-b8006e8dc54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test , z_train, z_test = train_test_split(X, y, z, test_size=1/3, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train, z_train)\n",
        "print('Weight2: ' + str(regressor.weight2) + 'Weight1: ' + str(regressor.weight1) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test,z_test)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\t Weight1: [4.771]\t Weight2: [2.40125]\t Bias: [20.6725]\t Cost: 59.40978903187499\n",
            "Iteration: 1\t Weight1: [5.39200407]\t Weight2: [2.71469663]\t Bias: [20.70214388]\t Cost: 45.63538162395922\n",
            "Iteration: 2\t Weight1: [5.47863673]\t Weight2: [2.75927277]\t Bias: [20.649223]\t Cost: 45.19462457178419\n",
            "Iteration: 3\t Weight1: [5.49645131]\t Weight2: [2.76918724]\t Bias: [20.58588054]\t Cost: 44.97650215521779\n",
            "Iteration: 4\t Weight1: [5.50539319]\t Weight2: [2.77459734]\t Bias: [20.52140499]\t Cost: 44.76362808592312\n",
            "Iteration: 5\t Weight1: [5.51318101]\t Weight2: [2.7793864]\t Bias: [20.45699154]\t Cost: 44.552386483960625\n",
            "Iteration: 6\t Weight1: [5.52080867]\t Weight2: [2.78405467]\t Bias: [20.39279333]\t Cost: 44.34270577169122\n",
            "Iteration: 7\t Weight1: [5.52840413]\t Weight2: [2.78866678]\t Bias: [20.32882928]\t Cost: 44.13457322301691\n",
            "Iteration: 8\t Weight1: [5.53598389]\t Weight2: [2.7932313]\t Bias: [20.26510105]\t Cost: 43.92797717556202\n",
            "Iteration: 9\t Weight1: [5.54355007]\t Weight2: [2.79774953]\t Bias: [20.20160809]\t Cost: 43.72290607190112\n",
            "Iteration: 10\t Weight1: [5.55110296]\t Weight2: [2.80222187]\t Bias: [20.13834954]\t Cost: 43.519348442990726\n",
            "Iteration: 11\t Weight1: [5.5586426]\t Weight2: [2.80664859]\t Bias: [20.07532454]\t Cost: 43.31729290722784\n",
            "Iteration: 12\t Weight1: [5.56616901]\t Weight2: [2.81102995]\t Bias: [20.01253221]\t Cost: 43.116728169772614\n",
            "Iteration: 13\t Weight1: [5.5736822]\t Weight2: [2.81536619]\t Bias: [19.94997166]\t Cost: 42.917643021880394\n",
            "Iteration: 14\t Weight1: [5.58118217]\t Weight2: [2.81965757]\t Bias: [19.88764203]\t Cost: 42.72002634023925\n",
            "Iteration: 15\t Weight1: [5.58866893]\t Weight2: [2.82390434]\t Bias: [19.82554245]\t Cost: 42.5238670863125\n",
            "Iteration: 16\t Weight1: [5.5961425]\t Weight2: [2.82810675]\t Bias: [19.76367205]\t Cost: 42.32915430568635\n",
            "Iteration: 17\t Weight1: [5.60360288]\t Weight2: [2.83226503]\t Bias: [19.70202997]\t Cost: 42.135877127422546\n",
            "Iteration: 18\t Weight1: [5.61105009]\t Weight2: [2.83637944]\t Bias: [19.64061535]\t Cost: 41.9440247634161\n",
            "Iteration: 19\t Weight1: [5.61848413]\t Weight2: [2.84045022]\t Bias: [19.57942734]\t Cost: 41.753586507758\n",
            "Iteration: 20\t Weight1: [5.62590501]\t Weight2: [2.84447762]\t Bias: [19.51846508]\t Cost: 41.564551736102786\n",
            "Iteration: 21\t Weight1: [5.63331275]\t Weight2: [2.84846186]\t Bias: [19.45772773]\t Cost: 41.376909905041146\n",
            "Iteration: 22\t Weight1: [5.64070735]\t Weight2: [2.85240321]\t Bias: [19.39721443]\t Cost: 41.19065055147712\n",
            "Iteration: 23\t Weight1: [5.64808882]\t Weight2: [2.85630189]\t Bias: [19.33692435]\t Cost: 41.005763292010535\n",
            "Iteration: 24\t Weight1: [5.65545717]\t Weight2: [2.86015814]\t Bias: [19.27685664]\t Cost: 40.82223782232382\n",
            "Iteration: 25\t Weight1: [5.66281242]\t Weight2: [2.86397221]\t Bias: [19.21701047]\t Cost: 40.64006391657378\n",
            "Iteration: 26\t Weight1: [5.67015457]\t Weight2: [2.86774432]\t Bias: [19.15738501]\t Cost: 40.45923142678805\n",
            "Iteration: 27\t Weight1: [5.67748364]\t Weight2: [2.87147472]\t Bias: [19.09797943]\t Cost: 40.2797302822662\n",
            "Iteration: 28\t Weight1: [5.68479963]\t Weight2: [2.87516363]\t Bias: [19.03879289]\t Cost: 40.10155048898544\n",
            "Iteration: 29\t Weight1: [5.69210255]\t Weight2: [2.8788113]\t Bias: [18.97982458]\t Cost: 39.92468212901116\n",
            "Iteration: 30\t Weight1: [5.69939242]\t Weight2: [2.88241794]\t Bias: [18.92107368]\t Cost: 39.74911535991153\n",
            "Iteration: 31\t Weight1: [5.70666925]\t Weight2: [2.8859838]\t Bias: [18.86253936]\t Cost: 39.574840414177274\n",
            "Iteration: 32\t Weight1: [5.71393304]\t Weight2: [2.8895091]\t Bias: [18.80422082]\t Cost: 39.40184759864543\n",
            "Iteration: 33\t Weight1: [5.72118381]\t Weight2: [2.89299408]\t Bias: [18.74611724]\t Cost: 39.23012729392776\n",
            "Iteration: 34\t Weight1: [5.72842157]\t Weight2: [2.89643895]\t Bias: [18.68822781]\t Cost: 39.05966995384364\n",
            "Iteration: 35\t Weight1: [5.73564632]\t Weight2: [2.89984394]\t Bias: [18.63055174]\t Cost: 38.890466104857275\n",
            "Iteration: 36\t Weight1: [5.74285809]\t Weight2: [2.90320929]\t Bias: [18.57308821]\t Cost: 38.72250634551926\n",
            "Iteration: 37\t Weight1: [5.75005687]\t Weight2: [2.90653521]\t Bias: [18.51583643]\t Cost: 38.55578134591241\n",
            "Iteration: 38\t Weight1: [5.75724269]\t Weight2: [2.90982193]\t Bias: [18.4587956]\t Cost: 38.39028184710208\n",
            "Iteration: 39\t Weight1: [5.76441555]\t Weight2: [2.91306966]\t Bias: [18.40196493]\t Cost: 38.22599866059051\n",
            "Iteration: 40\t Weight1: [5.77157546]\t Weight2: [2.91627864]\t Bias: [18.34534364]\t Cost: 38.06292266777561\n",
            "Iteration: 41\t Weight1: [5.77872244]\t Weight2: [2.91944908]\t Bias: [18.28893092]\t Cost: 37.90104481941357\n",
            "Iteration: 42\t Weight1: [5.7858565]\t Weight2: [2.92258121]\t Bias: [18.23272601]\t Cost: 37.74035613508616\n",
            "Iteration: 43\t Weight1: [5.79297764]\t Weight2: [2.92567523]\t Bias: [18.17672812]\t Cost: 37.58084770267172\n",
            "Iteration: 44\t Weight1: [5.80008588]\t Weight2: [2.92873136]\t Bias: [18.12093646]\t Cost: 37.42251067782039\n",
            "Iteration: 45\t Weight1: [5.80718123]\t Weight2: [2.93174983]\t Bias: [18.06535028]\t Cost: 37.26533628343347\n",
            "Iteration: 46\t Weight1: [5.8142637]\t Weight2: [2.93473084]\t Bias: [18.00996879]\t Cost: 37.10931580914662\n",
            "Iteration: 47\t Weight1: [5.82133331]\t Weight2: [2.93767461]\t Bias: [17.95479122]\t Cost: 36.95444061081736\n",
            "Iteration: 48\t Weight1: [5.82839006]\t Weight2: [2.94058136]\t Bias: [17.89981682]\t Cost: 36.80070211001618\n",
            "Iteration: 49\t Weight1: [5.83543396]\t Weight2: [2.94345129]\t Bias: [17.84504481]\t Cost: 36.64809179352187\n",
            "Iteration: 50\t Weight1: [5.84246504]\t Weight2: [2.94628462]\t Bias: [17.79047444]\t Cost: 36.496601212820664\n",
            "Iteration: 51\t Weight1: [5.84948329]\t Weight2: [2.94908155]\t Bias: [17.73610494]\t Cost: 36.346221983609105\n",
            "Iteration: 52\t Weight1: [5.85648874]\t Weight2: [2.9518423]\t Bias: [17.68193558]\t Cost: 36.19694578530101\n",
            "Iteration: 53\t Weight1: [5.86348139]\t Weight2: [2.95456707]\t Bias: [17.62796558]\t Cost: 36.0487643605382\n",
            "Iteration: 54\t Weight1: [5.87046126]\t Weight2: [2.95725607]\t Bias: [17.57419421]\t Cost: 35.9016695147047\n",
            "Iteration: 55\t Weight1: [5.87742835]\t Weight2: [2.9599095]\t Bias: [17.52062072]\t Cost: 35.755653115445256\n",
            "Iteration: 56\t Weight1: [5.88438269]\t Weight2: [2.96252757]\t Bias: [17.46724437]\t Cost: 35.61070709218705\n",
            "Iteration: 57\t Weight1: [5.89132427]\t Weight2: [2.96511049]\t Bias: [17.41406441]\t Cost: 35.46682343566535\n",
            "Iteration: 58\t Weight1: [5.89825312]\t Weight2: [2.96765846]\t Bias: [17.36108011]\t Cost: 35.32399419745291\n",
            "Iteration: 59\t Weight1: [5.90516924]\t Weight2: [2.97017168]\t Bias: [17.30829073]\t Cost: 35.182211489492886\n",
            "Iteration: 60\t Weight1: [5.91207266]\t Weight2: [2.97265034]\t Bias: [17.25569555]\t Cost: 35.041467483635245\n",
            "Iteration: 61\t Weight1: [5.91896337]\t Weight2: [2.97509466]\t Bias: [17.20329383]\t Cost: 34.90175441117711\n",
            "Iteration: 62\t Weight1: [5.9258414]\t Weight2: [2.97750482]\t Bias: [17.15108485]\t Cost: 34.76306456240631\n",
            "Iteration: 63\t Weight1: [5.93270675]\t Weight2: [2.97988104]\t Bias: [17.09906788]\t Cost: 34.62539028614862\n",
            "Iteration: 64\t Weight1: [5.93955944]\t Weight2: [2.9822235]\t Bias: [17.04724221]\t Cost: 34.488723989318615\n",
            "Iteration: 65\t Weight1: [5.94639948]\t Weight2: [2.9845324]\t Bias: [16.99560711]\t Cost: 34.35305813647364\n",
            "Iteration: 66\t Weight1: [5.95322688]\t Weight2: [2.98680793]\t Bias: [16.94416187]\t Cost: 34.21838524937158\n",
            "Iteration: 67\t Weight1: [5.96004165]\t Weight2: [2.9890503]\t Bias: [16.89290578]\t Cost: 34.084697906532014\n",
            "Iteration: 68\t Weight1: [5.96684382]\t Weight2: [2.99125969]\t Bias: [16.84183813]\t Cost: 33.95198874280049\n",
            "Iteration: 69\t Weight1: [5.97363339]\t Weight2: [2.9934363]\t Bias: [16.79095821]\t Cost: 33.820250448916454\n",
            "Iteration: 70\t Weight1: [5.98041036]\t Weight2: [2.99558032]\t Bias: [16.74026532]\t Cost: 33.68947577108445\n",
            "Iteration: 71\t Weight1: [5.98717477]\t Weight2: [2.99769194]\t Bias: [16.68975875]\t Cost: 33.55965751054842\n",
            "Iteration: 72\t Weight1: [5.99392661]\t Weight2: [2.99977135]\t Bias: [16.63943781]\t Cost: 33.43078852316975\n",
            "Iteration: 73\t Weight1: [6.00066591]\t Weight2: [3.00181873]\t Bias: [16.5893018]\t Cost: 33.30286171900809\n",
            "Iteration: 74\t Weight1: [6.00739267]\t Weight2: [3.00383429]\t Bias: [16.53935003]\t Cost: 33.17587006190566\n",
            "Iteration: 75\t Weight1: [6.01410691]\t Weight2: [3.00581819]\t Bias: [16.4895818]\t Cost: 33.04980656907484\n",
            "Iteration: 76\t Weight1: [6.02080863]\t Weight2: [3.00777064]\t Bias: [16.43999643]\t Cost: 32.92466431068874\n",
            "Iteration: 77\t Weight1: [6.02749786]\t Weight2: [3.00969181]\t Bias: [16.39059324]\t Cost: 32.800436409475076\n",
            "Iteration: 78\t Weight1: [6.03417461]\t Weight2: [3.01158189]\t Bias: [16.34137153]\t Cost: 32.677116040313166\n",
            "Iteration: 79\t Weight1: [6.04083889]\t Weight2: [3.01344107]\t Bias: [16.29233062]\t Cost: 32.55469642983395\n",
            "Iteration: 80\t Weight1: [6.04749071]\t Weight2: [3.01526952]\t Bias: [16.24346985]\t Cost: 32.433170856023324\n",
            "Iteration: 81\t Weight1: [6.05413009]\t Weight2: [3.01706743]\t Bias: [16.19478854]\t Cost: 32.31253264782816\n",
            "Iteration: 82\t Weight1: [6.06075703]\t Weight2: [3.01883497]\t Bias: [16.146286]\t Cost: 32.1927751847658\n",
            "Iteration: 83\t Weight1: [6.06737156]\t Weight2: [3.02057234]\t Bias: [16.09796158]\t Cost: 32.07389189653631\n",
            "Iteration: 84\t Weight1: [6.07397369]\t Weight2: [3.0222797]\t Bias: [16.0498146]\t Cost: 31.95587626263772\n",
            "Iteration: 85\t Weight1: [6.08056342]\t Weight2: [3.02395724]\t Bias: [16.0018444]\t Cost: 31.838721811984396\n",
            "Iteration: 86\t Weight1: [6.08714078]\t Weight2: [3.02560513]\t Bias: [15.95405032]\t Cost: 31.722422122528176\n",
            "Iteration: 87\t Weight1: [6.09370577]\t Weight2: [3.02722355]\t Bias: [15.90643169]\t Cost: 31.60697082088261\n",
            "Iteration: 88\t Weight1: [6.10025841]\t Weight2: [3.02881268]\t Bias: [15.85898786]\t Cost: 31.492361581949943\n",
            "Iteration: 89\t Weight1: [6.10679872]\t Weight2: [3.03037269]\t Bias: [15.81171817]\t Cost: 31.3785881285511\n",
            "Iteration: 90\t Weight1: [6.1133267]\t Weight2: [3.03190375]\t Bias: [15.76462198]\t Cost: 31.265644231058484\n",
            "Iteration: 91\t Weight1: [6.11984237]\t Weight2: [3.03340605]\t Bias: [15.71769863]\t Cost: 31.15352370703158\n",
            "Iteration: 92\t Weight1: [6.12634575]\t Weight2: [3.03487974]\t Bias: [15.67094747]\t Cost: 31.04222042085542\n",
            "Iteration: 93\t Weight1: [6.13283684]\t Weight2: [3.036325]\t Bias: [15.62436785]\t Cost: 30.93172828338181\n",
            "Iteration: 94\t Weight1: [6.13931567]\t Weight2: [3.03774201]\t Bias: [15.57795915]\t Cost: 30.82204125157337\n",
            "Iteration: 95\t Weight1: [6.14578224]\t Weight2: [3.03913093]\t Bias: [15.53172071]\t Cost: 30.713153328150252\n",
            "Iteration: 96\t Weight1: [6.15223657]\t Weight2: [3.04049193]\t Bias: [15.48565189]\t Cost: 30.605058561239684\n",
            "Iteration: 97\t Weight1: [6.15867867]\t Weight2: [3.04182519]\t Bias: [15.43975207]\t Cost: 30.497751044028064\n",
            "Iteration: 98\t Weight1: [6.16510856]\t Weight2: [3.04313086]\t Bias: [15.39402061]\t Cost: 30.391224914415993\n",
            "Iteration: 99\t Weight1: [6.17152624]\t Weight2: [3.04440911]\t Bias: [15.34845687]\t Cost: 30.285474354675678\n",
            "Iteration: 100\t Weight1: [6.17793175]\t Weight2: [3.04566011]\t Bias: [15.30306024]\t Cost: 30.18049359111117\n",
            "Iteration: 101\t Weight1: [6.18432508]\t Weight2: [3.04688403]\t Bias: [15.25783008]\t Cost: 30.076276893721253\n",
            "Iteration: 102\t Weight1: [6.19070625]\t Weight2: [3.04808103]\t Bias: [15.21276577]\t Cost: 29.972818575864714\n",
            "Iteration: 103\t Weight1: [6.19707528]\t Weight2: [3.04925127]\t Bias: [15.16786669]\t Cost: 29.870112993928476\n",
            "Iteration: 104\t Weight1: [6.20343218]\t Weight2: [3.05039492]\t Bias: [15.12313222]\t Cost: 29.768154546998066\n",
            "Iteration: 105\t Weight1: [6.20977696]\t Weight2: [3.05151213]\t Bias: [15.07856175]\t Cost: 29.666937676530775\n",
            "Iteration: 106\t Weight1: [6.21610964]\t Weight2: [3.05260307]\t Bias: [15.03415466]\t Cost: 29.566456866031288\n",
            "Iteration: 107\t Weight1: [6.22243024]\t Weight2: [3.0536679]\t Bias: [14.98991034]\t Cost: 29.466706640729804\n",
            "Iteration: 108\t Weight1: [6.22873876]\t Weight2: [3.05470678]\t Bias: [14.94582818]\t Cost: 29.367681567262622\n",
            "Iteration: 109\t Weight1: [6.23503522]\t Weight2: [3.05571987]\t Bias: [14.90190757]\t Cost: 29.269376253355276\n",
            "Iteration: 110\t Weight1: [6.24131964]\t Weight2: [3.05670732]\t Bias: [14.85814791]\t Cost: 29.17178534750801\n",
            "Iteration: 111\t Weight1: [6.24759203]\t Weight2: [3.05766929]\t Bias: [14.81454859]\t Cost: 29.074903538683824\n",
            "Iteration: 112\t Weight1: [6.2538524]\t Weight2: [3.05860594]\t Bias: [14.77110902]\t Cost: 28.97872555599868\n",
            "Iteration: 113\t Weight1: [6.26010077]\t Weight2: [3.05951743]\t Bias: [14.7278286]\t Cost: 28.883246168414445\n",
            "Iteration: 114\t Weight1: [6.26633715]\t Weight2: [3.0604039]\t Bias: [14.68470673]\t Cost: 28.788460184433895\n",
            "Iteration: 115\t Weight1: [6.27256156]\t Weight2: [3.06126552]\t Bias: [14.64174283]\t Cost: 28.694362451798153\n",
            "Iteration: 116\t Weight1: [6.27877401]\t Weight2: [3.06210243]\t Bias: [14.59893629]\t Cost: 28.60094785718665\n",
            "Iteration: 117\t Weight1: [6.28497451]\t Weight2: [3.06291479]\t Bias: [14.55628652]\t Cost: 28.508211325919135\n",
            "Iteration: 118\t Weight1: [6.29116309]\t Weight2: [3.06370276]\t Bias: [14.51379296]\t Cost: 28.41614782166009\n",
            "Iteration: 119\t Weight1: [6.29733975]\t Weight2: [3.06446647]\t Bias: [14.471455]\t Cost: 28.324752346125518\n",
            "Iteration: 120\t Weight1: [6.30350451]\t Weight2: [3.06520609]\t Bias: [14.42927206]\t Cost: 28.23401993879187\n",
            "Iteration: 121\t Weight1: [6.30965738]\t Weight2: [3.06592176]\t Bias: [14.38724358]\t Cost: 28.14394567660724\n",
            "Iteration: 122\t Weight1: [6.31579838]\t Weight2: [3.06661364]\t Bias: [14.34536896]\t Cost: 28.054524673704794\n",
            "Iteration: 123\t Weight1: [6.32192753]\t Weight2: [3.06728186]\t Bias: [14.30364763]\t Cost: 27.965752081118495\n",
            "Iteration: 124\t Weight1: [6.32804483]\t Weight2: [3.06792658]\t Bias: [14.26207903]\t Cost: 27.877623086500844\n",
            "Iteration: 125\t Weight1: [6.3341503]\t Weight2: [3.06854794]\t Bias: [14.22066258]\t Cost: 27.79013291384301\n",
            "Iteration: 126\t Weight1: [6.34024396]\t Weight2: [3.06914609]\t Bias: [14.1793977]\t Cost: 27.70327682319691\n",
            "Iteration: 127\t Weight1: [6.34632583]\t Weight2: [3.06972118]\t Bias: [14.13828384]\t Cost: 27.617050110399592\n",
            "Iteration: 128\t Weight1: [6.35239591]\t Weight2: [3.07027335]\t Bias: [14.09732042]\t Cost: 27.53144810679966\n",
            "Iteration: 129\t Weight1: [6.35845422]\t Weight2: [3.07080274]\t Bias: [14.0565069]\t Cost: 27.446466178985823\n",
            "Iteration: 130\t Weight1: [6.36450077]\t Weight2: [3.0713095]\t Bias: [14.0158427]\t Cost: 27.362099728517595\n",
            "Iteration: 131\t Weight1: [6.37053559]\t Weight2: [3.07179377]\t Bias: [13.97532726]\t Cost: 27.278344191657922\n",
            "Iteration: 132\t Weight1: [6.37655868]\t Weight2: [3.07225569]\t Bias: [13.93496004]\t Cost: 27.195195039108103\n",
            "Iteration: 133\t Weight1: [6.38257007]\t Weight2: [3.0726954]\t Bias: [13.89474047]\t Cost: 27.112647775744506\n",
            "Iteration: 134\t Weight1: [6.38856976]\t Weight2: [3.07311305]\t Bias: [13.85466801]\t Cost: 27.030697940357456\n",
            "Iteration: 135\t Weight1: [6.39455776]\t Weight2: [3.07350877]\t Bias: [13.81474211]\t Cost: 26.949341105392218\n",
            "Iteration: 136\t Weight1: [6.40053411]\t Weight2: [3.0738827]\t Bias: [13.77496221]\t Cost: 26.86857287669166\n",
            "Iteration: 137\t Weight1: [6.4064988]\t Weight2: [3.07423498]\t Bias: [13.73532778]\t Cost: 26.788388893241283\n",
            "Iteration: 138\t Weight1: [6.41245186]\t Weight2: [3.07456575]\t Bias: [13.69583826]\t Cost: 26.708784826916013\n",
            "Iteration: 139\t Weight1: [6.4183933]\t Weight2: [3.07487514]\t Bias: [13.65649312]\t Cost: 26.629756382228937\n",
            "Iteration: 140\t Weight1: [6.42432313]\t Weight2: [3.07516329]\t Bias: [13.61729182]\t Cost: 26.55129929608194\n",
            "Iteration: 141\t Weight1: [6.43024138]\t Weight2: [3.07543034]\t Bias: [13.57823382]\t Cost: 26.47340933751847\n",
            "Iteration: 142\t Weight1: [6.43614805]\t Weight2: [3.07567643]\t Bias: [13.53931859]\t Cost: 26.39608230747808\n",
            "Iteration: 143\t Weight1: [6.44204316]\t Weight2: [3.07590168]\t Bias: [13.50054559]\t Cost: 26.31931403855269\n",
            "Iteration: 144\t Weight1: [6.44792672]\t Weight2: [3.07610622]\t Bias: [13.46191428]\t Cost: 26.243100394745035\n",
            "Iteration: 145\t Weight1: [6.45379875]\t Weight2: [3.07629021]\t Bias: [13.42342415]\t Cost: 26.16743727122878\n",
            "Iteration: 146\t Weight1: [6.45965927]\t Weight2: [3.07645375]\t Bias: [13.38507466]\t Cost: 26.09232059411059\n",
            "Iteration: 147\t Weight1: [6.4655083]\t Weight2: [3.076597]\t Bias: [13.3468653]\t Cost: 26.017746320193858\n",
            "Iteration: 148\t Weight1: [6.47134583]\t Weight2: [3.07672007]\t Bias: [13.30879552]\t Cost: 25.943710436744503\n",
            "Iteration: 149\t Weight1: [6.4771719]\t Weight2: [3.0768231]\t Bias: [13.27086482]\t Cost: 25.87020896125838\n",
            "Iteration: 150\t Weight1: [6.48298651]\t Weight2: [3.07690622]\t Bias: [13.23307268]\t Cost: 25.797237941230545\n",
            "Iteration: 151\t Weight1: [6.48878969]\t Weight2: [3.07696955]\t Bias: [13.19541857]\t Cost: 25.724793453926274\n",
            "Iteration: 152\t Weight1: [6.49458144]\t Weight2: [3.07701323]\t Bias: [13.15790199]\t Cost: 25.652871606153962\n",
            "Iteration: 153\t Weight1: [6.50036179]\t Weight2: [3.07703739]\t Bias: [13.12052241]\t Cost: 25.58146853403956\n",
            "Iteration: 154\t Weight1: [6.50613074]\t Weight2: [3.07704214]\t Bias: [13.08327933]\t Cost: 25.51058040280295\n",
            "Iteration: 155\t Weight1: [6.51188831]\t Weight2: [3.07702762]\t Bias: [13.04617224]\t Cost: 25.440203406535897\n",
            "Iteration: 156\t Weight1: [6.51763452]\t Weight2: [3.07699396]\t Bias: [13.00920063]\t Cost: 25.370333767981837\n",
            "Iteration: 157\t Weight1: [6.52336939]\t Weight2: [3.07694127]\t Bias: [12.97236399]\t Cost: 25.300967738317244\n",
            "Iteration: 158\t Weight1: [6.52909292]\t Weight2: [3.07686969]\t Bias: [12.93566182]\t Cost: 25.232101596934804\n",
            "Iteration: 159\t Weight1: [6.53480514]\t Weight2: [3.07677933]\t Bias: [12.89909362]\t Cost: 25.163731651228055\n",
            "Iteration: 160\t Weight1: [6.54050605]\t Weight2: [3.07667033]\t Bias: [12.86265889]\t Cost: 25.095854236377946\n",
            "Iteration: 161\t Weight1: [6.54619568]\t Weight2: [3.07654279]\t Bias: [12.82635714]\t Cost: 25.028465715140886\n",
            "Iteration: 162\t Weight1: [6.55187405]\t Weight2: [3.07639686]\t Bias: [12.79018785]\t Cost: 24.961562477638417\n",
            "Iteration: 163\t Weight1: [6.55754115]\t Weight2: [3.07623264]\t Bias: [12.75415055]\t Cost: 24.895140941148533\n",
            "Iteration: 164\t Weight1: [6.56319702]\t Weight2: [3.07605026]\t Bias: [12.71824473]\t Cost: 24.829197549898662\n",
            "Iteration: 165\t Weight1: [6.56884166]\t Weight2: [3.07584983]\t Bias: [12.68246991]\t Cost: 24.763728774860162\n",
            "Iteration: 166\t Weight1: [6.5744751]\t Weight2: [3.07563149]\t Bias: [12.6468256]\t Cost: 24.698731113544394\n",
            "Iteration: 167\t Weight1: [6.58009734]\t Weight2: [3.07539534]\t Bias: [12.61131132]\t Cost: 24.63420108980048\n",
            "Iteration: 168\t Weight1: [6.5857084]\t Weight2: [3.07514151]\t Bias: [12.57592656]\t Cost: 24.570135253614477\n",
            "Iteration: 169\t Weight1: [6.59130831]\t Weight2: [3.07487011]\t Bias: [12.54067087]\t Cost: 24.506530180910143\n",
            "Iteration: 170\t Weight1: [6.59689706]\t Weight2: [3.07458127]\t Bias: [12.50554374]\t Cost: 24.44338247335135\n",
            "Iteration: 171\t Weight1: [6.60247469]\t Weight2: [3.07427509]\t Bias: [12.47054471]\t Cost: 24.380688758145727\n",
            "Iteration: 172\t Weight1: [6.6080412]\t Weight2: [3.0739517]\t Bias: [12.43567329]\t Cost: 24.318445687850218\n",
            "Iteration: 173\t Weight1: [6.61359661]\t Weight2: [3.07361121]\t Bias: [12.40092902]\t Cost: 24.25664994017783\n",
            "Iteration: 174\t Weight1: [6.61914094]\t Weight2: [3.07325373]\t Bias: [12.36631141]\t Cost: 24.195298217805863\n",
            "Iteration: 175\t Weight1: [6.6246742]\t Weight2: [3.07287939]\t Bias: [12.33181999]\t Cost: 24.13438724818588\n",
            "Iteration: 176\t Weight1: [6.6301964]\t Weight2: [3.07248829]\t Bias: [12.29745429]\t Cost: 24.073913783354875\n",
            "Iteration: 177\t Weight1: [6.63570757]\t Weight2: [3.07208054]\t Bias: [12.26321385]\t Cost: 24.013874599748036\n",
            "Iteration: 178\t Weight1: [6.64120772]\t Weight2: [3.07165627]\t Bias: [12.2290982]\t Cost: 23.954266498012792\n",
            "Iteration: 179\t Weight1: [6.64669686]\t Weight2: [3.07121557]\t Bias: [12.19510687]\t Cost: 23.895086302824613\n",
            "Iteration: 180\t Weight1: [6.65217501]\t Weight2: [3.07075858]\t Bias: [12.16123939]\t Cost: 23.836330862703768\n",
            "Iteration: 181\t Weight1: [6.65764218]\t Weight2: [3.07028538]\t Bias: [12.12749532]\t Cost: 23.777997049833942\n",
            "Iteration: 182\t Weight1: [6.6630984]\t Weight2: [3.0697961]\t Bias: [12.09387418]\t Cost: 23.720081759881918\n",
            "Iteration: 183\t Weight1: [6.66854367]\t Weight2: [3.06929085]\t Bias: [12.06037552]\t Cost: 23.662581911818798\n",
            "Iteration: 184\t Weight1: [6.67397802]\t Weight2: [3.06876973]\t Bias: [12.02699888]\t Cost: 23.605494447742664\n",
            "Iteration: 185\t Weight1: [6.67940145]\t Weight2: [3.06823286]\t Bias: [11.99374381]\t Cost: 23.548816332702383\n",
            "Iteration: 186\t Weight1: [6.68481399]\t Weight2: [3.06768034]\t Bias: [11.96060985]\t Cost: 23.492544554522926\n",
            "Iteration: 187\t Weight1: [6.69021564]\t Weight2: [3.06711228]\t Bias: [11.92759656]\t Cost: 23.43667612363212\n",
            "Iteration: 188\t Weight1: [6.69560643]\t Weight2: [3.06652878]\t Bias: [11.89470349]\t Cost: 23.3812080728884\n",
            "Iteration: 189\t Weight1: [6.70098637]\t Weight2: [3.06592996]\t Bias: [11.86193018]\t Cost: 23.326137457410336\n",
            "Iteration: 190\t Weight1: [6.70635548]\t Weight2: [3.06531592]\t Bias: [11.82927619]\t Cost: 23.271461354406977\n",
            "Iteration: 191\t Weight1: [6.71171377]\t Weight2: [3.06468677]\t Bias: [11.79674108]\t Cost: 23.21717686301006\n",
            "Iteration: 192\t Weight1: [6.71706126]\t Weight2: [3.0640426]\t Bias: [11.7643244]\t Cost: 23.16328110410685\n",
            "Iteration: 193\t Weight1: [6.72239796]\t Weight2: [3.06338353]\t Bias: [11.73202571]\t Cost: 23.109771220174927\n",
            "Iteration: 194\t Weight1: [6.72772389]\t Weight2: [3.06270967]\t Bias: [11.69984458]\t Cost: 23.056644375117756\n",
            "Iteration: 195\t Weight1: [6.73303906]\t Weight2: [3.0620211]\t Bias: [11.66778056]\t Cost: 23.003897754101718\n",
            "Iteration: 196\t Weight1: [6.7383435]\t Weight2: [3.06131794]\t Bias: [11.63583322]\t Cost: 22.9515285633945\n",
            "Iteration: 197\t Weight1: [6.74363721]\t Weight2: [3.06060028]\t Bias: [11.60400212]\t Cost: 22.899534030204382\n",
            "Iteration: 198\t Weight1: [6.74892022]\t Weight2: [3.05986824]\t Bias: [11.57228684]\t Cost: 22.84791140252121\n",
            "Iteration: 199\t Weight1: [6.75419253]\t Weight2: [3.05912191]\t Bias: [11.54068694]\t Cost: 22.796657948958156\n",
            "Iteration: 200\t Weight1: [6.75945417]\t Weight2: [3.05836139]\t Bias: [11.50920199]\t Cost: 22.74577095859507\n",
            "Iteration: 201\t Weight1: [6.76470515]\t Weight2: [3.05758679]\t Bias: [11.47783156]\t Cost: 22.6952477408227\n",
            "Iteration: 202\t Weight1: [6.76994548]\t Weight2: [3.05679819]\t Bias: [11.44657523]\t Cost: 22.64508562518841\n",
            "Iteration: 203\t Weight1: [6.77517519]\t Weight2: [3.05599571]\t Bias: [11.41543257]\t Cost: 22.595281961242854\n",
            "Iteration: 204\t Weight1: [6.78039428]\t Weight2: [3.05517944]\t Bias: [11.38440316]\t Cost: 22.54583411838798\n",
            "Iteration: 205\t Weight1: [6.78560278]\t Weight2: [3.05434948]\t Bias: [11.35348658]\t Cost: 22.496739485726057\n",
            "Iteration: 206\t Weight1: [6.79080069]\t Weight2: [3.05350593]\t Bias: [11.32268241]\t Cost: 22.447995471910023\n",
            "Iteration: 207\t Weight1: [6.79598804]\t Weight2: [3.05264888]\t Bias: [11.29199023]\t Cost: 22.399599504994885\n",
            "Iteration: 208\t Weight1: [6.80116484]\t Weight2: [3.05177843]\t Bias: [11.26140962]\t Cost: 22.351549032290254\n",
            "Iteration: 209\t Weight1: [6.80633111]\t Weight2: [3.05089468]\t Bias: [11.23094017]\t Cost: 22.303841520214064\n",
            "Iteration: 210\t Weight1: [6.81148686]\t Weight2: [3.04999772]\t Bias: [11.20058146]\t Cost: 22.256474454147327\n",
            "Iteration: 211\t Weight1: [6.8166321]\t Weight2: [3.04908765]\t Bias: [11.17033309]\t Cost: 22.20944533829018\n",
            "Iteration: 212\t Weight1: [6.82176687]\t Weight2: [3.04816457]\t Bias: [11.14019464]\t Cost: 22.162751695518782\n",
            "Iteration: 213\t Weight1: [6.82689116]\t Weight2: [3.04722856]\t Bias: [11.1101657]\t Cost: 22.11639106724356\n",
            "Iteration: 214\t Weight1: [6.832005]\t Weight2: [3.04627973]\t Bias: [11.08024587]\t Cost: 22.070361013268382\n",
            "Iteration: 215\t Weight1: [6.83710839]\t Weight2: [3.04531816]\t Bias: [11.05043474]\t Cost: 22.024659111650866\n",
            "Iteration: 216\t Weight1: [6.84220137]\t Weight2: [3.04434395]\t Bias: [11.02073191]\t Cost: 21.979282958563736\n",
            "Iteration: 217\t Weight1: [6.84728394]\t Weight2: [3.04335719]\t Bias: [10.99113697]\t Cost: 21.93423016815734\n",
            "Iteration: 218\t Weight1: [6.85235612]\t Weight2: [3.04235797]\t Bias: [10.96164952]\t Cost: 21.889498372423\n",
            "Iteration: 219\t Weight1: [6.85741793]\t Weight2: [3.04134639]\t Bias: [10.93226916]\t Cost: 21.845085221057765\n",
            "Iteration: 220\t Weight1: [6.86246937]\t Weight2: [3.04032253]\t Bias: [10.9029955]\t Cost: 21.800988381329777\n",
            "Iteration: 221\t Weight1: [6.86751048]\t Weight2: [3.03928649]\t Bias: [10.87382814]\t Cost: 21.757205537945\n",
            "Iteration: 222\t Weight1: [6.87254125]\t Weight2: [3.03823835]\t Bias: [10.84476668]\t Cost: 21.71373439291489\n",
            "Iteration: 223\t Weight1: [6.87756172]\t Weight2: [3.03717822]\t Bias: [10.81581073]\t Cost: 21.67057266542495\n",
            "Iteration: 224\t Weight1: [6.88257189]\t Weight2: [3.03610616]\t Bias: [10.7869599]\t Cost: 21.6277180917045\n",
            "Iteration: 225\t Weight1: [6.88757178]\t Weight2: [3.03502228]\t Bias: [10.7582138]\t Cost: 21.585168424897216\n",
            "Iteration: 226\t Weight1: [6.8925614]\t Weight2: [3.03392667]\t Bias: [10.72957203]\t Cost: 21.542921434932914\n",
            "Iteration: 227\t Weight1: [6.89754078]\t Weight2: [3.0328194]\t Bias: [10.70103421]\t Cost: 21.500974908400096\n",
            "Iteration: 228\t Weight1: [6.90250993]\t Weight2: [3.03170057]\t Bias: [10.67259996]\t Cost: 21.459326648419587\n",
            "Iteration: 229\t Weight1: [6.90746886]\t Weight2: [3.03057026]\t Bias: [10.64426888]\t Cost: 21.417974474519145\n",
            "Iteration: 230\t Weight1: [6.91241759]\t Weight2: [3.02942857]\t Bias: [10.6160406]\t Cost: 21.37691622250899\n",
            "Iteration: 231\t Weight1: [6.91735614]\t Weight2: [3.02827557]\t Bias: [10.58791473]\t Cost: 21.336149744358334\n",
            "Iteration: 232\t Weight1: [6.92228452]\t Weight2: [3.02711135]\t Bias: [10.5598909]\t Cost: 21.295672908072746\n",
            "Iteration: 233\t Weight1: [6.92720275]\t Weight2: [3.025936]\t Bias: [10.53196872]\t Cost: 21.25548359757266\n",
            "Iteration: 234\t Weight1: [6.93211084]\t Weight2: [3.0247496]\t Bias: [10.50414781]\t Cost: 21.215579712572605\n",
            "Iteration: 235\t Weight1: [6.93700881]\t Weight2: [3.02355224]\t Bias: [10.47642781]\t Cost: 21.175959168461485\n",
            "Iteration: 236\t Weight1: [6.94189667]\t Weight2: [3.022344]\t Bias: [10.44880833]\t Cost: 21.136619896183753\n",
            "Iteration: 237\t Weight1: [6.94677445]\t Weight2: [3.02112496]\t Bias: [10.421289]\t Cost: 21.097559842121466\n",
            "Iteration: 238\t Weight1: [6.95164216]\t Weight2: [3.01989521]\t Bias: [10.39386946]\t Cost: 21.05877696797728\n",
            "Iteration: 239\t Weight1: [6.95649981]\t Weight2: [3.01865483]\t Bias: [10.36654932]\t Cost: 21.020269250658288\n",
            "Iteration: 240\t Weight1: [6.96134741]\t Weight2: [3.0174039]\t Bias: [10.33932823]\t Cost: 20.982034682160922\n",
            "Iteration: 241\t Weight1: [6.966185]\t Weight2: [3.0161425]\t Bias: [10.31220581]\t Cost: 20.944071269456366\n",
            "Iteration: 242\t Weight1: [6.97101257]\t Weight2: [3.01487072]\t Bias: [10.28518169]\t Cost: 20.906377034377307\n",
            "Iteration: 243\t Weight1: [6.97583015]\t Weight2: [3.01358863]\t Bias: [10.25825552]\t Cost: 20.868950013505255\n",
            "Iteration: 244\t Weight1: [6.98063775]\t Weight2: [3.01229631]\t Bias: [10.23142693]\t Cost: 20.831788258058754\n",
            "Iteration: 245\t Weight1: [6.98543539]\t Weight2: [3.01099385]\t Bias: [10.20469555]\t Cost: 20.794889833782516\n",
            "Iteration: 246\t Weight1: [6.99022309]\t Weight2: [3.00968133]\t Bias: [10.17806103]\t Cost: 20.75825282083745\n",
            "Iteration: 247\t Weight1: [6.99500086]\t Weight2: [3.00835882]\t Bias: [10.151523]\t Cost: 20.721875313691452\n",
            "Iteration: 248\t Weight1: [6.99976871]\t Weight2: [3.0070264]\t Bias: [10.12508111]\t Cost: 20.68575542101094\n",
            "Iteration: 249\t Weight1: [7.00452667]\t Weight2: [3.00568415]\t Bias: [10.098735]\t Cost: 20.649891265553496\n",
            "Iteration: 250\t Weight1: [7.00927474]\t Weight2: [3.00433215]\t Bias: [10.07248432]\t Cost: 20.614280984061047\n",
            "Iteration: 251\t Weight1: [7.01401295]\t Weight2: [3.00297048]\t Bias: [10.04632871]\t Cost: 20.578922727154012\n",
            "Iteration: 252\t Weight1: [7.0187413]\t Weight2: [3.00159921]\t Bias: [10.02026782]\t Cost: 20.54381465922629\n",
            "Iteration: 253\t Weight1: [7.02345983]\t Weight2: [3.00021842]\t Bias: [9.9943013]\t Cost: 20.50895495834086\n",
            "Iteration: 254\t Weight1: [7.02816853]\t Weight2: [2.99882818]\t Bias: [9.9684288]\t Cost: 20.474341816126465\n",
            "Iteration: 255\t Weight1: [7.03286743]\t Weight2: [2.99742858]\t Bias: [9.94264996]\t Cost: 20.439973437674816\n",
            "Iteration: 256\t Weight1: [7.03755655]\t Weight2: [2.99601969]\t Bias: [9.91696445]\t Cost: 20.40584804143875\n",
            "Iteration: 257\t Weight1: [7.04223589]\t Weight2: [2.99460157]\t Bias: [9.89137191]\t Cost: 20.37196385913118\n",
            "Iteration: 258\t Weight1: [7.04690548]\t Weight2: [2.99317432]\t Bias: [9.865872]\t Cost: 20.338319135624616\n",
            "Iteration: 259\t Weight1: [7.05156533]\t Weight2: [2.991738]\t Bias: [9.84046438]\t Cost: 20.30491212885171\n",
            "Iteration: 260\t Weight1: [7.05621546]\t Weight2: [2.99029268]\t Bias: [9.81514871]\t Cost: 20.271741109706436\n",
            "Iteration: 261\t Weight1: [7.06085588]\t Weight2: [2.98883844]\t Bias: [9.78992464]\t Cost: 20.238804361946013\n",
            "Iteration: 262\t Weight1: [7.06548661]\t Weight2: [2.98737535]\t Bias: [9.76479183]\t Cost: 20.206100182093593\n",
            "Iteration: 263\t Weight1: [7.07010766]\t Weight2: [2.98590349]\t Bias: [9.73974995]\t Cost: 20.17362687934178\n",
            "Iteration: 264\t Weight1: [7.07471905]\t Weight2: [2.98442292]\t Bias: [9.71479866]\t Cost: 20.141382775456727\n",
            "Iteration: 265\t Weight1: [7.0793208]\t Weight2: [2.98293373]\t Bias: [9.68993762]\t Cost: 20.109366204683123\n",
            "Iteration: 266\t Weight1: [7.08391292]\t Weight2: [2.98143597]\t Bias: [9.66516651]\t Cost: 20.07757551364979\n",
            "Iteration: 267\t Weight1: [7.08849543]\t Weight2: [2.97992973]\t Bias: [9.64048498]\t Cost: 20.0460090612761\n",
            "Iteration: 268\t Weight1: [7.09306834]\t Weight2: [2.97841506]\t Bias: [9.6158927]\t Cost: 20.01466521867903\n",
            "Iteration: 269\t Weight1: [7.09763167]\t Weight2: [2.97689206]\t Bias: [9.59138934]\t Cost: 19.983542369080926\n",
            "Iteration: 270\t Weight1: [7.10218544]\t Weight2: [2.97536077]\t Bias: [9.56697458]\t Cost: 19.952638907718093\n",
            "Iteration: 271\t Weight1: [7.10672965]\t Weight2: [2.97382128]\t Bias: [9.54264809]\t Cost: 19.921953241749897\n",
            "Iteration: 272\t Weight1: [7.11126434]\t Weight2: [2.97227365]\t Bias: [9.51840953]\t Cost: 19.89148379016873\n",
            "Iteration: 273\t Weight1: [7.1157895]\t Weight2: [2.97071795]\t Bias: [9.49425858]\t Cost: 19.861228983710614\n",
            "Iteration: 274\t Weight1: [7.12030517]\t Weight2: [2.96915425]\t Bias: [9.47019493]\t Cost: 19.831187264766314\n",
            "Iteration: 275\t Weight1: [7.12481134]\t Weight2: [2.96758262]\t Bias: [9.44621824]\t Cost: 19.801357087293525\n",
            "Iteration: 276\t Weight1: [7.12930805]\t Weight2: [2.96600312]\t Bias: [9.42232819]\t Cost: 19.771736916729335\n",
            "Iteration: 277\t Weight1: [7.13379531]\t Weight2: [2.96441583]\t Bias: [9.39852446]\t Cost: 19.74232522990349\n",
            "Iteration: 278\t Weight1: [7.13827312]\t Weight2: [2.9628208]\t Bias: [9.37480674]\t Cost: 19.713120514952475\n",
            "Iteration: 279\t Weight1: [7.14274151]\t Weight2: [2.96121812]\t Bias: [9.35117469]\t Cost: 19.68412127123404\n",
            "Iteration: 280\t Weight1: [7.1472005]\t Weight2: [2.95960784]\t Bias: [9.32762802]\t Cost: 19.655326009242454\n",
            "Iteration: 281\t Weight1: [7.15165009]\t Weight2: [2.95799002]\t Bias: [9.3041664]\t Cost: 19.62673325052446\n",
            "Iteration: 282\t Weight1: [7.15609031]\t Weight2: [2.95636475]\t Bias: [9.28078951]\t Cost: 19.598341527595824\n",
            "Iteration: 283\t Weight1: [7.16052117]\t Weight2: [2.95473207]\t Bias: [9.25749704]\t Cost: 19.570149383858478\n",
            "Iteration: 284\t Weight1: [7.16494268]\t Weight2: [2.95309206]\t Bias: [9.23428868]\t Cost: 19.542155373518426\n",
            "Iteration: 285\t Weight1: [7.16935487]\t Weight2: [2.95144478]\t Bias: [9.21116412]\t Cost: 19.514358061504108\n",
            "Iteration: 286\t Weight1: [7.17375774]\t Weight2: [2.94979029]\t Bias: [9.18812305]\t Cost: 19.48675602338557\n",
            "Iteration: 287\t Weight1: [7.17815131]\t Weight2: [2.94812866]\t Bias: [9.16516516]\t Cost: 19.459347845294054\n",
            "Iteration: 288\t Weight1: [7.18253561]\t Weight2: [2.94645996]\t Bias: [9.14229014]\t Cost: 19.4321321238424\n",
            "Iteration: 289\t Weight1: [7.18691063]\t Weight2: [2.94478424]\t Bias: [9.11949768]\t Cost: 19.405107466045923\n",
            "Iteration: 290\t Weight1: [7.19127641]\t Weight2: [2.94310157]\t Bias: [9.09678748]\t Cost: 19.378272489243923\n",
            "Iteration: 291\t Weight1: [7.19563296]\t Weight2: [2.94141201]\t Bias: [9.07415924]\t Cost: 19.35162582102184\n",
            "Iteration: 292\t Weight1: [7.19998028]\t Weight2: [2.93971562]\t Bias: [9.05161265]\t Cost: 19.325166099133924\n",
            "Iteration: 293\t Weight1: [7.2043184]\t Weight2: [2.93801247]\t Bias: [9.0291474]\t Cost: 19.298891971426595\n",
            "Iteration: 294\t Weight1: [7.20864734]\t Weight2: [2.93630262]\t Bias: [9.00676321]\t Cost: 19.272802095762334\n",
            "Iteration: 295\t Weight1: [7.2129671]\t Weight2: [2.93458612]\t Bias: [8.98445976]\t Cost: 19.24689513994405\n",
            "Iteration: 296\t Weight1: [7.21727771]\t Weight2: [2.93286304]\t Bias: [8.96223677]\t Cost: 19.221169781640313\n",
            "Iteration: 297\t Weight1: [7.22157917]\t Weight2: [2.93113344]\t Bias: [8.94009392]\t Cost: 19.195624708310795\n",
            "Iteration: 298\t Weight1: [7.22587152]\t Weight2: [2.92939738]\t Bias: [8.91803094]\t Cost: 19.170258617132614\n",
            "Iteration: 299\t Weight1: [7.23015475]\t Weight2: [2.92765493]\t Bias: [8.89604751]\t Cost: 19.145070214926953\n",
            "Iteration: 300\t Weight1: [7.23442889]\t Weight2: [2.92590613]\t Bias: [8.87414335]\t Cost: 19.120058218086488\n",
            "Iteration: 301\t Weight1: [7.23869395]\t Weight2: [2.92415105]\t Bias: [8.85231817]\t Cost: 19.095221352503216\n",
            "Iteration: 302\t Weight1: [7.24294994]\t Weight2: [2.92238974]\t Bias: [8.83057166]\t Cost: 19.070558353496796\n",
            "Iteration: 303\t Weight1: [7.2471969]\t Weight2: [2.92062228]\t Bias: [8.80890355]\t Cost: 19.046067965743706\n",
            "Iteration: 304\t Weight1: [7.25143481]\t Weight2: [2.9188487]\t Bias: [8.78731353]\t Cost: 19.021748943206532\n",
            "Iteration: 305\t Weight1: [7.25566372]\t Weight2: [2.91706908]\t Bias: [8.76580133]\t Cost: 18.997600049064154\n",
            "Iteration: 306\t Weight1: [7.25988362]\t Weight2: [2.91528347]\t Bias: [8.74436666]\t Cost: 18.97362005564228\n",
            "Iteration: 307\t Weight1: [7.26409454]\t Weight2: [2.91349193]\t Bias: [8.72300922]\t Cost: 18.949807744344557\n",
            "Iteration: 308\t Weight1: [7.26829649]\t Weight2: [2.91169452]\t Bias: [8.70172873]\t Cost: 18.926161905584262\n",
            "Iteration: 309\t Weight1: [7.27248949]\t Weight2: [2.90989128]\t Bias: [8.68052492]\t Cost: 18.902681338716352\n",
            "Iteration: 310\t Weight1: [7.27667354]\t Weight2: [2.90808228]\t Bias: [8.65939749]\t Cost: 18.879364851970198\n",
            "Iteration: 311\t Weight1: [7.28084868]\t Weight2: [2.90626758]\t Bias: [8.63834616]\t Cost: 18.85621126238285\n",
            "Iteration: 312\t Weight1: [7.28501491]\t Weight2: [2.90444722]\t Bias: [8.61737065]\t Cost: 18.83321939573257\n",
            "Iteration: 313\t Weight1: [7.28917224]\t Weight2: [2.90262128]\t Bias: [8.59647069]\t Cost: 18.810388086473175\n",
            "Iteration: 314\t Weight1: [7.2933207]\t Weight2: [2.90078979]\t Bias: [8.57564598]\t Cost: 18.787716177668685\n",
            "Iteration: 315\t Weight1: [7.2974603]\t Weight2: [2.89895282]\t Bias: [8.55489627]\t Cost: 18.76520252092855\n",
            "Iteration: 316\t Weight1: [7.30159106]\t Weight2: [2.89711041]\t Bias: [8.53422126]\t Cost: 18.742845976343308\n",
            "Iteration: 317\t Weight1: [7.30571298]\t Weight2: [2.89526263]\t Bias: [8.51362068]\t Cost: 18.72064541242084\n",
            "Iteration: 318\t Weight1: [7.30982609]\t Weight2: [2.89340953]\t Bias: [8.49309426]\t Cost: 18.698599706022943\n",
            "Iteration: 319\t Weight1: [7.3139304]\t Weight2: [2.89155117]\t Bias: [8.47264172]\t Cost: 18.676707742302646\n",
            "Iteration: 320\t Weight1: [7.31802593]\t Weight2: [2.88968758]\t Bias: [8.45226279]\t Cost: 18.654968414641672\n",
            "Iteration: 321\t Weight1: [7.32211269]\t Weight2: [2.88781884]\t Bias: [8.4319572]\t Cost: 18.633380624588657\n",
            "Iteration: 322\t Weight1: [7.32619069]\t Weight2: [2.88594499]\t Bias: [8.41172468]\t Cost: 18.611943281797757\n",
            "Iteration: 323\t Weight1: [7.33025996]\t Weight2: [2.88406608]\t Bias: [8.39156496]\t Cost: 18.590655303967555\n",
            "Iteration: 324\t Weight1: [7.33432051]\t Weight2: [2.88218217]\t Bias: [8.37147776]\t Cost: 18.569515616780784\n",
            "Iteration: 325\t Weight1: [7.33837235]\t Weight2: [2.8802933]\t Bias: [8.35146283]\t Cost: 18.54852315384413\n",
            "Iteration: 326\t Weight1: [7.34241549]\t Weight2: [2.87839954]\t Bias: [8.33151989]\t Cost: 18.52767685662878\n",
            "Iteration: 327\t Weight1: [7.34644996]\t Weight2: [2.87650092]\t Bias: [8.31164869]\t Cost: 18.50697567441124\n",
            "Iteration: 328\t Weight1: [7.35047578]\t Weight2: [2.87459751]\t Bias: [8.29184894]\t Cost: 18.486418564214713\n",
            "Iteration: 329\t Weight1: [7.35449294]\t Weight2: [2.87268935]\t Bias: [8.2721204]\t Cost: 18.466004490750894\n",
            "Iteration: 330\t Weight1: [7.35850148]\t Weight2: [2.8707765]\t Bias: [8.2524628]\t Cost: 18.445732426362163\n",
            "Iteration: 331\t Weight1: [7.3625014]\t Weight2: [2.868859]\t Bias: [8.23287587]\t Cost: 18.425601350964286\n",
            "Iteration: 332\t Weight1: [7.36649272]\t Weight2: [2.8669369]\t Bias: [8.21335936]\t Cost: 18.405610251989504\n",
            "Iteration: 333\t Weight1: [7.37047545]\t Weight2: [2.86501025]\t Bias: [8.193913]\t Cost: 18.385758124330113\n",
            "Iteration: 334\t Weight1: [7.37444962]\t Weight2: [2.86307911]\t Bias: [8.17453654]\t Cost: 18.366043970282377\n",
            "Iteration: 335\t Weight1: [7.37841523]\t Weight2: [2.86114352]\t Bias: [8.15522972]\t Cost: 18.346466799490948\n",
            "Iteration: 336\t Weight1: [7.38237231]\t Weight2: [2.85920353]\t Bias: [8.13599228]\t Cost: 18.327025628893754\n",
            "Iteration: 337\t Weight1: [7.38632086]\t Weight2: [2.85725919]\t Bias: [8.11682397]\t Cost: 18.307719482667085\n",
            "Iteration: 338\t Weight1: [7.3902609]\t Weight2: [2.85531055]\t Bias: [8.09772454]\t Cost: 18.28854739217145\n",
            "Iteration: 339\t Weight1: [7.39419245]\t Weight2: [2.85335765]\t Bias: [8.07869372]\t Cost: 18.26950839589745\n",
            "Iteration: 340\t Weight1: [7.39811553]\t Weight2: [2.85140055]\t Bias: [8.05973126]\t Cost: 18.250601539412436\n",
            "Iteration: 341\t Weight1: [7.40203014]\t Weight2: [2.84943929]\t Bias: [8.04083692]\t Cost: 18.231825875307276\n",
            "Iteration: 342\t Weight1: [7.4059363]\t Weight2: [2.84747392]\t Bias: [8.02201044]\t Cost: 18.213180463143686\n",
            "Iteration: 343\t Weight1: [7.40983403]\t Weight2: [2.84550448]\t Bias: [8.00325157]\t Cost: 18.19466436940197\n",
            "Iteration: 344\t Weight1: [7.41372334]\t Weight2: [2.84353102]\t Bias: [7.98456006]\t Cost: 18.176276667429022\n",
            "Iteration: 345\t Weight1: [7.41760425]\t Weight2: [2.84155359]\t Bias: [7.96593567]\t Cost: 18.158016437386934\n",
            "Iteration: 346\t Weight1: [7.42147677]\t Weight2: [2.83957223]\t Bias: [7.94737815]\t Cost: 18.139882766201765\n",
            "Iteration: 347\t Weight1: [7.42534092]\t Weight2: [2.837587]\t Bias: [7.92888724]\t Cost: 18.12187474751285\n",
            "Iteration: 348\t Weight1: [7.42919672]\t Weight2: [2.83559793]\t Bias: [7.91046271]\t Cost: 18.103991481622483\n",
            "Iteration: 349\t Weight1: [7.43304417]\t Weight2: [2.83360507]\t Bias: [7.89210431]\t Cost: 18.08623207544596\n",
            "Iteration: 350\t Weight1: [7.4368833]\t Weight2: [2.83160847]\t Bias: [7.8738118]\t Cost: 18.0685956424619\n",
            "Iteration: 351\t Weight1: [7.44071411]\t Weight2: [2.82960817]\t Bias: [7.85558493]\t Cost: 18.051081302663206\n",
            "Iteration: 352\t Weight1: [7.44453663]\t Weight2: [2.82760422]\t Bias: [7.83742346]\t Cost: 18.033688182508044\n",
            "Iteration: 353\t Weight1: [7.44835086]\t Weight2: [2.82559665]\t Bias: [7.81932716]\t Cost: 18.016415414871553\n",
            "Iteration: 354\t Weight1: [7.45215683]\t Weight2: [2.82358553]\t Bias: [7.80129578]\t Cost: 17.999262138997665\n",
            "Iteration: 355\t Weight1: [7.45595455]\t Weight2: [2.82157087]\t Bias: [7.78332908]\t Cost: 17.982227500451405\n",
            "Iteration: 356\t Weight1: [7.45974403]\t Weight2: [2.81955274]\t Bias: [7.76542682]\t Cost: 17.965310651071476\n",
            "Iteration: 357\t Weight1: [7.46352529]\t Weight2: [2.81753118]\t Bias: [7.74758877]\t Cost: 17.948510748923397\n",
            "Iteration: 358\t Weight1: [7.46729834]\t Weight2: [2.81550622]\t Bias: [7.72981469]\t Cost: 17.93182695825267\n",
            "Iteration: 359\t Weight1: [7.4710632]\t Weight2: [2.81347792]\t Bias: [7.71210434]\t Cost: 17.915258449438657\n",
            "Iteration: 360\t Weight1: [7.47481988]\t Weight2: [2.81144631]\t Bias: [7.6944575]\t Cost: 17.898804398948556\n",
            "Iteration: 361\t Weight1: [7.4785684]\t Weight2: [2.80941143]\t Bias: [7.67687392]\t Cost: 17.88246398929182\n",
            "Iteration: 362\t Weight1: [7.48230878]\t Weight2: [2.80737334]\t Bias: [7.65935337]\t Cost: 17.866236408974917\n",
            "Iteration: 363\t Weight1: [7.48604102]\t Weight2: [2.80533206]\t Bias: [7.64189563]\t Cost: 17.850120852456467\n",
            "Iteration: 364\t Weight1: [7.48976514]\t Weight2: [2.80328765]\t Bias: [7.62450046]\t Cost: 17.83411652010267\n",
            "Iteration: 365\t Weight1: [7.49348116]\t Weight2: [2.80124014]\t Bias: [7.60716762]\t Cost: 17.818222618143015\n",
            "Iteration: 366\t Weight1: [7.4971891]\t Weight2: [2.79918957]\t Bias: [7.5898969]\t Cost: 17.802438358626492\n",
            "Iteration: 367\t Weight1: [7.50088896]\t Weight2: [2.79713599]\t Bias: [7.57268806]\t Cost: 17.786762959378024\n",
            "Iteration: 368\t Weight1: [7.50458076]\t Weight2: [2.79507943]\t Bias: [7.55554088]\t Cost: 17.77119564395522\n",
            "Iteration: 369\t Weight1: [7.50826452]\t Weight2: [2.79301994]\t Bias: [7.53845512]\t Cost: 17.75573564160552\n",
            "Iteration: 370\t Weight1: [7.51194025]\t Weight2: [2.79095756]\t Bias: [7.52143056]\t Cost: 17.740382187223545\n",
            "Iteration: 371\t Weight1: [7.51560797]\t Weight2: [2.78889233]\t Bias: [7.50446698]\t Cost: 17.725134521309002\n",
            "Iteration: 372\t Weight1: [7.51926768]\t Weight2: [2.78682428]\t Bias: [7.48756415]\t Cost: 17.709991889924645\n",
            "Iteration: 373\t Weight1: [7.52291942]\t Weight2: [2.78475345]\t Bias: [7.47072186]\t Cost: 17.694953544654677\n",
            "Iteration: 374\t Weight1: [7.52656318]\t Weight2: [2.7826799]\t Bias: [7.45393986]\t Cost: 17.680018742563554\n",
            "Iteration: 375\t Weight1: [7.53019899]\t Weight2: [2.78060364]\t Bias: [7.43721796]\t Cost: 17.665186746154937\n",
            "Iteration: 376\t Weight1: [7.53382686]\t Weight2: [2.77852473]\t Bias: [7.42055591]\t Cost: 17.65045682333103\n",
            "Iteration: 377\t Weight1: [7.5374468]\t Weight2: [2.77644321]\t Bias: [7.40395351]\t Cost: 17.635828247352258\n",
            "Iteration: 378\t Weight1: [7.54105883]\t Weight2: [2.7743591]\t Bias: [7.38741054]\t Cost: 17.621300296797227\n",
            "Iteration: 379\t Weight1: [7.54466297]\t Weight2: [2.77227245]\t Bias: [7.37092677]\t Cost: 17.606872255522937\n",
            "Iteration: 380\t Weight1: [7.54825922]\t Weight2: [2.7701833]\t Bias: [7.35450198]\t Cost: 17.592543412625375\n",
            "Iteration: 381\t Weight1: [7.55184761]\t Weight2: [2.76809168]\t Bias: [7.33813597]\t Cost: 17.578313062400373\n",
            "Iteration: 382\t Weight1: [7.55542815]\t Weight2: [2.76599763]\t Bias: [7.32182852]\t Cost: 17.564180504304733\n",
            "Iteration: 383\t Weight1: [7.55900085]\t Weight2: [2.76390119]\t Bias: [7.3055794]\t Cost: 17.550145042917727\n",
            "Iteration: 384\t Weight1: [7.56256572]\t Weight2: [2.7618024]\t Bias: [7.28938841]\t Cost: 17.536205987902793\n",
            "Iteration: 385\t Weight1: [7.56612279]\t Weight2: [2.75970129]\t Bias: [7.27325533]\t Cost: 17.522362653969584\n",
            "Iteration: 386\t Weight1: [7.56967206]\t Weight2: [2.7575979]\t Bias: [7.25717996]\t Cost: 17.508614360836297\n",
            "Iteration: 387\t Weight1: [7.57321355]\t Weight2: [2.75549227]\t Bias: [7.24116206]\t Cost: 17.494960433192283\n",
            "Iteration: 388\t Weight1: [7.57674728]\t Weight2: [2.75338443]\t Bias: [7.22520145]\t Cost: 17.481400200660904\n",
            "Iteration: 389\t Weight1: [7.58027325]\t Weight2: [2.75127441]\t Bias: [7.2092979]\t Cost: 17.467932997762748\n",
            "Iteration: 390\t Weight1: [7.5837915]\t Weight2: [2.74916226]\t Bias: [7.19345121]\t Cost: 17.454558163879042\n",
            "Iteration: 391\t Weight1: [7.58730202]\t Weight2: [2.74704801]\t Bias: [7.17766116]\t Cost: 17.441275043215416\n",
            "Iteration: 392\t Weight1: [7.59080483]\t Weight2: [2.7449317]\t Bias: [7.16192755]\t Cost: 17.428082984765854\n",
            "Iteration: 393\t Weight1: [7.59429995]\t Weight2: [2.74281335]\t Bias: [7.14625018]\t Cost: 17.414981342277027\n",
            "Iteration: 394\t Weight1: [7.59778739]\t Weight2: [2.74069301]\t Bias: [7.13062883]\t Cost: 17.401969474212816\n",
            "Iteration: 395\t Weight1: [7.60126717]\t Weight2: [2.73857071]\t Bias: [7.1150633]\t Cost: 17.38904674371908\n",
            "Iteration: 396\t Weight1: [7.60473929]\t Weight2: [2.73644649]\t Bias: [7.09955339]\t Cost: 17.376212518588844\n",
            "Iteration: 397\t Weight1: [7.60820379]\t Weight2: [2.73432037]\t Bias: [7.08409888]\t Cost: 17.363466171227568\n",
            "Iteration: 398\t Weight1: [7.61166066]\t Weight2: [2.73219239]\t Bias: [7.06869959]\t Cost: 17.350807078618715\n",
            "Iteration: 399\t Weight1: [7.61510992]\t Weight2: [2.73006259]\t Bias: [7.0533553]\t Cost: 17.338234622289754\n",
            "Iteration: 400\t Weight1: [7.6185516]\t Weight2: [2.727931]\t Bias: [7.03806581]\t Cost: 17.325748188278176\n",
            "Iteration: 401\t Weight1: [7.62198569]\t Weight2: [2.72579766]\t Bias: [7.02283092]\t Cost: 17.313347167097902\n",
            "Iteration: 402\t Weight1: [7.62541223]\t Weight2: [2.72366259]\t Bias: [7.00765043]\t Cost: 17.301030953705936\n",
            "Iteration: 403\t Weight1: [7.62883121]\t Weight2: [2.72152583]\t Bias: [6.99252415]\t Cost: 17.28879894746928\n",
            "Iteration: 404\t Weight1: [7.63224266]\t Weight2: [2.71938741]\t Bias: [6.97745187]\t Cost: 17.276650552132004\n",
            "Iteration: 405\t Weight1: [7.63564659]\t Weight2: [2.71724737]\t Bias: [6.96243339]\t Cost: 17.26458517578275\n",
            "Iteration: 406\t Weight1: [7.63904301]\t Weight2: [2.71510574]\t Bias: [6.94746852]\t Cost: 17.25260223082225\n",
            "Iteration: 407\t Weight1: [7.64243194]\t Weight2: [2.71296255]\t Bias: [6.93255706]\t Cost: 17.240701133931278\n",
            "Iteration: 408\t Weight1: [7.64581339]\t Weight2: [2.71081783]\t Bias: [6.91769882]\t Cost: 17.228881306038772\n",
            "Iteration: 409\t Weight1: [7.64918738]\t Weight2: [2.70867162]\t Bias: [6.90289359]\t Cost: 17.217142172290174\n",
            "Iteration: 410\t Weight1: [7.65255391]\t Weight2: [2.70652394]\t Bias: [6.88814119]\t Cost: 17.205483162016076\n",
            "Iteration: 411\t Weight1: [7.65591302]\t Weight2: [2.70437483]\t Bias: [6.87344142]\t Cost: 17.19390370870103\n",
            "Iteration: 412\t Weight1: [7.6592647]\t Weight2: [2.70222432]\t Bias: [6.85879409]\t Cost: 17.18240324995263\n",
            "Iteration: 413\t Weight1: [7.66260897]\t Weight2: [2.70007244]\t Bias: [6.84419901]\t Cost: 17.170981227470868\n",
            "Iteration: 414\t Weight1: [7.66594585]\t Weight2: [2.69791922]\t Bias: [6.82965598]\t Cost: 17.15963708701763\n",
            "Iteration: 415\t Weight1: [7.66927535]\t Weight2: [2.69576469]\t Bias: [6.81516481]\t Cost: 17.148370278386523\n",
            "Iteration: 416\t Weight1: [7.67259749]\t Weight2: [2.69360889]\t Bias: [6.80072532]\t Cost: 17.13718025537279\n",
            "Iteration: 417\t Weight1: [7.67591228]\t Weight2: [2.69145184]\t Bias: [6.78633731]\t Cost: 17.126066475743674\n",
            "Iteration: 418\t Weight1: [7.67921973]\t Weight2: [2.68929357]\t Bias: [6.7720006]\t Cost: 17.11502840120878\n",
            "Iteration: 419\t Weight1: [7.68251985]\t Weight2: [2.68713411]\t Bias: [6.75771499]\t Cost: 17.104065497390767\n",
            "Iteration: 420\t Weight1: [7.68581267]\t Weight2: [2.6849735]\t Bias: [6.74348031]\t Cost: 17.093177233796272\n",
            "Iteration: 421\t Weight1: [7.68909819]\t Weight2: [2.68281176]\t Bias: [6.72929636]\t Cost: 17.08236308378704\n",
            "Iteration: 422\t Weight1: [7.69237643]\t Weight2: [2.68064893]\t Bias: [6.71516295]\t Cost: 17.07162252455126\n",
            "Iteration: 423\t Weight1: [7.69564741]\t Weight2: [2.67848502]\t Bias: [6.70107991]\t Cost: 17.0609550370751\n",
            "Iteration: 424\t Weight1: [7.69891113]\t Weight2: [2.67632008]\t Bias: [6.68704705]\t Cost: 17.05036010611448\n",
            "Iteration: 425\t Weight1: [7.70216761]\t Weight2: [2.67415412]\t Bias: [6.67306418]\t Cost: 17.039837220167133\n",
            "Iteration: 426\t Weight1: [7.70541687]\t Weight2: [2.67198719]\t Bias: [6.65913112]\t Cost: 17.02938587144464\n",
            "Iteration: 427\t Weight1: [7.70865892]\t Weight2: [2.6698193]\t Bias: [6.64524769]\t Cost: 17.019005555845048\n",
            "Iteration: 428\t Weight1: [7.71189377]\t Weight2: [2.66765049]\t Bias: [6.63141371]\t Cost: 17.008695772925332\n",
            "Iteration: 429\t Weight1: [7.71512143]\t Weight2: [2.66548078]\t Bias: [6.61762899]\t Cost: 16.998456025874262\n",
            "Iteration: 430\t Weight1: [7.71834193]\t Weight2: [2.6633102]\t Bias: [6.60389336]\t Cost: 16.988285821485434\n",
            "Iteration: 431\t Weight1: [7.72155527]\t Weight2: [2.66113878]\t Bias: [6.59020663]\t Cost: 16.978184670130556\n",
            "Iteration: 432\t Weight1: [7.72476146]\t Weight2: [2.65896655]\t Bias: [6.57656863]\t Cost: 16.96815208573276\n",
            "Iteration: 433\t Weight1: [7.72796053]\t Weight2: [2.65679354]\t Bias: [6.56297918]\t Cost: 16.95818758574035\n",
            "Iteration: 434\t Weight1: [7.73115249]\t Weight2: [2.65461976]\t Bias: [6.5494381]\t Cost: 16.948290691100603\n",
            "Iteration: 435\t Weight1: [7.73433734]\t Weight2: [2.65244526]\t Bias: [6.53594522]\t Cost: 16.938460926233766\n",
            "Iteration: 436\t Weight1: [7.73751511]\t Weight2: [2.65027005]\t Bias: [6.52250035]\t Cost: 16.92869781900734\n",
            "Iteration: 437\t Weight1: [7.7406858]\t Weight2: [2.64809417]\t Bias: [6.50910332]\t Cost: 16.919000900710444\n",
            "Iteration: 438\t Weight1: [7.74384944]\t Weight2: [2.64591763]\t Bias: [6.49575395]\t Cost: 16.909369706028517\n",
            "Iteration: 439\t Weight1: [7.74700602]\t Weight2: [2.64374048]\t Bias: [6.48245208]\t Cost: 16.899803773017993\n",
            "Iteration: 440\t Weight1: [7.75015558]\t Weight2: [2.64156272]\t Bias: [6.46919753]\t Cost: 16.890302643081455\n",
            "Iteration: 441\t Weight1: [7.75329812]\t Weight2: [2.6393844]\t Bias: [6.45599012]\t Cost: 16.880865860942677\n",
            "Iteration: 442\t Weight1: [7.75643365]\t Weight2: [2.63720553]\t Bias: [6.44282969]\t Cost: 16.871492974622104\n",
            "Iteration: 443\t Weight1: [7.75956219]\t Weight2: [2.63502614]\t Bias: [6.42971606]\t Cost: 16.862183535412377\n",
            "Iteration: 444\t Weight1: [7.76268375]\t Weight2: [2.63284626]\t Bias: [6.41664905]\t Cost: 16.85293709785404\n",
            "Iteration: 445\t Weight1: [7.76579835]\t Weight2: [2.63066591]\t Bias: [6.4036285]\t Cost: 16.8437532197115\n",
            "Iteration: 446\t Weight1: [7.768906]\t Weight2: [2.62848512]\t Bias: [6.39065425]\t Cost: 16.834631461949183\n",
            "Iteration: 447\t Weight1: [7.77200671]\t Weight2: [2.62630391]\t Bias: [6.37772611]\t Cost: 16.825571388707704\n",
            "Iteration: 448\t Weight1: [7.7751005]\t Weight2: [2.62412231]\t Bias: [6.36484393]\t Cost: 16.816572567280442\n",
            "Iteration: 449\t Weight1: [7.77818738]\t Weight2: [2.62194034]\t Bias: [6.35200752]\t Cost: 16.80763456809015\n",
            "Iteration: 450\t Weight1: [7.78126736]\t Weight2: [2.61975803]\t Bias: [6.33921674]\t Cost: 16.798756964665767\n",
            "Iteration: 451\t Weight1: [7.78434046]\t Weight2: [2.6175754]\t Bias: [6.3264714]\t Cost: 16.789939333619387\n",
            "Iteration: 452\t Weight1: [7.78740669]\t Weight2: [2.61539248]\t Bias: [6.31377134]\t Cost: 16.781181254623526\n",
            "Iteration: 453\t Weight1: [7.79046606]\t Weight2: [2.61320928]\t Bias: [6.30111641]\t Cost: 16.772482310388344\n",
            "Iteration: 454\t Weight1: [7.79351859]\t Weight2: [2.61102585]\t Bias: [6.28850642]\t Cost: 16.763842086639237\n",
            "Iteration: 455\t Weight1: [7.79656429]\t Weight2: [2.60884219]\t Bias: [6.27594123]\t Cost: 16.755260172094474\n",
            "Iteration: 456\t Weight1: [7.79960317]\t Weight2: [2.60665834]\t Bias: [6.26342065]\t Cost: 16.746736158443113\n",
            "Iteration: 457\t Weight1: [7.80263525]\t Weight2: [2.60447431]\t Bias: [6.25094454]\t Cost: 16.73826964032288\n",
            "Iteration: 458\t Weight1: [7.80566055]\t Weight2: [2.60229013]\t Bias: [6.23851273]\t Cost: 16.729860215298572\n",
            "Iteration: 459\t Weight1: [7.80867906]\t Weight2: [2.60010582]\t Bias: [6.22612506]\t Cost: 16.721507483840163\n",
            "Iteration: 460\t Weight1: [7.81169082]\t Weight2: [2.59792141]\t Bias: [6.21378136]\t Cost: 16.713211049301457\n",
            "Iteration: 461\t Weight1: [7.81469582]\t Weight2: [2.59573692]\t Bias: [6.20148148]\t Cost: 16.704970517898758\n",
            "Iteration: 462\t Weight1: [7.81769409]\t Weight2: [2.59355238]\t Bias: [6.18922525]\t Cost: 16.69678549868965\n",
            "Iteration: 463\t Weight1: [7.82068564]\t Weight2: [2.59136779]\t Bias: [6.17701252]\t Cost: 16.688655603552\n",
            "Iteration: 464\t Weight1: [7.82367047]\t Weight2: [2.5891832]\t Bias: [6.16484312]\t Cost: 16.680580447163166\n",
            "Iteration: 465\t Weight1: [7.82664861]\t Weight2: [2.58699861]\t Bias: [6.15271691]\t Cost: 16.672559646979202\n",
            "Iteration: 466\t Weight1: [7.82962007]\t Weight2: [2.58481406]\t Bias: [6.14063372]\t Cost: 16.664592823214402\n",
            "Iteration: 467\t Weight1: [7.83258486]\t Weight2: [2.58262956]\t Bias: [6.12859339]\t Cost: 16.656679598820894\n",
            "Iteration: 468\t Weight1: [7.83554299]\t Weight2: [2.58044514]\t Bias: [6.11659576]\t Cost: 16.64881959946842\n",
            "Iteration: 469\t Weight1: [7.83849448]\t Weight2: [2.57826082]\t Bias: [6.10464069]\t Cost: 16.64101245352424\n",
            "Iteration: 470\t Weight1: [7.84143933]\t Weight2: [2.57607662]\t Bias: [6.09272802]\t Cost: 16.633257792033184\n",
            "Iteration: 471\t Weight1: [7.84437757]\t Weight2: [2.57389256]\t Bias: [6.08085759]\t Cost: 16.625555248697946\n",
            "Iteration: 472\t Weight1: [7.84730921]\t Weight2: [2.57170866]\t Bias: [6.06902924]\t Cost: 16.61790445985945\n",
            "Iteration: 473\t Weight1: [7.85023426]\t Weight2: [2.56952494]\t Bias: [6.05724283]\t Cost: 16.610305064477238\n",
            "Iteration: 474\t Weight1: [7.85315272]\t Weight2: [2.56734144]\t Bias: [6.0454982]\t Cost: 16.60275670411031\n",
            "Iteration: 475\t Weight1: [7.85606462]\t Weight2: [2.56515815]\t Bias: [6.0337952]\t Cost: 16.595259022897874\n",
            "Iteration: 476\t Weight1: [7.85896997]\t Weight2: [2.56297512]\t Bias: [6.02213367]\t Cost: 16.587811667540237\n",
            "Iteration: 477\t Weight1: [7.86186878]\t Weight2: [2.56079235]\t Bias: [6.01051347]\t Cost: 16.58041428728003\n",
            "Iteration: 478\t Weight1: [7.86476107]\t Weight2: [2.55860988]\t Bias: [5.99893445]\t Cost: 16.57306653388334\n",
            "Iteration: 479\t Weight1: [7.86764684]\t Weight2: [2.55642771]\t Bias: [5.98739645]\t Cost: 16.565768061621124\n",
            "Iteration: 480\t Weight1: [7.87052611]\t Weight2: [2.55424587]\t Bias: [5.97589932]\t Cost: 16.558518527250776\n",
            "Iteration: 481\t Weight1: [7.8733989]\t Weight2: [2.55206438]\t Bias: [5.96444292]\t Cost: 16.551317589997748\n",
            "Iteration: 482\t Weight1: [7.87626521]\t Weight2: [2.54988326]\t Bias: [5.9530271]\t Cost: 16.544164911537337\n",
            "Iteration: 483\t Weight1: [7.87912506]\t Weight2: [2.54770253]\t Bias: [5.94165171]\t Cost: 16.53706015597668\n",
            "Iteration: 484\t Weight1: [7.88197846]\t Weight2: [2.54552221]\t Bias: [5.9303166]\t Cost: 16.530002989836785\n",
            "Iteration: 485\t Weight1: [7.88482543]\t Weight2: [2.54334232]\t Bias: [5.91902162]\t Cost: 16.522993082034677\n",
            "Iteration: 486\t Weight1: [7.88766597]\t Weight2: [2.54116288]\t Bias: [5.90776663]\t Cost: 16.516030103865894\n",
            "Iteration: 487\t Weight1: [7.89050011]\t Weight2: [2.53898391]\t Bias: [5.89655149]\t Cost: 16.509113728986843\n",
            "Iteration: 488\t Weight1: [7.89332785]\t Weight2: [2.53680542]\t Bias: [5.88537604]\t Cost: 16.502243633397416\n",
            "Iteration: 489\t Weight1: [7.8961492]\t Weight2: [2.53462744]\t Bias: [5.87424015]\t Cost: 16.495419495423757\n",
            "Iteration: 490\t Weight1: [7.89896418]\t Weight2: [2.53244999]\t Bias: [5.86314367]\t Cost: 16.48864099570109\n",
            "Iteration: 491\t Weight1: [7.9017728]\t Weight2: [2.53027308]\t Bias: [5.85208645]\t Cost: 16.481907817156795\n",
            "Iteration: 492\t Weight1: [7.90457508]\t Weight2: [2.52809673]\t Bias: [5.84106835]\t Cost: 16.475219644993448\n",
            "Iteration: 493\t Weight1: [7.90737103]\t Weight2: [2.52592096]\t Bias: [5.83008923]\t Cost: 16.46857616667202\n",
            "Iteration: 494\t Weight1: [7.91016065]\t Weight2: [2.5237458]\t Bias: [5.81914896]\t Cost: 16.461977071895458\n",
            "Iteration: 495\t Weight1: [7.91294397]\t Weight2: [2.52157125]\t Bias: [5.80824737]\t Cost: 16.45542205259194\n",
            "Iteration: 496\t Weight1: [7.91572099]\t Weight2: [2.51939734]\t Bias: [5.79738435]\t Cost: 16.44891080289867\n",
            "Iteration: 497\t Weight1: [7.91849173]\t Weight2: [2.51722409]\t Bias: [5.78655974]\t Cost: 16.44244301914554\n",
            "Iteration: 498\t Weight1: [7.9212562]\t Weight2: [2.5150515]\t Bias: [5.7757734]\t Cost: 16.43601839983905\n",
            "Iteration: 499\t Weight1: [7.92401441]\t Weight2: [2.51287961]\t Bias: [5.7650252]\t Cost: 16.42963664564622\n",
            "Iteration: 500\t Weight1: [7.92676638]\t Weight2: [2.51070843]\t Bias: [5.754315]\t Cost: 16.423297459378787\n",
            "Iteration: 501\t Weight1: [7.92951211]\t Weight2: [2.50853797]\t Bias: [5.74364265]\t Cost: 16.417000545977377\n",
            "Iteration: 502\t Weight1: [7.93225163]\t Weight2: [2.50636825]\t Bias: [5.73300803]\t Cost: 16.41074561249588\n",
            "Iteration: 503\t Weight1: [7.93498494]\t Weight2: [2.5041993]\t Bias: [5.72241099]\t Cost: 16.404532368085885\n",
            "Iteration: 504\t Weight1: [7.93771205]\t Weight2: [2.50203112]\t Bias: [5.71185139]\t Cost: 16.398360523981275\n",
            "Iteration: 505\t Weight1: [7.94043299]\t Weight2: [2.49986374]\t Bias: [5.70132911]\t Cost: 16.392229793482972\n",
            "Iteration: 506\t Weight1: [7.94314775]\t Weight2: [2.49769717]\t Bias: [5.690844]\t Cost: 16.38613989194363\n",
            "Iteration: 507\t Weight1: [7.94585636]\t Weight2: [2.49553144]\t Bias: [5.68039593]\t Cost: 16.380090536752686\n",
            "Iteration: 508\t Weight1: [7.94855882]\t Weight2: [2.49336654]\t Bias: [5.66998477]\t Cost: 16.374081447321327\n",
            "Iteration: 509\t Weight1: [7.95125515]\t Weight2: [2.49120251]\t Bias: [5.65961037]\t Cost: 16.368112345067633\n",
            "Iteration: 510\t Weight1: [7.95394536]\t Weight2: [2.48903936]\t Bias: [5.64927261]\t Cost: 16.362182953401888\n",
            "Iteration: 511\t Weight1: [7.95662947]\t Weight2: [2.4868771]\t Bias: [5.63897136]\t Cost: 16.35629299771193\n",
            "Iteration: 512\t Weight1: [7.95930748]\t Weight2: [2.48471576]\t Bias: [5.62870648]\t Cost: 16.350442205348582\n",
            "Iteration: 513\t Weight1: [7.9619794]\t Weight2: [2.48255534]\t Bias: [5.61847783]\t Cost: 16.344630305611346\n",
            "Iteration: 514\t Weight1: [7.96464526]\t Weight2: [2.48039586]\t Bias: [5.60828529]\t Cost: 16.338857029733965\n",
            "Iteration: 515\t Weight1: [7.96730506]\t Weight2: [2.47823735]\t Bias: [5.59812873]\t Cost: 16.333122110870384\n",
            "Iteration: 516\t Weight1: [7.96995881]\t Weight2: [2.47607981]\t Bias: [5.58800801]\t Cost: 16.327425284080526\n",
            "Iteration: 517\t Weight1: [7.97260653]\t Weight2: [2.47392327]\t Bias: [5.577923]\t Cost: 16.321766286316386\n",
            "Iteration: 518\t Weight1: [7.97524823]\t Weight2: [2.47176773]\t Bias: [5.56787358]\t Cost: 16.316144856408116\n",
            "Iteration: 519\t Weight1: [7.97788392]\t Weight2: [2.46961321]\t Bias: [5.55785962]\t Cost: 16.31056073505029\n",
            "Iteration: 520\t Weight1: [7.98051362]\t Weight2: [2.46745973]\t Bias: [5.54788098]\t Cost: 16.305013664788177\n",
            "Iteration: 521\t Weight1: [7.98313733]\t Weight2: [2.4653073]\t Bias: [5.53793754]\t Cost: 16.299503390004194\n",
            "Iteration: 522\t Weight1: [7.98575507]\t Weight2: [2.46315595]\t Bias: [5.52802916]\t Cost: 16.29402965690449\n",
            "Iteration: 523\t Weight1: [7.98836685]\t Weight2: [2.46100567]\t Bias: [5.51815573]\t Cost: 16.28859221350548\n",
            "Iteration: 524\t Weight1: [7.99097268]\t Weight2: [2.4588565]\t Bias: [5.50831712]\t Cost: 16.283190809620695\n",
            "Iteration: 525\t Weight1: [7.99357257]\t Weight2: [2.45670843]\t Bias: [5.49851319]\t Cost: 16.277825196847495\n",
            "Iteration: 526\t Weight1: [7.99616654]\t Weight2: [2.4545615]\t Bias: [5.48874383]\t Cost: 16.272495128554084\n",
            "Iteration: 527\t Weight1: [7.99875461]\t Weight2: [2.45241571]\t Bias: [5.4790089]\t Cost: 16.267200359866482\n",
            "Iteration: 528\t Weight1: [8.00133677]\t Weight2: [2.45027107]\t Bias: [5.46930829]\t Cost: 16.26194064765573\n",
            "Iteration: 529\t Weight1: [8.00391304]\t Weight2: [2.44812761]\t Bias: [5.45964186]\t Cost: 16.256715750525036\n",
            "Iteration: 530\t Weight1: [8.00648344]\t Weight2: [2.44598533]\t Bias: [5.4500095]\t Cost: 16.251525428797095\n",
            "Iteration: 531\t Weight1: [8.00904798]\t Weight2: [2.44384425]\t Bias: [5.44041108]\t Cost: 16.246369444501546\n",
            "Iteration: 532\t Weight1: [8.01160666]\t Weight2: [2.44170439]\t Bias: [5.43084647]\t Cost: 16.24124756136246\n",
            "Iteration: 533\t Weight1: [8.01415951]\t Weight2: [2.43956575]\t Bias: [5.42131556]\t Cost: 16.23615954478593\n",
            "Iteration: 534\t Weight1: [8.01670653]\t Weight2: [2.43742836]\t Bias: [5.41181822]\t Cost: 16.231105161847786\n",
            "Iteration: 535\t Weight1: [8.01924773]\t Weight2: [2.43529222]\t Bias: [5.40235433]\t Cost: 16.22608418128133\n",
            "Iteration: 536\t Weight1: [8.02178313]\t Weight2: [2.43315735]\t Bias: [5.39292376]\t Cost: 16.221096373465247\n",
            "Iteration: 537\t Weight1: [8.02431274]\t Weight2: [2.43102376]\t Bias: [5.38352641]\t Cost: 16.216141510411617\n",
            "Iteration: 538\t Weight1: [8.02683657]\t Weight2: [2.42889147]\t Bias: [5.37416214]\t Cost: 16.211219365753873\n",
            "Iteration: 539\t Weight1: [8.02935463]\t Weight2: [2.42676049]\t Bias: [5.36483084]\t Cost: 16.206329714734988\n",
            "Iteration: 540\t Weight1: [8.03186694]\t Weight2: [2.42463083]\t Bias: [5.35553238]\t Cost: 16.201472334195778\n",
            "Iteration: 541\t Weight1: [8.0343735]\t Weight2: [2.42250251]\t Bias: [5.34626665]\t Cost: 16.196647002563093\n",
            "Iteration: 542\t Weight1: [8.03687433]\t Weight2: [2.42037554]\t Bias: [5.33703353]\t Cost: 16.191853499838327\n",
            "Iteration: 543\t Weight1: [8.03936944]\t Weight2: [2.41824993]\t Bias: [5.3278329]\t Cost: 16.18709160758589\n",
            "Iteration: 544\t Weight1: [8.04185884]\t Weight2: [2.41612569]\t Bias: [5.31866465]\t Cost: 16.182361108921768\n",
            "Iteration: 545\t Weight1: [8.04434255]\t Weight2: [2.41400285]\t Bias: [5.30952865]\t Cost: 16.1776617885022\n",
            "Iteration: 546\t Weight1: [8.04682057]\t Weight2: [2.4118814]\t Bias: [5.30042479]\t Cost: 16.17299343251243\n",
            "Iteration: 547\t Weight1: [8.04929292]\t Weight2: [2.40976137]\t Bias: [5.29135295]\t Cost: 16.168355828655553\n",
            "Iteration: 548\t Weight1: [8.0517596]\t Weight2: [2.40764276]\t Bias: [5.28231301]\t Cost: 16.16374876614141\n",
            "Iteration: 549\t Weight1: [8.05422064]\t Weight2: [2.40552559]\t Bias: [5.27330487]\t Cost: 16.159172035675628\n",
            "Iteration: 550\t Weight1: [8.05667604]\t Weight2: [2.40340987]\t Bias: [5.2643284]\t Cost: 16.154625429448654\n",
            "Iteration: 551\t Weight1: [8.05912581]\t Weight2: [2.40129561]\t Bias: [5.2553835]\t Cost: 16.150108741124935\n",
            "Iteration: 552\t Weight1: [8.06156996]\t Weight2: [2.39918283]\t Bias: [5.24647003]\t Cost: 16.1456217658322\n",
            "Iteration: 553\t Weight1: [8.06400852]\t Weight2: [2.39707153]\t Bias: [5.2375879]\t Cost: 16.141164300150738\n",
            "Iteration: 554\t Weight1: [8.06644148]\t Weight2: [2.39496174]\t Bias: [5.22873699]\t Cost: 16.136736142102812\n",
            "Iteration: 555\t Weight1: [8.06886886]\t Weight2: [2.39285345]\t Bias: [5.21991718]\t Cost: 16.13233709114219\n",
            "Iteration: 556\t Weight1: [8.07129068]\t Weight2: [2.39074668]\t Bias: [5.21112837]\t Cost: 16.127966948143634\n",
            "Iteration: 557\t Weight1: [8.07370693]\t Weight2: [2.38864145]\t Bias: [5.20237043]\t Cost: 16.123625515392582\n",
            "Iteration: 558\t Weight1: [8.07611764]\t Weight2: [2.38653777]\t Bias: [5.19364327]\t Cost: 16.11931259657486\n",
            "Iteration: 559\t Weight1: [8.07852282]\t Weight2: [2.38443564]\t Bias: [5.18494676]\t Cost: 16.115027996766507\n",
            "Iteration: 560\t Weight1: [8.08092248]\t Weight2: [2.38233508]\t Bias: [5.17628079]\t Cost: 16.110771522423573\n",
            "Iteration: 561\t Weight1: [8.08331662]\t Weight2: [2.38023609]\t Bias: [5.16764527]\t Cost: 16.10654298137212\n",
            "Iteration: 562\t Weight1: [8.08570527]\t Weight2: [2.3781387]\t Bias: [5.15904006]\t Cost: 16.10234218279823\n",
            "Iteration: 563\t Weight1: [8.08808842]\t Weight2: [2.37604291]\t Bias: [5.15046507]\t Cost: 16.098168937238054\n",
            "Iteration: 564\t Weight1: [8.0904661]\t Weight2: [2.37394873]\t Bias: [5.14192019]\t Cost: 16.09402305656814\n",
            "Iteration: 565\t Weight1: [8.09283832]\t Weight2: [2.37185618]\t Bias: [5.1334053]\t Cost: 16.089904353995422\n",
            "Iteration: 566\t Weight1: [8.09520508]\t Weight2: [2.36976526]\t Bias: [5.12492031]\t Cost: 16.085812644047753\n",
            "Iteration: 567\t Weight1: [8.0975664]\t Weight2: [2.36767599]\t Bias: [5.11646509]\t Cost: 16.081747742564193\n",
            "Iteration: 568\t Weight1: [8.09992229]\t Weight2: [2.36558837]\t Bias: [5.10803954]\t Cost: 16.077709466685473\n",
            "Iteration: 569\t Weight1: [8.10227276]\t Weight2: [2.36350241]\t Bias: [5.09964356]\t Cost: 16.07369763484451\n",
            "Iteration: 570\t Weight1: [8.10461782]\t Weight2: [2.36141814]\t Bias: [5.09127704]\t Cost: 16.069712066757116\n",
            "Iteration: 571\t Weight1: [8.10695748]\t Weight2: [2.35933555]\t Bias: [5.08293986]\t Cost: 16.065752583412458\n",
            "Iteration: 572\t Weight1: [8.10929176]\t Weight2: [2.35725466]\t Bias: [5.07463194]\t Cost: 16.061819007064052\n",
            "Iteration: 573\t Weight1: [8.11162066]\t Weight2: [2.35517547]\t Bias: [5.06635315]\t Cost: 16.05791116122031\n",
            "Iteration: 574\t Weight1: [8.1139442]\t Weight2: [2.35309801]\t Bias: [5.05810339]\t Cost: 16.054028870635662\n",
            "Iteration: 575\t Weight1: [8.11626238]\t Weight2: [2.35102227]\t Bias: [5.04988257]\t Cost: 16.05017196130131\n",
            "Iteration: 576\t Weight1: [8.11857523]\t Weight2: [2.34894827]\t Bias: [5.04169057]\t Cost: 16.04634026043633\n",
            "Iteration: 577\t Weight1: [8.12088275]\t Weight2: [2.34687602]\t Bias: [5.03352728]\t Cost: 16.042533596478744\n",
            "Iteration: 578\t Weight1: [8.12318494]\t Weight2: [2.34480552]\t Bias: [5.02539262]\t Cost: 16.038751799076632\n",
            "Iteration: 579\t Weight1: [8.12548183]\t Weight2: [2.34273679]\t Bias: [5.01728646]\t Cost: 16.034994699079373\n",
            "Iteration: 580\t Weight1: [8.12777343]\t Weight2: [2.34066984]\t Bias: [5.00920872]\t Cost: 16.03126212852895\n",
            "Iteration: 581\t Weight1: [8.13005974]\t Weight2: [2.33860468]\t Bias: [5.00115928]\t Cost: 16.027553920651197\n",
            "Iteration: 582\t Weight1: [8.13234077]\t Weight2: [2.33654131]\t Bias: [4.99313805]\t Cost: 16.02386990984724\n",
            "Iteration: 583\t Weight1: [8.13461654]\t Weight2: [2.33447975]\t Bias: [4.98514492]\t Cost: 16.020209931685066\n",
            "Iteration: 584\t Weight1: [8.13688706]\t Weight2: [2.33242]\t Bias: [4.97717979]\t Cost: 16.01657382289092\n",
            "Iteration: 585\t Weight1: [8.13915234]\t Weight2: [2.33036208]\t Bias: [4.96924256]\t Cost: 16.012961421340922\n",
            "Iteration: 586\t Weight1: [8.14141239]\t Weight2: [2.32830599]\t Bias: [4.96133312]\t Cost: 16.00937256605282\n",
            "Iteration: 587\t Weight1: [8.14366721]\t Weight2: [2.32625174]\t Bias: [4.95345139]\t Cost: 16.005807097177616\n",
            "Iteration: 588\t Weight1: [8.14591683]\t Weight2: [2.32419934]\t Bias: [4.94559726]\t Cost: 16.00226485599135\n",
            "Iteration: 589\t Weight1: [8.14816126]\t Weight2: [2.3221488]\t Bias: [4.93777062]\t Cost: 15.998745684886996\n",
            "Iteration: 590\t Weight1: [8.1504005]\t Weight2: [2.32010013]\t Bias: [4.92997138]\t Cost: 15.995249427366328\n",
            "Iteration: 591\t Weight1: [8.15263456]\t Weight2: [2.31805334]\t Bias: [4.92219944]\t Cost: 15.99177592803186\n",
            "Iteration: 592\t Weight1: [8.15486346]\t Weight2: [2.31600844]\t Bias: [4.91445471]\t Cost: 15.988325032578969\n",
            "Iteration: 593\t Weight1: [8.1570872]\t Weight2: [2.31396543]\t Bias: [4.90673708]\t Cost: 15.98489658778781\n",
            "Iteration: 594\t Weight1: [8.1593058]\t Weight2: [2.31192432]\t Bias: [4.89904645]\t Cost: 15.981490441515618\n",
            "Iteration: 595\t Weight1: [8.16151927]\t Weight2: [2.30988513]\t Bias: [4.89138273]\t Cost: 15.9781064426888\n",
            "Iteration: 596\t Weight1: [8.16372762]\t Weight2: [2.30784786]\t Bias: [4.88374583]\t Cost: 15.974744441295254\n",
            "Iteration: 597\t Weight1: [8.16593086]\t Weight2: [2.30581251]\t Bias: [4.87613563]\t Cost: 15.971404288376622\n",
            "Iteration: 598\t Weight1: [8.168129]\t Weight2: [2.30377911]\t Bias: [4.86855206]\t Cost: 15.968085836020748\n",
            "Iteration: 599\t Weight1: [8.17032205]\t Weight2: [2.30174765]\t Bias: [4.860995]\t Cost: 15.964788937354015\n",
            "Iteration: 600\t Weight1: [8.17251003]\t Weight2: [2.29971814]\t Bias: [4.85346437]\t Cost: 15.961513446533829\n",
            "Iteration: 601\t Weight1: [8.17469293]\t Weight2: [2.29769059]\t Bias: [4.84596008]\t Cost: 15.958259218741286\n",
            "Iteration: 602\t Weight1: [8.17687078]\t Weight2: [2.29566501]\t Bias: [4.83848202]\t Cost: 15.955026110173604\n",
            "Iteration: 603\t Weight1: [8.17904359]\t Weight2: [2.29364141]\t Bias: [4.83103009]\t Cost: 15.951813978036878\n",
            "Iteration: 604\t Weight1: [8.18121136]\t Weight2: [2.2916198]\t Bias: [4.82360422]\t Cost: 15.948622680538723\n",
            "Iteration: 605\t Weight1: [8.1833741]\t Weight2: [2.28960018]\t Bias: [4.8162043]\t Cost: 15.945452076881045\n",
            "Iteration: 606\t Weight1: [8.18553184]\t Weight2: [2.28758255]\t Bias: [4.80883023]\t Cost: 15.942302027252921\n",
            "Iteration: 607\t Weight1: [8.18768457]\t Weight2: [2.28556694]\t Bias: [4.80148194]\t Cost: 15.939172392823348\n",
            "Iteration: 608\t Weight1: [8.1898323]\t Weight2: [2.28355334]\t Bias: [4.79415931]\t Cost: 15.936063035734241\n",
            "Iteration: 609\t Weight1: [8.19197506]\t Weight2: [2.28154177]\t Bias: [4.78686227]\t Cost: 15.932973819093387\n",
            "Iteration: 610\t Weight1: [8.19411284]\t Weight2: [2.27953222]\t Bias: [4.77959071]\t Cost: 15.929904606967426\n",
            "Iteration: 611\t Weight1: [8.19624567]\t Weight2: [2.27752471]\t Bias: [4.77234455]\t Cost: 15.926855264375021\n",
            "Iteration: 612\t Weight1: [8.19837354]\t Weight2: [2.27551925]\t Bias: [4.76512369]\t Cost: 15.923825657279842\n",
            "Iteration: 613\t Weight1: [8.20049647]\t Weight2: [2.27351584]\t Bias: [4.75792805]\t Cost: 15.92081565258388\n",
            "Iteration: 614\t Weight1: [8.20261448]\t Weight2: [2.27151449]\t Bias: [4.75075753]\t Cost: 15.917825118120575\n",
            "Iteration: 615\t Weight1: [8.20472756]\t Weight2: [2.26951521]\t Bias: [4.74361204]\t Cost: 15.914853922648145\n",
            "Iteration: 616\t Weight1: [8.20683574]\t Weight2: [2.267518]\t Bias: [4.73649149]\t Cost: 15.911901935842916\n",
            "Iteration: 617\t Weight1: [8.20893902]\t Weight2: [2.26552287]\t Bias: [4.7293958]\t Cost: 15.908969028292601\n",
            "Iteration: 618\t Weight1: [8.21103741]\t Weight2: [2.26352982]\t Bias: [4.72232487]\t Cost: 15.906055071489904\n",
            "Iteration: 619\t Weight1: [8.21313093]\t Weight2: [2.26153887]\t Bias: [4.71527861]\t Cost: 15.903159937825805\n",
            "Iteration: 620\t Weight1: [8.21521958]\t Weight2: [2.25955002]\t Bias: [4.70825693]\t Cost: 15.900283500583232\n",
            "Iteration: 621\t Weight1: [8.21730337]\t Weight2: [2.25756328]\t Bias: [4.70125975]\t Cost: 15.89742563393047\n",
            "Iteration: 622\t Weight1: [8.21938232]\t Weight2: [2.25557866]\t Bias: [4.69428698]\t Cost: 15.894586212914973\n",
            "Iteration: 623\t Weight1: [8.22145643]\t Weight2: [2.25359615]\t Bias: [4.68733852]\t Cost: 15.891765113456863\n",
            "Iteration: 624\t Weight1: [8.22352572]\t Weight2: [2.25161577]\t Bias: [4.6804143]\t Cost: 15.888962212342708\n",
            "Iteration: 625\t Weight1: [8.22559019]\t Weight2: [2.24963752]\t Bias: [4.67351422]\t Cost: 15.886177387219306\n",
            "Iteration: 626\t Weight1: [8.22764986]\t Weight2: [2.24766141]\t Bias: [4.6666382]\t Cost: 15.883410516587421\n",
            "Iteration: 627\t Weight1: [8.22970474]\t Weight2: [2.24568745]\t Bias: [4.65978615]\t Cost: 15.880661479795663\n",
            "Iteration: 628\t Weight1: [8.23175483]\t Weight2: [2.24371564]\t Bias: [4.65295799]\t Cost: 15.877930157034417\n",
            "Iteration: 629\t Weight1: [8.23380014]\t Weight2: [2.24174599]\t Bias: [4.64615363]\t Cost: 15.875216429329695\n",
            "Iteration: 630\t Weight1: [8.2358407]\t Weight2: [2.2397785]\t Bias: [4.63937297]\t Cost: 15.872520178537265\n",
            "Iteration: 631\t Weight1: [8.2378765]\t Weight2: [2.23781318]\t Bias: [4.63261595]\t Cost: 15.869841287336477\n",
            "Iteration: 632\t Weight1: [8.23990755]\t Weight2: [2.23585004]\t Bias: [4.62588247]\t Cost: 15.867179639224558\n",
            "Iteration: 633\t Weight1: [8.24193388]\t Weight2: [2.23388908]\t Bias: [4.61917244]\t Cost: 15.86453511851054\n",
            "Iteration: 634\t Weight1: [8.24395548]\t Weight2: [2.23193031]\t Bias: [4.61248579]\t Cost: 15.861907610309508\n",
            "Iteration: 635\t Weight1: [8.24597237]\t Weight2: [2.22997374]\t Bias: [4.60582243]\t Cost: 15.859297000536834\n",
            "Iteration: 636\t Weight1: [8.24798455]\t Weight2: [2.22801936]\t Bias: [4.59918228]\t Cost: 15.856703175902343\n",
            "Iteration: 637\t Weight1: [8.24999205]\t Weight2: [2.22606719]\t Bias: [4.59256525]\t Cost: 15.854126023904648\n",
            "Iteration: 638\t Weight1: [8.25199486]\t Weight2: [2.22411722]\t Bias: [4.58597125]\t Cost: 15.85156543282546\n",
            "Iteration: 639\t Weight1: [8.253993]\t Weight2: [2.22216948]\t Bias: [4.57940022]\t Cost: 15.849021291724045\n",
            "Iteration: 640\t Weight1: [8.25598647]\t Weight2: [2.22022395]\t Bias: [4.57285205]\t Cost: 15.846493490431406\n",
            "Iteration: 641\t Weight1: [8.2579753]\t Weight2: [2.21828066]\t Bias: [4.56632668]\t Cost: 15.843981919545072\n",
            "Iteration: 642\t Weight1: [8.25995948]\t Weight2: [2.21633959]\t Bias: [4.55982402]\t Cost: 15.841486470423284\n",
            "Iteration: 643\t Weight1: [8.26193903]\t Weight2: [2.21440077]\t Bias: [4.55334399]\t Cost: 15.83900703517974\n",
            "Iteration: 644\t Weight1: [8.26391395]\t Weight2: [2.21246418]\t Bias: [4.5468865]\t Cost: 15.836543506678039\n",
            "Iteration: 645\t Weight1: [8.26588427]\t Weight2: [2.21052985]\t Bias: [4.54045148]\t Cost: 15.834095778526402\n",
            "Iteration: 646\t Weight1: [8.26784998]\t Weight2: [2.20859777]\t Bias: [4.53403884]\t Cost: 15.831663745072232\n",
            "Iteration: 647\t Weight1: [8.2698111]\t Weight2: [2.20666794]\t Bias: [4.52764851]\t Cost: 15.8292473013969\n",
            "Iteration: 648\t Weight1: [8.27176764]\t Weight2: [2.20474038]\t Bias: [4.5212804]\t Cost: 15.826846343310393\n",
            "Iteration: 649\t Weight1: [8.2737196]\t Weight2: [2.20281509]\t Bias: [4.51493444]\t Cost: 15.824460767346139\n",
            "Iteration: 650\t Weight1: [8.27566701]\t Weight2: [2.20089207]\t Bias: [4.50861054]\t Cost: 15.822090470755835\n",
            "Iteration: 651\t Weight1: [8.27760985]\t Weight2: [2.19897133]\t Bias: [4.50230862]\t Cost: 15.819735351504232\n",
            "Iteration: 652\t Weight1: [8.27954816]\t Weight2: [2.19705288]\t Bias: [4.49602862]\t Cost: 15.817395308264082\n",
            "Iteration: 653\t Weight1: [8.28148193]\t Weight2: [2.19513671]\t Bias: [4.48977044]\t Cost: 15.815070240411014\n",
            "Iteration: 654\t Weight1: [8.28341118]\t Weight2: [2.19322283]\t Bias: [4.48353401]\t Cost: 15.812760048018566\n",
            "Iteration: 655\t Weight1: [8.28533591]\t Weight2: [2.19131125]\t Bias: [4.47731925]\t Cost: 15.81046463185311\n",
            "Iteration: 656\t Weight1: [8.28725614]\t Weight2: [2.18940197]\t Bias: [4.47112608]\t Cost: 15.808183893368914\n",
            "Iteration: 657\t Weight1: [8.28917188]\t Weight2: [2.187495]\t Bias: [4.46495444]\t Cost: 15.805917734703243\n",
            "Iteration: 658\t Weight1: [8.29108313]\t Weight2: [2.18559034]\t Bias: [4.45880423]\t Cost: 15.803666058671439\n",
            "Iteration: 659\t Weight1: [8.29298991]\t Weight2: [2.18368799]\t Bias: [4.45267538]\t Cost: 15.80142876876207\n",
            "Iteration: 660\t Weight1: [8.29489222]\t Weight2: [2.18178796]\t Bias: [4.44656782]\t Cost: 15.799205769132094\n",
            "Iteration: 661\t Weight1: [8.29679007]\t Weight2: [2.17989026]\t Bias: [4.44048146]\t Cost: 15.79699696460212\n",
            "Iteration: 662\t Weight1: [8.29868348]\t Weight2: [2.17799488]\t Bias: [4.43441624]\t Cost: 15.794802260651654\n",
            "Iteration: 663\t Weight1: [8.30057245]\t Weight2: [2.17610184]\t Bias: [4.42837208]\t Cost: 15.7926215634143\n",
            "Iteration: 664\t Weight1: [8.302457]\t Weight2: [2.17421113]\t Bias: [4.4223489]\t Cost: 15.790454779673176\n",
            "Iteration: 665\t Weight1: [8.30433713]\t Weight2: [2.17232277]\t Bias: [4.41634662]\t Cost: 15.78830181685628\n",
            "Iteration: 666\t Weight1: [8.30621285]\t Weight2: [2.17043675]\t Bias: [4.41036518]\t Cost: 15.786162583031778\n",
            "Iteration: 667\t Weight1: [8.30808417]\t Weight2: [2.16855307]\t Bias: [4.40440449]\t Cost: 15.78403698690352\n",
            "Iteration: 668\t Weight1: [8.30995111]\t Weight2: [2.16667175]\t Bias: [4.39846448]\t Cost: 15.781924937806453\n",
            "Iteration: 669\t Weight1: [8.31181367]\t Weight2: [2.16479279]\t Bias: [4.39254508]\t Cost: 15.779826345702109\n",
            "Iteration: 670\t Weight1: [8.31367185]\t Weight2: [2.16291618]\t Bias: [4.38664622]\t Cost: 15.777741121174158\n",
            "Iteration: 671\t Weight1: [8.31552568]\t Weight2: [2.16104194]\t Bias: [4.38076781]\t Cost: 15.775669175423936\n",
            "Iteration: 672\t Weight1: [8.31737516]\t Weight2: [2.15917007]\t Bias: [4.3749098]\t Cost: 15.773610420266063\n",
            "Iteration: 673\t Weight1: [8.31922029]\t Weight2: [2.15730057]\t Bias: [4.36907209]\t Cost: 15.771564768124023\n",
            "Iteration: 674\t Weight1: [8.32106109]\t Weight2: [2.15543344]\t Bias: [4.36325463]\t Cost: 15.76953213202583\n",
            "Iteration: 675\t Weight1: [8.32289758]\t Weight2: [2.15356869]\t Bias: [4.35745734]\t Cost: 15.767512425599783\n",
            "Iteration: 676\t Weight1: [8.32472975]\t Weight2: [2.15170633]\t Bias: [4.35168014]\t Cost: 15.765505563070024\n",
            "Iteration: 677\t Weight1: [8.32655761]\t Weight2: [2.14984635]\t Bias: [4.34592297]\t Cost: 15.763511459252474\n",
            "Iteration: 678\t Weight1: [8.32838118]\t Weight2: [2.14798876]\t Bias: [4.34018575]\t Cost: 15.761530029550455\n",
            "Iteration: 679\t Weight1: [8.33020047]\t Weight2: [2.14613356]\t Bias: [4.33446841]\t Cost: 15.759561189950611\n",
            "Iteration: 680\t Weight1: [8.33201548]\t Weight2: [2.14428076]\t Bias: [4.32877088]\t Cost: 15.75760485701869\n",
            "Iteration: 681\t Weight1: [8.33382623]\t Weight2: [2.14243036]\t Bias: [4.32309309]\t Cost: 15.755660947895416\n",
            "Iteration: 682\t Weight1: [8.33563272]\t Weight2: [2.14058236]\t Bias: [4.31743496]\t Cost: 15.75372938029242\n",
            "Iteration: 683\t Weight1: [8.33743496]\t Weight2: [2.13873677]\t Bias: [4.31179644]\t Cost: 15.751810072488162\n",
            "Iteration: 684\t Weight1: [8.33923296]\t Weight2: [2.13689359]\t Bias: [4.30617744]\t Cost: 15.749902943323873\n",
            "Iteration: 685\t Weight1: [8.34102674]\t Weight2: [2.13505282]\t Bias: [4.3005779]\t Cost: 15.748007912199547\n",
            "Iteration: 686\t Weight1: [8.34281629]\t Weight2: [2.13321446]\t Bias: [4.29499775]\t Cost: 15.74612489907\n",
            "Iteration: 687\t Weight1: [8.34460164]\t Weight2: [2.13137852]\t Bias: [4.28943692]\t Cost: 15.74425382444086\n",
            "Iteration: 688\t Weight1: [8.34638278]\t Weight2: [2.12954501]\t Bias: [4.28389533]\t Cost: 15.742394609364707\n",
            "Iteration: 689\t Weight1: [8.34815973]\t Weight2: [2.12771392]\t Bias: [4.27837293]\t Cost: 15.74054717543716\n",
            "Iteration: 690\t Weight1: [8.3499325]\t Weight2: [2.12588525]\t Bias: [4.27286964]\t Cost: 15.738711444792953\n",
            "Iteration: 691\t Weight1: [8.3517011]\t Weight2: [2.12405902]\t Bias: [4.26738539]\t Cost: 15.736887340102193\n",
            "Iteration: 692\t Weight1: [8.35346553]\t Weight2: [2.12223522]\t Bias: [4.26192012]\t Cost: 15.735074784566486\n",
            "Iteration: 693\t Weight1: [8.35522581]\t Weight2: [2.12041386]\t Bias: [4.25647375]\t Cost: 15.733273701915177\n",
            "Iteration: 694\t Weight1: [8.35698193]\t Weight2: [2.11859493]\t Bias: [4.25104623]\t Cost: 15.731484016401643\n",
            "Iteration: 695\t Weight1: [8.35873393]\t Weight2: [2.11677845]\t Bias: [4.24563748]\t Cost: 15.729705652799451\n",
            "Iteration: 696\t Weight1: [8.36048179]\t Weight2: [2.11496441]\t Bias: [4.24024743]\t Cost: 15.727938536398783\n",
            "Iteration: 697\t Weight1: [8.36222553]\t Weight2: [2.11315281]\t Bias: [4.23487602]\t Cost: 15.726182593002692\n",
            "Iteration: 698\t Weight1: [8.36396517]\t Weight2: [2.11134367]\t Bias: [4.22952318]\t Cost: 15.724437748923483\n",
            "Iteration: 699\t Weight1: [8.3657007]\t Weight2: [2.10953698]\t Bias: [4.22418885]\t Cost: 15.722703930979117\n",
            "Iteration: 700\t Weight1: [8.36743214]\t Weight2: [2.10773274]\t Bias: [4.21887296]\t Cost: 15.720981066489555\n",
            "Iteration: 701\t Weight1: [8.3691595]\t Weight2: [2.10593096]\t Bias: [4.21357544]\t Cost: 15.719269083273238\n",
            "Iteration: 702\t Weight1: [8.37088279]\t Weight2: [2.10413163]\t Bias: [4.20829623]\t Cost: 15.717567909643584\n",
            "Iteration: 703\t Weight1: [8.372602]\t Weight2: [2.10233477]\t Bias: [4.20303526]\t Cost: 15.715877474405405\n",
            "Iteration: 704\t Weight1: [8.37431717]\t Weight2: [2.10054038]\t Bias: [4.19779247]\t Cost: 15.714197706851438\n",
            "Iteration: 705\t Weight1: [8.37602828]\t Weight2: [2.09874844]\t Bias: [4.19256779]\t Cost: 15.712528536758924\n",
            "Iteration: 706\t Weight1: [8.37773536]\t Weight2: [2.09695898]\t Bias: [4.18736115]\t Cost: 15.7108698943861\n",
            "Iteration: 707\t Weight1: [8.37943841]\t Weight2: [2.09517199]\t Bias: [4.1821725]\t Cost: 15.709221710468865\n",
            "Iteration: 708\t Weight1: [8.38113743]\t Weight2: [2.09338747]\t Bias: [4.17700177]\t Cost: 15.707583916217345\n",
            "Iteration: 709\t Weight1: [8.38283245]\t Weight2: [2.09160543]\t Bias: [4.1718489]\t Cost: 15.705956443312544\n",
            "Iteration: 710\t Weight1: [8.38452346]\t Weight2: [2.08982586]\t Bias: [4.16671381]\t Cost: 15.704339223903004\n",
            "Iteration: 711\t Weight1: [8.38621047]\t Weight2: [2.08804877]\t Bias: [4.16159645]\t Cost: 15.702732190601477\n",
            "Iteration: 712\t Weight1: [8.38789351]\t Weight2: [2.08627416]\t Bias: [4.15649676]\t Cost: 15.70113527648169\n",
            "Iteration: 713\t Weight1: [8.38957256]\t Weight2: [2.08450204]\t Bias: [4.15141466]\t Cost: 15.699548415075013\n",
            "Iteration: 714\t Weight1: [8.39124765]\t Weight2: [2.0827324]\t Bias: [4.14635011]\t Cost: 15.697971540367233\n",
            "Iteration: 715\t Weight1: [8.39291878]\t Weight2: [2.08096525]\t Bias: [4.14130303]\t Cost: 15.6964045867954\n",
            "Iteration: 716\t Weight1: [8.39458595]\t Weight2: [2.07920058]\t Bias: [4.13627336]\t Cost: 15.694847489244536\n",
            "Iteration: 717\t Weight1: [8.39624919]\t Weight2: [2.07743841]\t Bias: [4.13126104]\t Cost: 15.69330018304454\n",
            "Iteration: 718\t Weight1: [8.39790849]\t Weight2: [2.07567873]\t Bias: [4.12626602]\t Cost: 15.691762603966978\n",
            "Iteration: 719\t Weight1: [8.39956387]\t Weight2: [2.07392154]\t Bias: [4.12128822]\t Cost: 15.69023468822203\n",
            "Iteration: 720\t Weight1: [8.40121533]\t Weight2: [2.07216685]\t Bias: [4.11632758]\t Cost: 15.688716372455348\n",
            "Iteration: 721\t Weight1: [8.40286289]\t Weight2: [2.07041466]\t Bias: [4.11138406]\t Cost: 15.687207593744933\n",
            "Iteration: 722\t Weight1: [8.40450655]\t Weight2: [2.06866496]\t Bias: [4.10645757]\t Cost: 15.68570828959818\n",
            "Iteration: 723\t Weight1: [8.40614632]\t Weight2: [2.06691777]\t Bias: [4.10154807]\t Cost: 15.684218397948719\n",
            "Iteration: 724\t Weight1: [8.4077822]\t Weight2: [2.06517308]\t Bias: [4.09665549]\t Cost: 15.682737857153553\n",
            "Iteration: 725\t Weight1: [8.40941422]\t Weight2: [2.06343089]\t Bias: [4.09177977]\t Cost: 15.68126660598991\n",
            "Iteration: 726\t Weight1: [8.41104237]\t Weight2: [2.06169121]\t Bias: [4.08692085]\t Cost: 15.679804583652377\n",
            "Iteration: 727\t Weight1: [8.41266666]\t Weight2: [2.05995403]\t Bias: [4.08207868]\t Cost: 15.67835172974993\n",
            "Iteration: 728\t Weight1: [8.41428711]\t Weight2: [2.05821937]\t Bias: [4.07725318]\t Cost: 15.676907984302968\n",
            "Iteration: 729\t Weight1: [8.41590372]\t Weight2: [2.05648721]\t Bias: [4.07244431]\t Cost: 15.675473287740497\n",
            "Iteration: 730\t Weight1: [8.4175165]\t Weight2: [2.05475756]\t Bias: [4.06765201]\t Cost: 15.674047580897135\n",
            "Iteration: 731\t Weight1: [8.41912545]\t Weight2: [2.05303043]\t Bias: [4.0628762]\t Cost: 15.672630805010341\n",
            "Iteration: 732\t Weight1: [8.4207306]\t Weight2: [2.05130581]\t Bias: [4.05811685]\t Cost: 15.671222901717499\n",
            "Iteration: 733\t Weight1: [8.42233194]\t Weight2: [2.0495837]\t Bias: [4.05337388]\t Cost: 15.669823813053172\n",
            "Iteration: 734\t Weight1: [8.42392948]\t Weight2: [2.04786411]\t Bias: [4.04864724]\t Cost: 15.668433481446236\n",
            "Iteration: 735\t Weight1: [8.42552324]\t Weight2: [2.04614704]\t Bias: [4.04393687]\t Cost: 15.667051849717154\n",
            "Iteration: 736\t Weight1: [8.42711321]\t Weight2: [2.04443248]\t Bias: [4.03924271]\t Cost: 15.66567886107514\n",
            "Iteration: 737\t Weight1: [8.42869942]\t Weight2: [2.04272045]\t Bias: [4.0345647]\t Cost: 15.664314459115527\n",
            "Iteration: 738\t Weight1: [8.43028186]\t Weight2: [2.04101093]\t Bias: [4.0299028]\t Cost: 15.662958587816929\n",
            "Iteration: 739\t Weight1: [8.43186055]\t Weight2: [2.03930394]\t Bias: [4.02525693]\t Cost: 15.661611191538668\n",
            "Iteration: 740\t Weight1: [8.4334355]\t Weight2: [2.03759947]\t Bias: [4.02062705]\t Cost: 15.660272215017958\n",
            "Iteration: 741\t Weight1: [8.4350067]\t Weight2: [2.03589752]\t Bias: [4.01601309]\t Cost: 15.658941603367321\n",
            "Iteration: 742\t Weight1: [8.43657418]\t Weight2: [2.0341981]\t Bias: [4.011415]\t Cost: 15.657619302071973\n",
            "Iteration: 743\t Weight1: [8.43813794]\t Weight2: [2.0325012]\t Bias: [4.00683272]\t Cost: 15.656305256987094\n",
            "Iteration: 744\t Weight1: [8.43969798]\t Weight2: [2.03080683]\t Bias: [4.0022662]\t Cost: 15.654999414335368\n",
            "Iteration: 745\t Weight1: [8.44125432]\t Weight2: [2.02911499]\t Bias: [3.99771538]\t Cost: 15.653701720704259\n",
            "Iteration: 746\t Weight1: [8.44280696]\t Weight2: [2.02742568]\t Bias: [3.99318021]\t Cost: 15.65241212304352\n",
            "Iteration: 747\t Weight1: [8.44435592]\t Weight2: [2.02573889]\t Bias: [3.98866062]\t Cost: 15.651130568662657\n",
            "Iteration: 748\t Weight1: [8.44590119]\t Weight2: [2.02405463]\t Bias: [3.98415657]\t Cost: 15.649857005228329\n",
            "Iteration: 749\t Weight1: [8.4474428]\t Weight2: [2.02237291]\t Bias: [3.97966799]\t Cost: 15.64859138076194\n",
            "Iteration: 750\t Weight1: [8.44898074]\t Weight2: [2.02069371]\t Bias: [3.97519484]\t Cost: 15.647333643637017\n",
            "Iteration: 751\t Weight1: [8.45051502]\t Weight2: [2.01901705]\t Bias: [3.97073706]\t Cost: 15.646083742576872\n",
            "Iteration: 752\t Weight1: [8.45204566]\t Weight2: [2.01734292]\t Bias: [3.96629458]\t Cost: 15.644841626652047\n",
            "Iteration: 753\t Weight1: [8.45357266]\t Weight2: [2.01567132]\t Bias: [3.96186737]\t Cost: 15.643607245277893\n",
            "Iteration: 754\t Weight1: [8.45509603]\t Weight2: [2.01400225]\t Bias: [3.95745536]\t Cost: 15.64238054821219\n",
            "Iteration: 755\t Weight1: [8.45661578]\t Weight2: [2.01233572]\t Bias: [3.95305851]\t Cost: 15.64116148555271\n",
            "Iteration: 756\t Weight1: [8.45813191]\t Weight2: [2.01067173]\t Bias: [3.94867675]\t Cost: 15.639950007734827\n",
            "Iteration: 757\t Weight1: [8.45964443]\t Weight2: [2.00901027]\t Bias: [3.94431003]\t Cost: 15.638746065529146\n",
            "Iteration: 758\t Weight1: [8.46115336]\t Weight2: [2.00735134]\t Bias: [3.9399583]\t Cost: 15.637549610039216\n",
            "Iteration: 759\t Weight1: [8.46265869]\t Weight2: [2.00569495]\t Bias: [3.93562151]\t Cost: 15.636360592699061\n",
            "Iteration: 760\t Weight1: [8.46416045]\t Weight2: [2.0040411]\t Bias: [3.93129961]\t Cost: 15.635178965271008\n",
            "Iteration: 761\t Weight1: [8.46565863]\t Weight2: [2.00238979]\t Bias: [3.92699253]\t Cost: 15.6340046798433\n",
            "Iteration: 762\t Weight1: [8.46715324]\t Weight2: [2.00074101]\t Bias: [3.92270023]\t Cost: 15.632837688827788\n",
            "Iteration: 763\t Weight1: [8.4686443]\t Weight2: [1.99909477]\t Bias: [3.91842265]\t Cost: 15.631677944957776\n",
            "Iteration: 764\t Weight1: [8.4701318]\t Weight2: [1.99745106]\t Bias: [3.91415975]\t Cost: 15.630525401285652\n",
            "Iteration: 765\t Weight1: [8.47161576]\t Weight2: [1.9958099]\t Bias: [3.90991147]\t Cost: 15.629380011180704\n",
            "Iteration: 766\t Weight1: [8.47309619]\t Weight2: [1.99417127]\t Bias: [3.90567776]\t Cost: 15.628241728326914\n",
            "Iteration: 767\t Weight1: [8.47457309]\t Weight2: [1.99253518]\t Bias: [3.90145856]\t Cost: 15.627110506720717\n",
            "Iteration: 768\t Weight1: [8.47604647]\t Weight2: [1.99090163]\t Bias: [3.89725384]\t Cost: 15.62598630066884\n",
            "Iteration: 769\t Weight1: [8.47751634]\t Weight2: [1.98927062]\t Bias: [3.89306352]\t Cost: 15.624869064786116\n",
            "Iteration: 770\t Weight1: [8.47898271]\t Weight2: [1.98764215]\t Bias: [3.88888757]\t Cost: 15.623758753993346\n",
            "Iteration: 771\t Weight1: [8.48044558]\t Weight2: [1.98601622]\t Bias: [3.88472593]\t Cost: 15.622655323515152\n",
            "Iteration: 772\t Weight1: [8.48190496]\t Weight2: [1.98439283]\t Bias: [3.88057855]\t Cost: 15.621558728877808\n",
            "Iteration: 773\t Weight1: [8.48336087]\t Weight2: [1.98277197]\t Bias: [3.87644538]\t Cost: 15.620468925907225\n",
            "Iteration: 774\t Weight1: [8.4848133]\t Weight2: [1.98115366]\t Bias: [3.87232637]\t Cost: 15.619385870726768\n",
            "Iteration: 775\t Weight1: [8.48626227]\t Weight2: [1.97953788]\t Bias: [3.86822148]\t Cost: 15.618309519755192\n",
            "Iteration: 776\t Weight1: [8.48770779]\t Weight2: [1.97792464]\t Bias: [3.86413064]\t Cost: 15.617239829704646\n",
            "Iteration: 777\t Weight1: [8.48914985]\t Weight2: [1.97631395]\t Bias: [3.86005381]\t Cost: 15.616176757578526\n",
            "Iteration: 778\t Weight1: [8.49058848]\t Weight2: [1.97470579]\t Bias: [3.85599094]\t Cost: 15.615120260669517\n",
            "Iteration: 779\t Weight1: [8.49202367]\t Weight2: [1.97310017]\t Bias: [3.85194199]\t Cost: 15.614070296557525\n",
            "Iteration: 780\t Weight1: [8.49345543]\t Weight2: [1.97149709]\t Bias: [3.84790689]\t Cost: 15.613026823107687\n",
            "Iteration: 781\t Weight1: [8.49488378]\t Weight2: [1.96989654]\t Bias: [3.84388561]\t Cost: 15.611989798468416\n",
            "Iteration: 782\t Weight1: [8.49630872]\t Weight2: [1.96829854]\t Bias: [3.83987809]\t Cost: 15.610959181069338\n",
            "Iteration: 783\t Weight1: [8.49773026]\t Weight2: [1.96670308]\t Bias: [3.83588428]\t Cost: 15.609934929619419\n",
            "Iteration: 784\t Weight1: [8.4991484]\t Weight2: [1.96511015]\t Bias: [3.83190414]\t Cost: 15.608917003104978\n",
            "Iteration: 785\t Weight1: [8.50056315]\t Weight2: [1.96351976]\t Bias: [3.82793762]\t Cost: 15.607905360787733\n",
            "Iteration: 786\t Weight1: [8.50197453]\t Weight2: [1.96193191]\t Bias: [3.82398467]\t Cost: 15.606899962202949\n",
            "Iteration: 787\t Weight1: [8.50338253]\t Weight2: [1.96034659]\t Bias: [3.82004524]\t Cost: 15.6059007671574\n",
            "Iteration: 788\t Weight1: [8.50478717]\t Weight2: [1.95876381]\t Bias: [3.81611928]\t Cost: 15.60490773572766\n",
            "Iteration: 789\t Weight1: [8.50618846]\t Weight2: [1.95718357]\t Bias: [3.81220675]\t Cost: 15.60392082825804\n",
            "Iteration: 790\t Weight1: [8.50758639]\t Weight2: [1.95560587]\t Bias: [3.80830759]\t Cost: 15.602940005358858\n",
            "Iteration: 791\t Weight1: [8.50898099]\t Weight2: [1.9540307]\t Bias: [3.80442177]\t Cost: 15.601965227904518\n",
            "Iteration: 792\t Weight1: [8.51037224]\t Weight2: [1.95245806]\t Bias: [3.80054923]\t Cost: 15.600996457031691\n",
            "Iteration: 793\t Weight1: [8.51176018]\t Weight2: [1.95088796]\t Bias: [3.79668992]\t Cost: 15.60003365413749\n",
            "Iteration: 794\t Weight1: [8.51314479]\t Weight2: [1.9493204]\t Bias: [3.79284381]\t Cost: 15.599076780877645\n",
            "Iteration: 795\t Weight1: [8.51452609]\t Weight2: [1.94775537]\t Bias: [3.78901083]\t Cost: 15.598125799164743\n",
            "Iteration: 796\t Weight1: [8.51590409]\t Weight2: [1.94619287]\t Bias: [3.78519096]\t Cost: 15.597180671166335\n",
            "Iteration: 797\t Weight1: [8.51727879]\t Weight2: [1.9446329]\t Bias: [3.78138413]\t Cost: 15.596241359303342\n",
            "Iteration: 798\t Weight1: [8.51865021]\t Weight2: [1.94307547]\t Bias: [3.77759031]\t Cost: 15.595307826248101\n",
            "Iteration: 799\t Weight1: [8.52001834]\t Weight2: [1.94152057]\t Bias: [3.77380944]\t Cost: 15.594380034922752\n",
            "Iteration: 800\t Weight1: [8.5213832]\t Weight2: [1.9399682]\t Bias: [3.77004149]\t Cost: 15.593457948497456\n",
            "Iteration: 801\t Weight1: [8.52274479]\t Weight2: [1.93841836]\t Bias: [3.7662864]\t Cost: 15.59254153038863\n",
            "Iteration: 802\t Weight1: [8.52410312]\t Weight2: [1.93687105]\t Bias: [3.76254413]\t Cost: 15.59163074425734\n",
            "Iteration: 803\t Weight1: [8.5254582]\t Weight2: [1.93532627]\t Bias: [3.75881464]\t Cost: 15.59072555400748\n",
            "Iteration: 804\t Weight1: [8.52681003]\t Weight2: [1.93378402]\t Bias: [3.75509788]\t Cost: 15.589825923784181\n",
            "Iteration: 805\t Weight1: [8.52815863]\t Weight2: [1.9322443]\t Bias: [3.7513938]\t Cost: 15.588931817972085\n",
            "Iteration: 806\t Weight1: [8.52950399]\t Weight2: [1.9307071]\t Bias: [3.74770237]\t Cost: 15.588043201193699\n",
            "Iteration: 807\t Weight1: [8.53084614]\t Weight2: [1.92917243]\t Bias: [3.74402353]\t Cost: 15.587160038307777\n",
            "Iteration: 808\t Weight1: [8.53218507]\t Weight2: [1.92764028]\t Bias: [3.74035724]\t Cost: 15.586282294407562\n",
            "Iteration: 809\t Weight1: [8.53352079]\t Weight2: [1.92611066]\t Bias: [3.73670345]\t Cost: 15.58540993481932\n",
            "Iteration: 810\t Weight1: [8.53485331]\t Weight2: [1.92458357]\t Bias: [3.73306213]\t Cost: 15.584542925100633\n",
            "Iteration: 811\t Weight1: [8.53618263]\t Weight2: [1.92305899]\t Bias: [3.72943323]\t Cost: 15.583681231038804\n",
            "Iteration: 812\t Weight1: [8.53750877]\t Weight2: [1.92153694]\t Bias: [3.7258167]\t Cost: 15.582824818649266\n",
            "Iteration: 813\t Weight1: [8.53883173]\t Weight2: [1.92001741]\t Bias: [3.7222125]\t Cost: 15.581973654174021\n",
            "Iteration: 814\t Weight1: [8.54015152]\t Weight2: [1.9185004]\t Bias: [3.71862059]\t Cost: 15.581127704080034\n",
            "Iteration: 815\t Weight1: [8.54146814]\t Weight2: [1.91698591]\t Bias: [3.71504092]\t Cost: 15.58028693505772\n",
            "Iteration: 816\t Weight1: [8.54278161]\t Weight2: [1.91547394]\t Bias: [3.71147345]\t Cost: 15.579451314019371\n",
            "Iteration: 817\t Weight1: [8.54409193]\t Weight2: [1.91396449]\t Bias: [3.70791814]\t Cost: 15.5786208080976\n",
            "Iteration: 818\t Weight1: [8.5453991]\t Weight2: [1.91245755]\t Bias: [3.70437494]\t Cost: 15.577795384643867\n",
            "Iteration: 819\t Weight1: [8.54670313]\t Weight2: [1.91095313]\t Bias: [3.70084382]\t Cost: 15.576975011226915\n",
            "Iteration: 820\t Weight1: [8.54800404]\t Weight2: [1.90945122]\t Bias: [3.69732472]\t Cost: 15.576159655631313\n",
            "Iteration: 821\t Weight1: [8.54930183]\t Weight2: [1.90795183]\t Bias: [3.69381761]\t Cost: 15.575349285855909\n",
            "Iteration: 822\t Weight1: [8.5505965]\t Weight2: [1.90645494]\t Bias: [3.69032245]\t Cost: 15.574543870112397\n",
            "Iteration: 823\t Weight1: [8.55188806]\t Weight2: [1.90496057]\t Bias: [3.68683918]\t Cost: 15.57374337682381\n",
            "Iteration: 824\t Weight1: [8.55317652]\t Weight2: [1.90346872]\t Bias: [3.68336778]\t Cost: 15.572947774623104\n",
            "Iteration: 825\t Weight1: [8.55446189]\t Weight2: [1.90197937]\t Bias: [3.67990819]\t Cost: 15.572157032351646\n",
            "Iteration: 826\t Weight1: [8.55574417]\t Weight2: [1.90049252]\t Bias: [3.67646038]\t Cost: 15.571371119057838\n",
            "Iteration: 827\t Weight1: [8.55702337]\t Weight2: [1.89900819]\t Bias: [3.67302431]\t Cost: 15.570590003995605\n",
            "Iteration: 828\t Weight1: [8.5582995]\t Weight2: [1.89752636]\t Bias: [3.66959993]\t Cost: 15.569813656623094\n",
            "Iteration: 829\t Weight1: [8.55957256]\t Weight2: [1.89604703]\t Bias: [3.6661872]\t Cost: 15.569042046601142\n",
            "Iteration: 830\t Weight1: [8.56084256]\t Weight2: [1.89457021]\t Bias: [3.66278608]\t Cost: 15.568275143791979\n",
            "Iteration: 831\t Weight1: [8.56210952]\t Weight2: [1.8930959]\t Bias: [3.65939653]\t Cost: 15.56751291825775\n",
            "Iteration: 832\t Weight1: [8.56337342]\t Weight2: [1.89162408]\t Bias: [3.65601851]\t Cost: 15.56675534025918\n",
            "Iteration: 833\t Weight1: [8.56463429]\t Weight2: [1.89015476]\t Bias: [3.65265198]\t Cost: 15.566002380254236\n",
            "Iteration: 834\t Weight1: [8.56589213]\t Weight2: [1.88868794]\t Bias: [3.6492969]\t Cost: 15.565254008896694\n",
            "Iteration: 835\t Weight1: [8.56714695]\t Weight2: [1.88722362]\t Bias: [3.64595322]\t Cost: 15.564510197034876\n",
            "Iteration: 836\t Weight1: [8.56839875]\t Weight2: [1.88576179]\t Bias: [3.64262092]\t Cost: 15.563770915710185\n",
            "Iteration: 837\t Weight1: [8.56964753]\t Weight2: [1.88430246]\t Bias: [3.63929994]\t Cost: 15.563036136155905\n",
            "Iteration: 838\t Weight1: [8.57089332]\t Weight2: [1.88284562]\t Bias: [3.63599024]\t Cost: 15.562305829795841\n",
            "Iteration: 839\t Weight1: [8.5721361]\t Weight2: [1.88139127]\t Bias: [3.6326918]\t Cost: 15.561579968242926\n",
            "Iteration: 840\t Weight1: [8.5733759]\t Weight2: [1.87993941]\t Bias: [3.62940456]\t Cost: 15.560858523298045\n",
            "Iteration: 841\t Weight1: [8.57461272]\t Weight2: [1.87849005]\t Bias: [3.62612849]\t Cost: 15.560141466948666\n",
            "Iteration: 842\t Weight1: [8.57584656]\t Weight2: [1.87704317]\t Bias: [3.62286355]\t Cost: 15.559428771367502\n",
            "Iteration: 843\t Weight1: [8.57707742]\t Weight2: [1.87559877]\t Bias: [3.61960971]\t Cost: 15.558720408911405\n",
            "Iteration: 844\t Weight1: [8.57830533]\t Weight2: [1.87415686]\t Bias: [3.61636691]\t Cost: 15.558016352119925\n",
            "Iteration: 845\t Weight1: [8.57953028]\t Weight2: [1.87271744]\t Bias: [3.61313512]\t Cost: 15.557316573714186\n",
            "Iteration: 846\t Weight1: [8.58075228]\t Weight2: [1.8712805]\t Bias: [3.60991431]\t Cost: 15.556621046595492\n",
            "Iteration: 847\t Weight1: [8.58197134]\t Weight2: [1.86984603]\t Bias: [3.60670443]\t Cost: 15.555929743844269\n",
            "Iteration: 848\t Weight1: [8.58318747]\t Weight2: [1.86841405]\t Bias: [3.60350545]\t Cost: 15.555242638718678\n",
            "Iteration: 849\t Weight1: [8.58440066]\t Weight2: [1.86698454]\t Bias: [3.60031732]\t Cost: 15.554559704653466\n",
            "Iteration: 850\t Weight1: [8.58561094]\t Weight2: [1.86555751]\t Bias: [3.59714002]\t Cost: 15.553880915258759\n",
            "Iteration: 851\t Weight1: [8.58681829]\t Weight2: [1.86413295]\t Bias: [3.5939735]\t Cost: 15.55320624431882\n",
            "Iteration: 852\t Weight1: [8.58802274]\t Weight2: [1.86271087]\t Bias: [3.59081772]\t Cost: 15.552535665790888\n",
            "Iteration: 853\t Weight1: [8.58922429]\t Weight2: [1.86129125]\t Bias: [3.58767264]\t Cost: 15.551869153803976\n",
            "Iteration: 854\t Weight1: [8.59042294]\t Weight2: [1.85987411]\t Bias: [3.58453823]\t Cost: 15.551206682657684\n",
            "Iteration: 855\t Weight1: [8.5916187]\t Weight2: [1.85845944]\t Bias: [3.58141446]\t Cost: 15.550548226821055\n",
            "Iteration: 856\t Weight1: [8.59281158]\t Weight2: [1.85704723]\t Bias: [3.57830128]\t Cost: 15.549893760931367\n",
            "Iteration: 857\t Weight1: [8.59400159]\t Weight2: [1.85563748]\t Bias: [3.57519865]\t Cost: 15.549243259793027\n",
            "Iteration: 858\t Weight1: [8.59518872]\t Weight2: [1.8542302]\t Bias: [3.57210654]\t Cost: 15.548596698376402\n",
            "Iteration: 859\t Weight1: [8.596373]\t Weight2: [1.85282538]\t Bias: [3.56902491]\t Cost: 15.547954051816685\n",
            "Iteration: 860\t Weight1: [8.59755441]\t Weight2: [1.85142302]\t Bias: [3.56595373]\t Cost: 15.547315295412773\n",
            "Iteration: 861\t Weight1: [8.59873298]\t Weight2: [1.85002312]\t Bias: [3.56289296]\t Cost: 15.546680404626109\n",
            "Iteration: 862\t Weight1: [8.5999087]\t Weight2: [1.84862567]\t Bias: [3.55984256]\t Cost: 15.546049355079644\n",
            "Iteration: 863\t Weight1: [8.60108159]\t Weight2: [1.84723068]\t Bias: [3.55680249]\t Cost: 15.545422122556646\n",
            "Iteration: 864\t Weight1: [8.60225165]\t Weight2: [1.84583814]\t Bias: [3.55377272]\t Cost: 15.544798682999682\n",
            "Iteration: 865\t Weight1: [8.60341888]\t Weight2: [1.84444805]\t Bias: [3.55075322]\t Cost: 15.544179012509419\n",
            "Iteration: 866\t Weight1: [8.6045833]\t Weight2: [1.84306041]\t Bias: [3.54774394]\t Cost: 15.5435630873437\n",
            "Iteration: 867\t Weight1: [8.60574491]\t Weight2: [1.84167522]\t Bias: [3.54474485]\t Cost: 15.542950883916285\n",
            "Iteration: 868\t Weight1: [8.60690371]\t Weight2: [1.84029248]\t Bias: [3.54175591]\t Cost: 15.54234237879597\n",
            "Iteration: 869\t Weight1: [8.60805972]\t Weight2: [1.83891218]\t Bias: [3.5387771]\t Cost: 15.541737548705365\n",
            "Iteration: 870\t Weight1: [8.60921293]\t Weight2: [1.83753432]\t Bias: [3.53580837]\t Cost: 15.541136370519954\n",
            "Iteration: 871\t Weight1: [8.61036336]\t Weight2: [1.8361589]\t Bias: [3.53284968]\t Cost: 15.54053882126698\n",
            "Iteration: 872\t Weight1: [8.61151101]\t Weight2: [1.83478592]\t Bias: [3.52990101]\t Cost: 15.539944878124471\n",
            "Iteration: 873\t Weight1: [8.61265589]\t Weight2: [1.83341537]\t Bias: [3.52696232]\t Cost: 15.539354518420147\n",
            "Iteration: 874\t Weight1: [8.61379801]\t Weight2: [1.83204726]\t Bias: [3.52403357]\t Cost: 15.538767719630444\n",
            "Iteration: 875\t Weight1: [8.61493736]\t Weight2: [1.83068159]\t Bias: [3.52111473]\t Cost: 15.538184459379494\n",
            "Iteration: 876\t Weight1: [8.61607396]\t Weight2: [1.82931834]\t Bias: [3.51820576]\t Cost: 15.537604715438064\n",
            "Iteration: 877\t Weight1: [8.61720782]\t Weight2: [1.82795753]\t Bias: [3.51530663]\t Cost: 15.537028465722639\n",
            "Iteration: 878\t Weight1: [8.61833893]\t Weight2: [1.82659914]\t Bias: [3.5124173]\t Cost: 15.536455688294366\n",
            "Iteration: 879\t Weight1: [8.61946731]\t Weight2: [1.82524317]\t Bias: [3.50953774]\t Cost: 15.535886361358083\n",
            "Iteration: 880\t Weight1: [8.62059297]\t Weight2: [1.82388963]\t Bias: [3.50666792]\t Cost: 15.535320463261346\n",
            "Iteration: 881\t Weight1: [8.6217159]\t Weight2: [1.82253851]\t Bias: [3.5038078]\t Cost: 15.534757972493479\n",
            "Iteration: 882\t Weight1: [8.62283611]\t Weight2: [1.82118981]\t Bias: [3.50095734]\t Cost: 15.53419886768452\n",
            "Iteration: 883\t Weight1: [8.62395362]\t Weight2: [1.81984353]\t Bias: [3.49811652]\t Cost: 15.53364312760439\n",
            "Iteration: 884\t Weight1: [8.62506843]\t Weight2: [1.81849966]\t Bias: [3.4952853]\t Cost: 15.533090731161849\n",
            "Iteration: 885\t Weight1: [8.62618054]\t Weight2: [1.81715821]\t Bias: [3.49246364]\t Cost: 15.532541657403547\n",
            "Iteration: 886\t Weight1: [8.62728996]\t Weight2: [1.81581916]\t Bias: [3.48965152]\t Cost: 15.531995885513174\n",
            "Iteration: 887\t Weight1: [8.62839669]\t Weight2: [1.81448253]\t Bias: [3.48684889]\t Cost: 15.531453394810377\n",
            "Iteration: 888\t Weight1: [8.62950075]\t Weight2: [1.8131483]\t Bias: [3.48405573]\t Cost: 15.530914164750039\n",
            "Iteration: 889\t Weight1: [8.63060213]\t Weight2: [1.81181648]\t Bias: [3.481272]\t Cost: 15.53037817492116\n",
            "Iteration: 890\t Weight1: [8.63170085]\t Weight2: [1.81048706]\t Bias: [3.47849767]\t Cost: 15.529845405046045\n",
            "Iteration: 891\t Weight1: [8.63279691]\t Weight2: [1.80916004]\t Bias: [3.4757327]\t Cost: 15.529315834979405\n",
            "Iteration: 892\t Weight1: [8.63389032]\t Weight2: [1.80783542]\t Bias: [3.47297707]\t Cost: 15.528789444707408\n",
            "Iteration: 893\t Weight1: [8.63498108]\t Weight2: [1.8065132]\t Bias: [3.47023074]\t Cost: 15.528266214346818\n",
            "Iteration: 894\t Weight1: [8.6360692]\t Weight2: [1.80519338]\t Bias: [3.46749368]\t Cost: 15.527746124144109\n",
            "Iteration: 895\t Weight1: [8.63715468]\t Weight2: [1.80387594]\t Bias: [3.46476585]\t Cost: 15.527229154474558\n",
            "Iteration: 896\t Weight1: [8.63823754]\t Weight2: [1.8025609]\t Bias: [3.46204723]\t Cost: 15.52671528584143\n",
            "Iteration: 897\t Weight1: [8.63931777]\t Weight2: [1.80124824]\t Bias: [3.45933778]\t Cost: 15.526204498874996\n",
            "Iteration: 898\t Weight1: [8.64039539]\t Weight2: [1.79993797]\t Bias: [3.45663747]\t Cost: 15.525696774331811\n",
            "Iteration: 899\t Weight1: [8.6414704]\t Weight2: [1.79863009]\t Bias: [3.45394626]\t Cost: 15.525192093093745\n",
            "Iteration: 900\t Weight1: [8.6425428]\t Weight2: [1.79732459]\t Bias: [3.45126413]\t Cost: 15.524690436167187\n",
            "Iteration: 901\t Weight1: [8.6436126]\t Weight2: [1.79602146]\t Bias: [3.44859104]\t Cost: 15.524191784682191\n",
            "Iteration: 902\t Weight1: [8.64467981]\t Weight2: [1.79472072]\t Bias: [3.44592696]\t Cost: 15.523696119891623\n",
            "Iteration: 903\t Weight1: [8.64574443]\t Weight2: [1.79342235]\t Bias: [3.44327187]\t Cost: 15.523203423170353\n",
            "Iteration: 904\t Weight1: [8.64680648]\t Weight2: [1.79212635]\t Bias: [3.44062572]\t Cost: 15.522713676014437\n",
            "Iteration: 905\t Weight1: [8.64786594]\t Weight2: [1.79083272]\t Bias: [3.43798849]\t Cost: 15.52222686004019\n",
            "Iteration: 906\t Weight1: [8.64892284]\t Weight2: [1.78954146]\t Bias: [3.43536014]\t Cost: 15.521742956983557\n",
            "Iteration: 907\t Weight1: [8.64997718]\t Weight2: [1.78825257]\t Bias: [3.43274065]\t Cost: 15.521261948699141\n",
            "Iteration: 908\t Weight1: [8.65102896]\t Weight2: [1.78696604]\t Bias: [3.43012999]\t Cost: 15.520783817159469\n",
            "Iteration: 909\t Weight1: [8.65207819]\t Weight2: [1.78568188]\t Bias: [3.42752811]\t Cost: 15.520308544454227\n",
            "Iteration: 910\t Weight1: [8.65312488]\t Weight2: [1.78440007]\t Bias: [3.424935]\t Cost: 15.519836112789351\n",
            "Iteration: 911\t Weight1: [8.65416902]\t Weight2: [1.78312062]\t Bias: [3.42235063]\t Cost: 15.519366504486337\n",
            "Iteration: 912\t Weight1: [8.65521063]\t Weight2: [1.78184353]\t Bias: [3.41977495]\t Cost: 15.518899701981484\n",
            "Iteration: 913\t Weight1: [8.65624972]\t Weight2: [1.78056879]\t Bias: [3.41720794]\t Cost: 15.518435687825006\n",
            "Iteration: 914\t Weight1: [8.65728628]\t Weight2: [1.7792964]\t Bias: [3.41464958]\t Cost: 15.517974444680382\n",
            "Iteration: 915\t Weight1: [8.65832033]\t Weight2: [1.77802636]\t Bias: [3.41209982]\t Cost: 15.517515955323478\n",
            "Iteration: 916\t Weight1: [8.65935187]\t Weight2: [1.77675866]\t Bias: [3.40955865]\t Cost: 15.517060202641877\n",
            "Iteration: 917\t Weight1: [8.6603809]\t Weight2: [1.77549331]\t Bias: [3.40702602]\t Cost: 15.516607169634089\n",
            "Iteration: 918\t Weight1: [8.66140744]\t Weight2: [1.7742303]\t Bias: [3.40450192]\t Cost: 15.516156839408804\n",
            "Iteration: 919\t Weight1: [8.66243148]\t Weight2: [1.77296963]\t Bias: [3.4019863]\t Cost: 15.515709195184131\n",
            "Iteration: 920\t Weight1: [8.66345304]\t Weight2: [1.77171129]\t Bias: [3.39947915]\t Cost: 15.51526422028688\n",
            "Iteration: 921\t Weight1: [8.66447211]\t Weight2: [1.77045529]\t Bias: [3.39698043]\t Cost: 15.514821898151848\n",
            "Iteration: 922\t Weight1: [8.66548872]\t Weight2: [1.76920162]\t Bias: [3.39449011]\t Cost: 15.514382212321044\n",
            "Iteration: 923\t Weight1: [8.66650285]\t Weight2: [1.76795028]\t Bias: [3.39200816]\t Cost: 15.513945146442975\n",
            "Iteration: 924\t Weight1: [8.66751452]\t Weight2: [1.76670126]\t Bias: [3.38953456]\t Cost: 15.513510684271981\n",
            "Iteration: 925\t Weight1: [8.66852373]\t Weight2: [1.76545457]\t Bias: [3.38706927]\t Cost: 15.513078809667437\n",
            "Iteration: 926\t Weight1: [8.66953048]\t Weight2: [1.76421021]\t Bias: [3.38461227]\t Cost: 15.51264950659315\n",
            "Iteration: 927\t Weight1: [8.6705348]\t Weight2: [1.76296816]\t Bias: [3.38216352]\t Cost: 15.51222275911651\n",
            "Iteration: 928\t Weight1: [8.67153667]\t Weight2: [1.76172843]\t Bias: [3.379723]\t Cost: 15.511798551407958\n",
            "Iteration: 929\t Weight1: [8.6725361]\t Weight2: [1.76049101]\t Bias: [3.37729068]\t Cost: 15.511376867740168\n",
            "Iteration: 930\t Weight1: [8.67353311]\t Weight2: [1.75925591]\t Bias: [3.37486653]\t Cost: 15.510957692487416\n",
            "Iteration: 931\t Weight1: [8.67452769]\t Weight2: [1.75802312]\t Bias: [3.37245052]\t Cost: 15.510541010124856\n",
            "Iteration: 932\t Weight1: [8.67551986]\t Weight2: [1.75679263]\t Bias: [3.37004262]\t Cost: 15.510126805227898\n",
            "Iteration: 933\t Weight1: [8.67650961]\t Weight2: [1.75556445]\t Bias: [3.36764281]\t Cost: 15.509715062471487\n",
            "Iteration: 934\t Weight1: [8.67749696]\t Weight2: [1.75433858]\t Bias: [3.36525106]\t Cost: 15.509305766629478\n",
            "Iteration: 935\t Weight1: [8.6784819]\t Weight2: [1.753115]\t Bias: [3.36286733]\t Cost: 15.508898902573897\n",
            "Iteration: 936\t Weight1: [8.67946445]\t Weight2: [1.75189372]\t Bias: [3.36049161]\t Cost: 15.50849445527434\n",
            "Iteration: 937\t Weight1: [8.68044461]\t Weight2: [1.75067473]\t Bias: [3.35812386]\t Cost: 15.508092409797312\n",
            "Iteration: 938\t Weight1: [8.68142238]\t Weight2: [1.74945804]\t Bias: [3.35576405]\t Cost: 15.507692751305562\n",
            "Iteration: 939\t Weight1: [8.68239777]\t Weight2: [1.74824364]\t Bias: [3.35341216]\t Cost: 15.507295465057446\n",
            "Iteration: 940\t Weight1: [8.6833708]\t Weight2: [1.74703153]\t Bias: [3.35106816]\t Cost: 15.506900536406263\n",
            "Iteration: 941\t Weight1: [8.68434145]\t Weight2: [1.7458217]\t Bias: [3.34873203]\t Cost: 15.506507950799673\n",
            "Iteration: 942\t Weight1: [8.68530974]\t Weight2: [1.74461415]\t Bias: [3.34640372]\t Cost: 15.506117693778979\n",
            "Iteration: 943\t Weight1: [8.68627567]\t Weight2: [1.74340888]\t Bias: [3.34408323]\t Cost: 15.505729750978556\n",
            "Iteration: 944\t Weight1: [8.68723926]\t Weight2: [1.7422059]\t Bias: [3.34177051]\t Cost: 15.505344108125232\n",
            "Iteration: 945\t Weight1: [8.68820049]\t Weight2: [1.74100518]\t Bias: [3.33946555]\t Cost: 15.504960751037657\n",
            "Iteration: 946\t Weight1: [8.68915939]\t Weight2: [1.73980674]\t Bias: [3.33716832]\t Cost: 15.504579665625656\n",
            "Iteration: 947\t Weight1: [8.69011595]\t Weight2: [1.73861057]\t Bias: [3.33487878]\t Cost: 15.504200837889652\n",
            "Iteration: 948\t Weight1: [8.69107018]\t Weight2: [1.73741666]\t Bias: [3.33259692]\t Cost: 15.503824253920063\n",
            "Iteration: 949\t Weight1: [8.69202209]\t Weight2: [1.73622503]\t Bias: [3.3303227]\t Cost: 15.503449899896657\n",
            "Iteration: 950\t Weight1: [8.69297167]\t Weight2: [1.73503565]\t Bias: [3.3280561]\t Cost: 15.503077762088013\n",
            "Iteration: 951\t Weight1: [8.69391895]\t Weight2: [1.73384853]\t Bias: [3.3257971]\t Cost: 15.50270782685088\n",
            "Iteration: 952\t Weight1: [8.69486392]\t Weight2: [1.73266367]\t Bias: [3.32354566]\t Cost: 15.502340080629608\n",
            "Iteration: 953\t Weight1: [8.69580658]\t Weight2: [1.73148106]\t Bias: [3.32130176]\t Cost: 15.50197450995554\n",
            "Iteration: 954\t Weight1: [8.69674695]\t Weight2: [1.73030071]\t Bias: [3.31906537]\t Cost: 15.501611101446493\n",
            "Iteration: 955\t Weight1: [8.69768502]\t Weight2: [1.7291226]\t Bias: [3.31683648]\t Cost: 15.501249841806072\n",
            "Iteration: 956\t Weight1: [8.69862081]\t Weight2: [1.72794674]\t Bias: [3.31461504]\t Cost: 15.50089071782318\n",
            "Iteration: 957\t Weight1: [8.69955432]\t Weight2: [1.72677313]\t Bias: [3.31240104]\t Cost: 15.500533716371448\n",
            "Iteration: 958\t Weight1: [8.70048555]\t Weight2: [1.72560175]\t Bias: [3.31019445]\t Cost: 15.500178824408614\n",
            "Iteration: 959\t Weight1: [8.70141452]\t Weight2: [1.72443262]\t Bias: [3.30799524]\t Cost: 15.499826028976004\n",
            "Iteration: 960\t Weight1: [8.70234121]\t Weight2: [1.72326572]\t Bias: [3.30580339]\t Cost: 15.499475317197952\n",
            "Iteration: 961\t Weight1: [8.70326565]\t Weight2: [1.72210105]\t Bias: [3.30361888]\t Cost: 15.499126676281275\n",
            "Iteration: 962\t Weight1: [8.70418783]\t Weight2: [1.72093862]\t Bias: [3.30144167]\t Cost: 15.498780093514686\n",
            "Iteration: 963\t Weight1: [8.70510776]\t Weight2: [1.71977841]\t Bias: [3.29927174]\t Cost: 15.49843555626827\n",
            "Iteration: 964\t Weight1: [8.70602545]\t Weight2: [1.71862043]\t Bias: [3.29710907]\t Cost: 15.49809305199292\n",
            "Iteration: 965\t Weight1: [8.7069409]\t Weight2: [1.71746467]\t Bias: [3.29495363]\t Cost: 15.497752568219834\n",
            "Iteration: 966\t Weight1: [8.70785412]\t Weight2: [1.71631113]\t Bias: [3.2928054]\t Cost: 15.497414092559957\n",
            "Iteration: 967\t Weight1: [8.70876511]\t Weight2: [1.71515981]\t Bias: [3.29066435]\t Cost: 15.497077612703418\n",
            "Iteration: 968\t Weight1: [8.70967387]\t Weight2: [1.7140107]\t Bias: [3.28853045]\t Cost: 15.496743116419081\n",
            "Iteration: 969\t Weight1: [8.71058042]\t Weight2: [1.7128638]\t Bias: [3.28640369]\t Cost: 15.496410591553927\n",
            "Iteration: 970\t Weight1: [8.71148476]\t Weight2: [1.71171912]\t Bias: [3.28428403]\t Cost: 15.496080026032605\n",
            "Iteration: 971\t Weight1: [8.71238688]\t Weight2: [1.71057664]\t Bias: [3.28217145]\t Cost: 15.49575140785689\n",
            "Iteration: 972\t Weight1: [8.71328681]\t Weight2: [1.70943636]\t Bias: [3.28006593]\t Cost: 15.495424725105183\n",
            "Iteration: 973\t Weight1: [8.71418454]\t Weight2: [1.70829829]\t Bias: [3.27796745]\t Cost: 15.495099965931917\n",
            "Iteration: 974\t Weight1: [8.71508007]\t Weight2: [1.70716241]\t Bias: [3.27587597]\t Cost: 15.494777118567194\n",
            "Iteration: 975\t Weight1: [8.71597342]\t Weight2: [1.70602873]\t Bias: [3.27379148]\t Cost: 15.494456171316193\n",
            "Iteration: 976\t Weight1: [8.71686459]\t Weight2: [1.70489724]\t Bias: [3.27171394]\t Cost: 15.494137112558654\n",
            "Iteration: 977\t Weight1: [8.71775358]\t Weight2: [1.70376795]\t Bias: [3.26964335]\t Cost: 15.493819930748455\n",
            "Iteration: 978\t Weight1: [8.7186404]\t Weight2: [1.70264084]\t Bias: [3.26757966]\t Cost: 15.493504614413048\n",
            "Iteration: 979\t Weight1: [8.71952505]\t Weight2: [1.70151591]\t Bias: [3.26552286]\t Cost: 15.493191152152992\n",
            "Iteration: 980\t Weight1: [8.72040754]\t Weight2: [1.70039317]\t Bias: [3.26347292]\t Cost: 15.4928795326415\n",
            "Iteration: 981\t Weight1: [8.72128787]\t Weight2: [1.69927261]\t Bias: [3.26142983]\t Cost: 15.49256974462391\n",
            "Iteration: 982\t Weight1: [8.72216606]\t Weight2: [1.69815422]\t Bias: [3.25939355]\t Cost: 15.492261776917237\n",
            "Iteration: 983\t Weight1: [8.7230421]\t Weight2: [1.69703801]\t Bias: [3.25736406]\t Cost: 15.491955618409705\n",
            "Iteration: 984\t Weight1: [8.72391599]\t Weight2: [1.69592397]\t Bias: [3.25534134]\t Cost: 15.491651258060198\n",
            "Iteration: 985\t Weight1: [8.72478775]\t Weight2: [1.69481209]\t Bias: [3.25332537]\t Cost: 15.491348684897913\n",
            "Iteration: 986\t Weight1: [8.72565738]\t Weight2: [1.69370239]\t Bias: [3.25131612]\t Cost: 15.491047888021786\n",
            "Iteration: 987\t Weight1: [8.72652488]\t Weight2: [1.69259484]\t Bias: [3.24931357]\t Cost: 15.490748856600078\n",
            "Iteration: 988\t Weight1: [8.72739026]\t Weight2: [1.69148946]\t Bias: [3.2473177]\t Cost: 15.49045157986996\n",
            "Iteration: 989\t Weight1: [8.72825353]\t Weight2: [1.69038623]\t Bias: [3.24532847]\t Cost: 15.490156047136939\n",
            "Iteration: 990\t Weight1: [8.72911468]\t Weight2: [1.68928515]\t Bias: [3.24334588]\t Cost: 15.489862247774479\n",
            "Iteration: 991\t Weight1: [8.72997373]\t Weight2: [1.68818623]\t Bias: [3.24136989]\t Cost: 15.489570171223578\n",
            "Iteration: 992\t Weight1: [8.73083068]\t Weight2: [1.68708946]\t Bias: [3.23940049]\t Cost: 15.489279806992272\n",
            "Iteration: 993\t Weight1: [8.73168553]\t Weight2: [1.68599483]\t Bias: [3.23743764]\t Cost: 15.488991144655198\n",
            "Iteration: 994\t Weight1: [8.73253829]\t Weight2: [1.68490235]\t Bias: [3.23548134]\t Cost: 15.48870417385316\n",
            "Iteration: 995\t Weight1: [8.73338896]\t Weight2: [1.68381201]\t Bias: [3.23353155]\t Cost: 15.488418884292718\n",
            "Iteration: 996\t Weight1: [8.73423755]\t Weight2: [1.6827238]\t Bias: [3.23158825]\t Cost: 15.488135265745678\n",
            "Iteration: 997\t Weight1: [8.73508407]\t Weight2: [1.68163773]\t Bias: [3.22965143]\t Cost: 15.487853308048749\n",
            "Iteration: 998\t Weight1: [8.73592851]\t Weight2: [1.68055379]\t Bias: [3.22772105]\t Cost: 15.487573001103026\n",
            "Iteration: 999\t Weight1: [8.73677089]\t Weight2: [1.67947198]\t Bias: [3.2257971]\t Cost: 15.487294334873694\n",
            "Iteration: 1000\t Weight1: [8.7376112]\t Weight2: [1.6783923]\t Bias: [3.22387955]\t Cost: 15.487017299389436\n",
            "Iteration: 1001\t Weight1: [8.73844946]\t Weight2: [1.67731474]\t Bias: [3.22196838]\t Cost: 15.48674188474213\n",
            "Iteration: 1002\t Weight1: [8.73928566]\t Weight2: [1.6762393]\t Bias: [3.22006357]\t Cost: 15.486468081086429\n",
            "Iteration: 1003\t Weight1: [8.74011982]\t Weight2: [1.67516598]\t Bias: [3.2181651]\t Cost: 15.486195878639256\n",
            "Iteration: 1004\t Weight1: [8.74095193]\t Weight2: [1.67409477]\t Bias: [3.21627294]\t Cost: 15.485925267679523\n",
            "Iteration: 1005\t Weight1: [8.74178201]\t Weight2: [1.67302568]\t Bias: [3.21438708]\t Cost: 15.485656238547604\n",
            "Iteration: 1006\t Weight1: [8.74261005]\t Weight2: [1.67195869]\t Bias: [3.21250749]\t Cost: 15.48538878164499\n",
            "Iteration: 1007\t Weight1: [8.74343607]\t Weight2: [1.67089382]\t Bias: [3.21063415]\t Cost: 15.485122887433903\n",
            "Iteration: 1008\t Weight1: [8.74426006]\t Weight2: [1.66983104]\t Bias: [3.20876703]\t Cost: 15.484858546436808\n",
            "Iteration: 1009\t Weight1: [8.74508203]\t Weight2: [1.66877037]\t Bias: [3.20690613]\t Cost: 15.484595749236133\n",
            "Iteration: 1010\t Weight1: [8.74590199]\t Weight2: [1.66771179]\t Bias: [3.20505141]\t Cost: 15.484334486473783\n",
            "Iteration: 1011\t Weight1: [8.74671994]\t Weight2: [1.66665531]\t Bias: [3.20320285]\t Cost: 15.48407474885079\n",
            "Iteration: 1012\t Weight1: [8.74753588]\t Weight2: [1.66560092]\t Bias: [3.20136043]\t Cost: 15.483816527126907\n",
            "Iteration: 1013\t Weight1: [8.74834983]\t Weight2: [1.66454863]\t Bias: [3.19952414]\t Cost: 15.48355981212024\n",
            "Iteration: 1014\t Weight1: [8.74916178]\t Weight2: [1.66349841]\t Bias: [3.19769395]\t Cost: 15.483304594706837\n",
            "Iteration: 1015\t Weight1: [8.74997174]\t Weight2: [1.66245029]\t Bias: [3.19586983]\t Cost: 15.483050865820319\n",
            "Iteration: 1016\t Weight1: [8.75077971]\t Weight2: [1.66140424]\t Bias: [3.19405178]\t Cost: 15.482798616451513\n",
            "Iteration: 1017\t Weight1: [8.75158571]\t Weight2: [1.66036027]\t Bias: [3.19223976]\t Cost: 15.482547837648083\n",
            "Iteration: 1018\t Weight1: [8.75238972]\t Weight2: [1.65931837]\t Bias: [3.19043376]\t Cost: 15.482298520514082\n",
            "Iteration: 1019\t Weight1: [8.75319177]\t Weight2: [1.65827855]\t Bias: [3.18863375]\t Cost: 15.482050656209701\n",
            "Iteration: 1020\t Weight1: [8.75399185]\t Weight2: [1.6572408]\t Bias: [3.18683972]\t Cost: 15.481804235950797\n",
            "Iteration: 1021\t Weight1: [8.75478996]\t Weight2: [1.65620511]\t Bias: [3.18505165]\t Cost: 15.481559251008585\n",
            "Iteration: 1022\t Weight1: [8.75558612]\t Weight2: [1.65517149]\t Bias: [3.1832695]\t Cost: 15.481315692709247\n",
            "Iteration: 1023\t Weight1: [8.75638033]\t Weight2: [1.65413993]\t Bias: [3.18149328]\t Cost: 15.481073552433566\n",
            "Iteration: 1024\t Weight1: [8.75717259]\t Weight2: [1.65311042]\t Bias: [3.17972294]\t Cost: 15.480832821616616\n",
            "Iteration: 1025\t Weight1: [8.7579629]\t Weight2: [1.65208297]\t Bias: [3.17795848]\t Cost: 15.48059349174734\n",
            "Iteration: 1026\t Weight1: [8.75875127]\t Weight2: [1.65105758]\t Bias: [3.17619986]\t Cost: 15.480355554368236\n",
            "Iteration: 1027\t Weight1: [8.75953771]\t Weight2: [1.65003423]\t Bias: [3.17444708]\t Cost: 15.48011900107501\n",
            "Iteration: 1028\t Weight1: [8.76032222]\t Weight2: [1.64901292]\t Bias: [3.17270012]\t Cost: 15.479883823516175\n",
            "Iteration: 1029\t Weight1: [8.76110481]\t Weight2: [1.64799367]\t Bias: [3.17095894]\t Cost: 15.479650013392792\n",
            "Iteration: 1030\t Weight1: [8.76188547]\t Weight2: [1.64697645]\t Bias: [3.16922354]\t Cost: 15.479417562458039\n",
            "Iteration: 1031\t Weight1: [8.76266422]\t Weight2: [1.64596127]\t Bias: [3.16749389]\t Cost: 15.479186462516926\n",
            "Iteration: 1032\t Weight1: [8.76344105]\t Weight2: [1.64494812]\t Bias: [3.16576997]\t Cost: 15.47895670542592\n",
            "Iteration: 1033\t Weight1: [8.76421598]\t Weight2: [1.64393701]\t Bias: [3.16405176]\t Cost: 15.478728283092648\n",
            "Iteration: 1034\t Weight1: [8.76498901]\t Weight2: [1.64292792]\t Bias: [3.16233925]\t Cost: 15.478501187475512\n",
            "Iteration: 1035\t Weight1: [8.76576013]\t Weight2: [1.64192086]\t Bias: [3.16063241]\t Cost: 15.478275410583382\n",
            "Iteration: 1036\t Weight1: [8.76652937]\t Weight2: [1.64091582]\t Bias: [3.15893122]\t Cost: 15.478050944475314\n",
            "Iteration: 1037\t Weight1: [8.76729671]\t Weight2: [1.63991281]\t Bias: [3.15723567]\t Cost: 15.477827781260089\n",
            "Iteration: 1038\t Weight1: [8.76806217]\t Weight2: [1.63891181]\t Bias: [3.15554573]\t Cost: 15.477605913096049\n",
            "Iteration: 1039\t Weight1: [8.76882575]\t Weight2: [1.63791282]\t Bias: [3.15386138]\t Cost: 15.477385332190638\n",
            "Iteration: 1040\t Weight1: [8.76958745]\t Weight2: [1.63691585]\t Bias: [3.15218262]\t Cost: 15.477166030800207\n",
            "Iteration: 1041\t Weight1: [8.77034728]\t Weight2: [1.63592088]\t Bias: [3.15050941]\t Cost: 15.476948001229529\n",
            "Iteration: 1042\t Weight1: [8.77110524]\t Weight2: [1.63492792]\t Bias: [3.14884173]\t Cost: 15.47673123583167\n",
            "Iteration: 1043\t Weight1: [8.77186134]\t Weight2: [1.63393696]\t Bias: [3.14717958]\t Cost: 15.476515727007545\n",
            "Iteration: 1044\t Weight1: [8.77261559]\t Weight2: [1.632948]\t Bias: [3.14552293]\t Cost: 15.476301467205642\n",
            "Iteration: 1045\t Weight1: [8.77336797]\t Weight2: [1.63196104]\t Bias: [3.14387175]\t Cost: 15.4760884489217\n",
            "Iteration: 1046\t Weight1: [8.77411851]\t Weight2: [1.63097607]\t Bias: [3.14222604]\t Cost: 15.47587666469844\n",
            "Iteration: 1047\t Weight1: [8.77486721]\t Weight2: [1.6299931]\t Bias: [3.14058578]\t Cost: 15.4756661071252\n",
            "Iteration: 1048\t Weight1: [8.77561406]\t Weight2: [1.62901211]\t Bias: [3.13895093]\t Cost: 15.475456768837711\n",
            "Iteration: 1049\t Weight1: [8.77635908]\t Weight2: [1.6280331]\t Bias: [3.13732149]\t Cost: 15.47524864251769\n",
            "Iteration: 1050\t Weight1: [8.77710227]\t Weight2: [1.62705608]\t Bias: [3.13569744]\t Cost: 15.475041720892635\n",
            "Iteration: 1051\t Weight1: [8.77784362]\t Weight2: [1.62608104]\t Bias: [3.13407876]\t Cost: 15.474835996735466\n",
            "Iteration: 1052\t Weight1: [8.77858316]\t Weight2: [1.62510797]\t Bias: [3.13246543]\t Cost: 15.474631462864249\n",
            "Iteration: 1053\t Weight1: [8.77932087]\t Weight2: [1.62413688]\t Bias: [3.13085743]\t Cost: 15.474428112141917\n",
            "Iteration: 1054\t Weight1: [8.78005678]\t Weight2: [1.62316776]\t Bias: [3.12925474]\t Cost: 15.474225937475934\n",
            "Iteration: 1055\t Weight1: [8.78079087]\t Weight2: [1.6222006]\t Bias: [3.12765735]\t Cost: 15.474024931818084\n",
            "Iteration: 1056\t Weight1: [8.78152315]\t Weight2: [1.62123541]\t Bias: [3.12606523]\t Cost: 15.4738250881641\n",
            "Iteration: 1057\t Weight1: [8.78225364]\t Weight2: [1.62027218]\t Bias: [3.12447838]\t Cost: 15.4736263995534\n",
            "Iteration: 1058\t Weight1: [8.78298232]\t Weight2: [1.61931091]\t Bias: [3.12289676]\t Cost: 15.473428859068829\n",
            "Iteration: 1059\t Weight1: [8.78370921]\t Weight2: [1.61835159]\t Bias: [3.12132037]\t Cost: 15.473232459836376\n",
            "Iteration: 1060\t Weight1: [8.78443432]\t Weight2: [1.61739423]\t Bias: [3.11974918]\t Cost: 15.473037195024842\n",
            "Iteration: 1061\t Weight1: [8.78515764]\t Weight2: [1.61643882]\t Bias: [3.11818318]\t Cost: 15.472843057845626\n",
            "Iteration: 1062\t Weight1: [8.78587918]\t Weight2: [1.61548535]\t Bias: [3.11662235]\t Cost: 15.472650041552397\n",
            "Iteration: 1063\t Weight1: [8.78659894]\t Weight2: [1.61453383]\t Bias: [3.11506667]\t Cost: 15.472458139440874\n",
            "Iteration: 1064\t Weight1: [8.78731693]\t Weight2: [1.61358425]\t Bias: [3.11351612]\t Cost: 15.472267344848495\n",
            "Iteration: 1065\t Weight1: [8.78803315]\t Weight2: [1.6126366]\t Bias: [3.11197069]\t Cost: 15.472077651154184\n",
            "Iteration: 1066\t Weight1: [8.78874761]\t Weight2: [1.61169089]\t Bias: [3.11043036]\t Cost: 15.471889051778051\n",
            "Iteration: 1067\t Weight1: [8.78946031]\t Weight2: [1.61074712]\t Bias: [3.1088951]\t Cost: 15.471701540181165\n",
            "Iteration: 1068\t Weight1: [8.79017126]\t Weight2: [1.60980527]\t Bias: [3.10736492]\t Cost: 15.471515109865265\n",
            "Iteration: 1069\t Weight1: [8.79088045]\t Weight2: [1.60886535]\t Bias: [3.10583977]\t Cost: 15.471329754372471\n",
            "Iteration: 1070\t Weight1: [8.7915879]\t Weight2: [1.60792735]\t Bias: [3.10431966]\t Cost: 15.471145467285078\n",
            "Iteration: 1071\t Weight1: [8.7922936]\t Weight2: [1.60699127]\t Bias: [3.10280456]\t Cost: 15.470962242225264\n",
            "Iteration: 1072\t Weight1: [8.79299757]\t Weight2: [1.60605711]\t Bias: [3.10129445]\t Cost: 15.470780072854799\n",
            "Iteration: 1073\t Weight1: [8.7936998]\t Weight2: [1.60512487]\t Bias: [3.09978932]\t Cost: 15.470598952874884\n",
            "Iteration: 1074\t Weight1: [8.7944003]\t Weight2: [1.60419453]\t Bias: [3.09828915]\t Cost: 15.470418876025775\n",
            "Iteration: 1075\t Weight1: [8.79509908]\t Weight2: [1.6032661]\t Bias: [3.09679392]\t Cost: 15.470239836086622\n",
            "Iteration: 1076\t Weight1: [8.79579613]\t Weight2: [1.60233958]\t Bias: [3.09530362]\t Cost: 15.47006182687516\n",
            "Iteration: 1077\t Weight1: [8.79649147]\t Weight2: [1.60141497]\t Bias: [3.09381823]\t Cost: 15.469884842247511\n",
            "Iteration: 1078\t Weight1: [8.79718509]\t Weight2: [1.60049225]\t Bias: [3.09233773]\t Cost: 15.469708876097894\n",
            "Iteration: 1079\t Weight1: [8.797877]\t Weight2: [1.59957143]\t Bias: [3.0908621]\t Cost: 15.469533922358394\n",
            "Iteration: 1080\t Weight1: [8.79856721]\t Weight2: [1.5986525]\t Bias: [3.08939134]\t Cost: 15.469359974998714\n",
            "Iteration: 1081\t Weight1: [8.79925571]\t Weight2: [1.59773546]\t Bias: [3.08792541]\t Cost: 15.469187028025932\n",
            "Iteration: 1082\t Weight1: [8.79994252]\t Weight2: [1.59682031]\t Bias: [3.08646432]\t Cost: 15.469015075484265\n",
            "Iteration: 1083\t Weight1: [8.80062763]\t Weight2: [1.59590705]\t Bias: [3.08500803]\t Cost: 15.468844111454823\n",
            "Iteration: 1084\t Weight1: [8.80131106]\t Weight2: [1.59499566]\t Bias: [3.08355653]\t Cost: 15.468674130055382\n",
            "Iteration: 1085\t Weight1: [8.80199279]\t Weight2: [1.59408616]\t Bias: [3.08210981]\t Cost: 15.468505125440123\n",
            "Iteration: 1086\t Weight1: [8.80267285]\t Weight2: [1.59317853]\t Bias: [3.08066785]\t Cost: 15.468337091799393\n",
            "Iteration: 1087\t Weight1: [8.80335123]\t Weight2: [1.59227278]\t Bias: [3.07923064]\t Cost: 15.468170023359553\n",
            "Iteration: 1088\t Weight1: [8.80402794]\t Weight2: [1.59136889]\t Bias: [3.07779815]\t Cost: 15.468003914382626\n",
            "Iteration: 1089\t Weight1: [8.80470298]\t Weight2: [1.59046687]\t Bias: [3.07637037]\t Cost: 15.46783875916613\n",
            "Iteration: 1090\t Weight1: [8.80537635]\t Weight2: [1.58956672]\t Bias: [3.07494729]\t Cost: 15.467674552042856\n",
            "Iteration: 1091\t Weight1: [8.80604806]\t Weight2: [1.58866843]\t Bias: [3.07352889]\t Cost: 15.46751128738063\n",
            "Iteration: 1092\t Weight1: [8.80671811]\t Weight2: [1.587772]\t Bias: [3.07211515]\t Cost: 15.467348959582067\n",
            "Iteration: 1093\t Weight1: [8.80738651]\t Weight2: [1.58687742]\t Bias: [3.07070605]\t Cost: 15.467187563084366\n",
            "Iteration: 1094\t Weight1: [8.80805326]\t Weight2: [1.58598469]\t Bias: [3.06930159]\t Cost: 15.467027092359109\n",
            "Iteration: 1095\t Weight1: [8.80871837]\t Weight2: [1.58509382]\t Bias: [3.06790174]\t Cost: 15.466867541911988\n",
            "Iteration: 1096\t Weight1: [8.80938183]\t Weight2: [1.58420479]\t Bias: [3.0665065]\t Cost: 15.466708906282632\n",
            "Iteration: 1097\t Weight1: [8.81004365]\t Weight2: [1.5833176]\t Bias: [3.06511583]\t Cost: 15.46655118004433\n",
            "Iteration: 1098\t Weight1: [8.81070384]\t Weight2: [1.58243225]\t Bias: [3.06372974]\t Cost: 15.466394357803917\n",
            "Iteration: 1099\t Weight1: [8.8113624]\t Weight2: [1.58154875]\t Bias: [3.06234819]\t Cost: 15.466238434201438\n",
            "Iteration: 1100\t Weight1: [8.81201934]\t Weight2: [1.58066707]\t Bias: [3.06097119]\t Cost: 15.46608340391004\n",
            "Iteration: 1101\t Weight1: [8.81267465]\t Weight2: [1.57978723]\t Bias: [3.0595987]\t Cost: 15.465929261635637\n",
            "Iteration: 1102\t Weight1: [8.81332835]\t Weight2: [1.57890922]\t Bias: [3.05823072]\t Cost: 15.465776002116842\n",
            "Iteration: 1103\t Weight1: [8.81398043]\t Weight2: [1.57803303]\t Bias: [3.05686723]\t Cost: 15.46562362012468\n",
            "Iteration: 1104\t Weight1: [8.8146309]\t Weight2: [1.57715867]\t Bias: [3.05550822]\t Cost: 15.465472110462342\n",
            "Iteration: 1105\t Weight1: [8.81527976]\t Weight2: [1.57628612]\t Bias: [3.05415366]\t Cost: 15.465321467965058\n",
            "Iteration: 1106\t Weight1: [8.81592702]\t Weight2: [1.5754154]\t Bias: [3.05280355]\t Cost: 15.46517168749986\n",
            "Iteration: 1107\t Weight1: [8.81657268]\t Weight2: [1.57454648]\t Bias: [3.05145787]\t Cost: 15.465022763965356\n",
            "Iteration: 1108\t Weight1: [8.81721675]\t Weight2: [1.57367938]\t Bias: [3.05011661]\t Cost: 15.464874692291545\n",
            "Iteration: 1109\t Weight1: [8.81785922]\t Weight2: [1.57281409]\t Bias: [3.04877974]\t Cost: 15.464727467439625\n",
            "Iteration: 1110\t Weight1: [8.81850011]\t Weight2: [1.5719506]\t Bias: [3.04744726]\t Cost: 15.464581084401797\n",
            "Iteration: 1111\t Weight1: [8.81913941]\t Weight2: [1.57108891]\t Bias: [3.04611915]\t Cost: 15.464435538201013\n",
            "Iteration: 1112\t Weight1: [8.81977714]\t Weight2: [1.57022903]\t Bias: [3.04479539]\t Cost: 15.46429082389086\n",
            "Iteration: 1113\t Weight1: [8.82041328]\t Weight2: [1.56937094]\t Bias: [3.04347597]\t Cost: 15.464146936555284\n",
            "Iteration: 1114\t Weight1: [8.82104786]\t Weight2: [1.56851464]\t Bias: [3.04216087]\t Cost: 15.464003871308503\n",
            "Iteration: 1115\t Weight1: [8.82168086]\t Weight2: [1.56766013]\t Bias: [3.04085009]\t Cost: 15.463861623294648\n",
            "Iteration: 1116\t Weight1: [8.8223123]\t Weight2: [1.56680742]\t Bias: [3.0395436]\t Cost: 15.46372018768773\n",
            "Iteration: 1117\t Weight1: [8.82294218]\t Weight2: [1.56595648]\t Bias: [3.03824139]\t Cost: 15.463579559691384\n",
            "Iteration: 1118\t Weight1: [8.82357051]\t Weight2: [1.56510733]\t Bias: [3.03694345]\t Cost: 15.463439734538653\n",
            "Iteration: 1119\t Weight1: [8.82419727]\t Weight2: [1.56425996]\t Bias: [3.03564975]\t Cost: 15.463300707491843\n",
            "Iteration: 1120\t Weight1: [8.82482249]\t Weight2: [1.56341436]\t Bias: [3.0343603]\t Cost: 15.463162473842345\n",
            "Iteration: 1121\t Weight1: [8.82544617]\t Weight2: [1.56257054]\t Bias: [3.03307506]\t Cost: 15.463025028910375\n",
            "Iteration: 1122\t Weight1: [8.8260683]\t Weight2: [1.56172848]\t Bias: [3.03179404]\t Cost: 15.462888368044865\n",
            "Iteration: 1123\t Weight1: [8.82668889]\t Weight2: [1.56088819]\t Bias: [3.03051721]\t Cost: 15.462752486623266\n",
            "Iteration: 1124\t Weight1: [8.82730794]\t Weight2: [1.56004967]\t Bias: [3.02924456]\t Cost: 15.462617380051329\n",
            "Iteration: 1125\t Weight1: [8.82792547]\t Weight2: [1.55921291]\t Bias: [3.02797607]\t Cost: 15.462483043762985\n",
            "Iteration: 1126\t Weight1: [8.82854146]\t Weight2: [1.55837791]\t Bias: [3.02671173]\t Cost: 15.462349473220087\n",
            "Iteration: 1127\t Weight1: [8.82915594]\t Weight2: [1.55754466]\t Bias: [3.02545153]\t Cost: 15.462216663912285\n",
            "Iteration: 1128\t Weight1: [8.82976889]\t Weight2: [1.55671316]\t Bias: [3.02419546]\t Cost: 15.46208461135687\n",
            "Iteration: 1129\t Weight1: [8.83038032]\t Weight2: [1.55588342]\t Bias: [3.02294349]\t Cost: 15.461953311098508\n",
            "Iteration: 1130\t Weight1: [8.83099025]\t Weight2: [1.55505542]\t Bias: [3.02169562]\t Cost: 15.461822758709172\n",
            "Iteration: 1131\t Weight1: [8.83159866]\t Weight2: [1.55422916]\t Bias: [3.02045182]\t Cost: 15.461692949787889\n",
            "Iteration: 1132\t Weight1: [8.83220557]\t Weight2: [1.55340465]\t Bias: [3.0192121]\t Cost: 15.461563879960602\n",
            "Iteration: 1133\t Weight1: [8.83281097]\t Weight2: [1.55258187]\t Bias: [3.01797642]\t Cost: 15.461435544880002\n",
            "Iteration: 1134\t Weight1: [8.83341488]\t Weight2: [1.55176083]\t Bias: [3.01674479]\t Cost: 15.461307940225343\n",
            "Iteration: 1135\t Weight1: [8.83401729]\t Weight2: [1.55094152]\t Bias: [3.01551718]\t Cost: 15.461181061702266\n",
            "Iteration: 1136\t Weight1: [8.8346182]\t Weight2: [1.55012393]\t Bias: [3.01429359]\t Cost: 15.461054905042669\n",
            "Iteration: 1137\t Weight1: [8.83521764]\t Weight2: [1.54930808]\t Bias: [3.01307399]\t Cost: 15.46092946600448\n",
            "Iteration: 1138\t Weight1: [8.83581558]\t Weight2: [1.54849395]\t Bias: [3.01185837]\t Cost: 15.46080474037155\n",
            "Iteration: 1139\t Weight1: [8.83641205]\t Weight2: [1.54768154]\t Bias: [3.01064673]\t Cost: 15.460680723953447\n",
            "Iteration: 1140\t Weight1: [8.83700704]\t Weight2: [1.54687084]\t Bias: [3.00943904]\t Cost: 15.460557412585338\n",
            "Iteration: 1141\t Weight1: [8.83760055]\t Weight2: [1.54606186]\t Bias: [3.0082353]\t Cost: 15.460434802127754\n",
            "Iteration: 1142\t Weight1: [8.8381926]\t Weight2: [1.54525459]\t Bias: [3.00703549]\t Cost: 15.460312888466497\n",
            "Iteration: 1143\t Weight1: [8.83878317]\t Weight2: [1.54444904]\t Bias: [3.00583959]\t Cost: 15.460191667512456\n",
            "Iteration: 1144\t Weight1: [8.83937229]\t Weight2: [1.54364518]\t Bias: [3.0046476]\t Cost: 15.46007113520141\n",
            "Iteration: 1145\t Weight1: [8.83995994]\t Weight2: [1.54284303]\t Bias: [3.0034595]\t Cost: 15.459951287493961\n",
            "Iteration: 1146\t Weight1: [8.84054614]\t Weight2: [1.54204258]\t Bias: [3.00227528]\t Cost: 15.459832120375285\n",
            "Iteration: 1147\t Weight1: [8.84113089]\t Weight2: [1.54124383]\t Bias: [3.00109492]\t Cost: 15.459713629855013\n",
            "Iteration: 1148\t Weight1: [8.84171419]\t Weight2: [1.54044677]\t Bias: [2.99991841]\t Cost: 15.45959581196706\n",
            "Iteration: 1149\t Weight1: [8.84229604]\t Weight2: [1.5396514]\t Bias: [2.99874574]\t Cost: 15.459478662769522\n",
            "Iteration: 1150\t Weight1: [8.84287645]\t Weight2: [1.53885772]\t Bias: [2.99757689]\t Cost: 15.459362178344461\n",
            "Iteration: 1151\t Weight1: [8.84345542]\t Weight2: [1.53806573]\t Bias: [2.99641186]\t Cost: 15.459246354797765\n",
            "Iteration: 1152\t Weight1: [8.84403296]\t Weight2: [1.53727542]\t Bias: [2.99525063]\t Cost: 15.459131188259049\n",
            "Iteration: 1153\t Weight1: [8.84460906]\t Weight2: [1.53648679]\t Bias: [2.99409318]\t Cost: 15.459016674881424\n",
            "Iteration: 1154\t Weight1: [8.84518374]\t Weight2: [1.53569983]\t Bias: [2.9929395]\t Cost: 15.45890281084141\n",
            "Iteration: 1155\t Weight1: [8.84575699]\t Weight2: [1.53491455]\t Bias: [2.99178959]\t Cost: 15.45878959233877\n",
            "Iteration: 1156\t Weight1: [8.84632882]\t Weight2: [1.53413094]\t Bias: [2.99064342]\t Cost: 15.458677015596344\n",
            "Iteration: 1157\t Weight1: [8.84689923]\t Weight2: [1.533349]\t Bias: [2.98950098]\t Cost: 15.458565076859898\n",
            "Iteration: 1158\t Weight1: [8.84746823]\t Weight2: [1.53256872]\t Bias: [2.98836227]\t Cost: 15.458453772398068\n",
            "Iteration: 1159\t Weight1: [8.84803581]\t Weight2: [1.53179011]\t Bias: [2.98722727]\t Cost: 15.458343098502075\n",
            "Iteration: 1160\t Weight1: [8.84860199]\t Weight2: [1.53101316]\t Bias: [2.98609597]\t Cost: 15.458233051485669\n",
            "Iteration: 1161\t Weight1: [8.84916677]\t Weight2: [1.53023786]\t Bias: [2.98496835]\t Cost: 15.458123627685001\n",
            "Iteration: 1162\t Weight1: [8.84973014]\t Weight2: [1.52946422]\t Bias: [2.9838444]\t Cost: 15.458014823458436\n",
            "Iteration: 1163\t Weight1: [8.85029211]\t Weight2: [1.52869222]\t Bias: [2.98272411]\t Cost: 15.457906635186417\n",
            "Iteration: 1164\t Weight1: [8.8508527]\t Weight2: [1.52792188]\t Bias: [2.98160747]\t Cost: 15.457799059271334\n",
            "Iteration: 1165\t Weight1: [8.85141189]\t Weight2: [1.52715318]\t Bias: [2.98049446]\t Cost: 15.457692092137396\n",
            "Iteration: 1166\t Weight1: [8.85196969]\t Weight2: [1.52638612]\t Bias: [2.97938507]\t Cost: 15.457585730230498\n",
            "Iteration: 1167\t Weight1: [8.85252611]\t Weight2: [1.5256207]\t Bias: [2.9782793]\t Cost: 15.457479970018033\n",
            "Iteration: 1168\t Weight1: [8.85308114]\t Weight2: [1.52485692]\t Bias: [2.97717712]\t Cost: 15.457374807988822\n",
            "Iteration: 1169\t Weight1: [8.8536348]\t Weight2: [1.52409478]\t Bias: [2.97607853]\t Cost: 15.457270240652946\n",
            "Iteration: 1170\t Weight1: [8.85418709]\t Weight2: [1.52333426]\t Bias: [2.97498351]\t Cost: 15.45716626454161\n",
            "Iteration: 1171\t Weight1: [8.85473801]\t Weight2: [1.52257537]\t Bias: [2.97389206]\t Cost: 15.457062876207031\n",
            "Iteration: 1172\t Weight1: [8.85528755]\t Weight2: [1.52181811]\t Bias: [2.97280415]\t Cost: 15.456960072222268\n",
            "Iteration: 1173\t Weight1: [8.85583574]\t Weight2: [1.52106247]\t Bias: [2.97171978]\t Cost: 15.456857849181121\n",
            "Iteration: 1174\t Weight1: [8.85638256]\t Weight2: [1.52030845]\t Bias: [2.97063893]\t Cost: 15.456756203698008\n",
            "Iteration: 1175\t Weight1: [8.85692802]\t Weight2: [1.51955604]\t Bias: [2.9695616]\t Cost: 15.45665513240779\n",
            "Iteration: 1176\t Weight1: [8.85747213]\t Weight2: [1.51880525]\t Bias: [2.96848777]\t Cost: 15.456554631965687\n",
            "Iteration: 1177\t Weight1: [8.85801489]\t Weight2: [1.51805607]\t Bias: [2.96741743]\t Cost: 15.45645469904714\n",
            "Iteration: 1178\t Weight1: [8.8585563]\t Weight2: [1.5173085]\t Bias: [2.96635057]\t Cost: 15.456355330347671\n",
            "Iteration: 1179\t Weight1: [8.85909637]\t Weight2: [1.51656253]\t Bias: [2.96528717]\t Cost: 15.456256522582757\n",
            "Iteration: 1180\t Weight1: [8.85963509]\t Weight2: [1.51581817]\t Bias: [2.96422722]\t Cost: 15.45615827248772\n",
            "Iteration: 1181\t Weight1: [8.86017248]\t Weight2: [1.5150754]\t Bias: [2.96317072]\t Cost: 15.456060576817597\n",
            "Iteration: 1182\t Weight1: [8.86070853]\t Weight2: [1.51433424]\t Bias: [2.96211765]\t Cost: 15.455963432347003\n",
            "Iteration: 1183\t Weight1: [8.86124325]\t Weight2: [1.51359466]\t Bias: [2.961068]\t Cost: 15.455866835870015\n",
            "Iteration: 1184\t Weight1: [8.86177664]\t Weight2: [1.51285668]\t Bias: [2.96002176]\t Cost: 15.45577078420005\n",
            "Iteration: 1185\t Weight1: [8.86230871]\t Weight2: [1.51212028]\t Bias: [2.95897891]\t Cost: 15.455675274169765\n",
            "Iteration: 1186\t Weight1: [8.86283945]\t Weight2: [1.51138547]\t Bias: [2.95793945]\t Cost: 15.455580302630883\n",
            "Iteration: 1187\t Weight1: [8.86336888]\t Weight2: [1.51065225]\t Bias: [2.95690336]\t Cost: 15.455485866454136\n",
            "Iteration: 1188\t Weight1: [8.86389699]\t Weight2: [1.5099206]\t Bias: [2.95587064]\t Cost: 15.45539196252909\n",
            "Iteration: 1189\t Weight1: [8.86442378]\t Weight2: [1.50919053]\t Bias: [2.95484126]\t Cost: 15.455298587764082\n",
            "Iteration: 1190\t Weight1: [8.86494927]\t Weight2: [1.50846203]\t Bias: [2.95381522]\t Cost: 15.45520573908605\n",
            "Iteration: 1191\t Weight1: [8.86547345]\t Weight2: [1.50773511]\t Bias: [2.95279251]\t Cost: 15.455113413440436\n",
            "Iteration: 1192\t Weight1: [8.86599633]\t Weight2: [1.50700975]\t Bias: [2.95177312]\t Cost: 15.455021607791114\n",
            "Iteration: 1193\t Weight1: [8.86651791]\t Weight2: [1.50628596]\t Bias: [2.95075703]\t Cost: 15.454930319120166\n",
            "Iteration: 1194\t Weight1: [8.86703819]\t Weight2: [1.50556373]\t Bias: [2.94974424]\t Cost: 15.45483954442789\n",
            "Iteration: 1195\t Weight1: [8.86755718]\t Weight2: [1.50484307]\t Bias: [2.94873473]\t Cost: 15.454749280732603\n",
            "Iteration: 1196\t Weight1: [8.86807488]\t Weight2: [1.50412396]\t Bias: [2.94772849]\t Cost: 15.454659525070573\n",
            "Iteration: 1197\t Weight1: [8.86859129]\t Weight2: [1.5034064]\t Bias: [2.94672552]\t Cost: 15.45457027449587\n",
            "Iteration: 1198\t Weight1: [8.86910642]\t Weight2: [1.5026904]\t Bias: [2.94572579]\t Cost: 15.4544815260803\n",
            "Iteration: 1199\t Weight1: [8.86962026]\t Weight2: [1.50197594]\t Bias: [2.9447293]\t Cost: 15.454393276913251\n",
            "Iteration: 1200\t Weight1: [8.87013283]\t Weight2: [1.50126303]\t Bias: [2.94373604]\t Cost: 15.454305524101596\n",
            "Iteration: 1201\t Weight1: [8.87064412]\t Weight2: [1.50055166]\t Bias: [2.942746]\t Cost: 15.454218264769588\n",
            "Iteration: 1202\t Weight1: [8.87115414]\t Weight2: [1.49984184]\t Bias: [2.94175916]\t Cost: 15.454131496058777\n",
            "Iteration: 1203\t Weight1: [8.87166289]\t Weight2: [1.49913355]\t Bias: [2.94077552]\t Cost: 15.454045215127856\n",
            "Iteration: 1204\t Weight1: [8.87217038]\t Weight2: [1.4984268]\t Bias: [2.93979506]\t Cost: 15.45395941915254\n",
            "Iteration: 1205\t Weight1: [8.8726766]\t Weight2: [1.49772158]\t Bias: [2.93881778]\t Cost: 15.453874105325566\n",
            "Iteration: 1206\t Weight1: [8.87318156]\t Weight2: [1.49701789]\t Bias: [2.93784366]\t Cost: 15.453789270856447\n",
            "Iteration: 1207\t Weight1: [8.87368527]\t Weight2: [1.49631572]\t Bias: [2.93687269]\t Cost: 15.453704912971496\n",
            "Iteration: 1208\t Weight1: [8.87418773]\t Weight2: [1.49561508]\t Bias: [2.93590487]\t Cost: 15.453621028913581\n",
            "Iteration: 1209\t Weight1: [8.87468893]\t Weight2: [1.49491596]\t Bias: [2.93494017]\t Cost: 15.453537615942162\n",
            "Iteration: 1210\t Weight1: [8.87518888]\t Weight2: [1.49421836]\t Bias: [2.9339786]\t Cost: 15.453454671333112\n",
            "Iteration: 1211\t Weight1: [8.8756876]\t Weight2: [1.49352227]\t Bias: [2.93302014]\t Cost: 15.453372192378616\n",
            "Iteration: 1212\t Weight1: [8.87618507]\t Weight2: [1.4928277]\t Bias: [2.93206477]\t Cost: 15.453290176387085\n",
            "Iteration: 1213\t Weight1: [8.8766813]\t Weight2: [1.49213464]\t Bias: [2.9311125]\t Cost: 15.453208620683046\n",
            "Iteration: 1214\t Weight1: [8.87717629]\t Weight2: [1.49144308]\t Bias: [2.9301633]\t Cost: 15.45312752260706\n",
            "Iteration: 1215\t Weight1: [8.87767006]\t Weight2: [1.49075303]\t Bias: [2.92921718]\t Cost: 15.45304687951561\n",
            "Iteration: 1216\t Weight1: [8.87816259]\t Weight2: [1.49006448]\t Bias: [2.92827411]\t Cost: 15.452966688780963\n",
            "Iteration: 1217\t Weight1: [8.8786539]\t Weight2: [1.48937743]\t Bias: [2.92733409]\t Cost: 15.452886947791166\n",
            "Iteration: 1218\t Weight1: [8.87914399]\t Weight2: [1.48869187]\t Bias: [2.9263971]\t Cost: 15.45280765394983\n",
            "Iteration: 1219\t Weight1: [8.87963285]\t Weight2: [1.48800781]\t Bias: [2.92546315]\t Cost: 15.452728804676138\n",
            "Iteration: 1220\t Weight1: [8.8801205]\t Weight2: [1.48732524]\t Bias: [2.92453221]\t Cost: 15.452650397404701\n",
            "Iteration: 1221\t Weight1: [8.88060693]\t Weight2: [1.48664416]\t Bias: [2.92360428]\t Cost: 15.452572429585441\n",
            "Iteration: 1222\t Weight1: [8.88109215]\t Weight2: [1.48596456]\t Bias: [2.92267934]\t Cost: 15.452494898683522\n",
            "Iteration: 1223\t Weight1: [8.88157616]\t Weight2: [1.48528644]\t Bias: [2.92175739]\t Cost: 15.45241780217926\n",
            "Iteration: 1224\t Weight1: [8.88205897]\t Weight2: [1.48460981]\t Bias: [2.92083842]\t Cost: 15.45234113756804\n",
            "Iteration: 1225\t Weight1: [8.88254057]\t Weight2: [1.48393465]\t Bias: [2.91992242]\t Cost: 15.452264902360163\n",
            "Iteration: 1226\t Weight1: [8.88302098]\t Weight2: [1.48326097]\t Bias: [2.91900937]\t Cost: 15.452189094080826\n",
            "Iteration: 1227\t Weight1: [8.88350018]\t Weight2: [1.48258875]\t Bias: [2.91809927]\t Cost: 15.452113710269996\n",
            "Iteration: 1228\t Weight1: [8.8839782]\t Weight2: [1.48191801]\t Bias: [2.91719211]\t Cost: 15.452038748482291\n",
            "Iteration: 1229\t Weight1: [8.88445502]\t Weight2: [1.48124873]\t Bias: [2.91628787]\t Cost: 15.45196420628697\n",
            "Iteration: 1230\t Weight1: [8.88493065]\t Weight2: [1.48058092]\t Bias: [2.91538655]\t Cost: 15.451890081267715\n",
            "Iteration: 1231\t Weight1: [8.8854051]\t Weight2: [1.47991457]\t Bias: [2.91448814]\t Cost: 15.451816371022682\n",
            "Iteration: 1232\t Weight1: [8.88587836]\t Weight2: [1.47924967]\t Bias: [2.91359262]\t Cost: 15.451743073164312\n",
            "Iteration: 1233\t Weight1: [8.88635045]\t Weight2: [1.47858623]\t Bias: [2.91269999]\t Cost: 15.45167018531928\n",
            "Iteration: 1234\t Weight1: [8.88682136]\t Weight2: [1.47792424]\t Bias: [2.91181024]\t Cost: 15.451597705128417\n",
            "Iteration: 1235\t Weight1: [8.88729109]\t Weight2: [1.47726371]\t Bias: [2.91092336]\t Cost: 15.451525630246586\n",
            "Iteration: 1236\t Weight1: [8.88775966]\t Weight2: [1.47660462]\t Bias: [2.91003934]\t Cost: 15.451453958342636\n",
            "Iteration: 1237\t Weight1: [8.88822705]\t Weight2: [1.47594697]\t Bias: [2.90915817]\t Cost: 15.451382687099281\n",
            "Iteration: 1238\t Weight1: [8.88869328]\t Weight2: [1.47529077]\t Bias: [2.90827983]\t Cost: 15.451311814213028\n",
            "Iteration: 1239\t Weight1: [8.88915835]\t Weight2: [1.474636]\t Bias: [2.90740433]\t Cost: 15.451241337394114\n",
            "Iteration: 1240\t Weight1: [8.88962226]\t Weight2: [1.47398267]\t Bias: [2.90653165]\t Cost: 15.451171254366388\n",
            "Iteration: 1241\t Weight1: [8.89008501]\t Weight2: [1.47333078]\t Bias: [2.90566178]\t Cost: 15.451101562867219\n",
            "Iteration: 1242\t Weight1: [8.89054661]\t Weight2: [1.47268031]\t Bias: [2.90479471]\t Cost: 15.451032260647446\n",
            "Iteration: 1243\t Weight1: [8.89100705]\t Weight2: [1.47203128]\t Bias: [2.90393043]\t Cost: 15.450963345471285\n",
            "Iteration: 1244\t Weight1: [8.89146635]\t Weight2: [1.47138367]\t Bias: [2.90306893]\t Cost: 15.450894815116254\n",
            "Iteration: 1245\t Weight1: [8.8919245]\t Weight2: [1.47073748]\t Bias: [2.90221021]\t Cost: 15.450826667373049\n",
            "Iteration: 1246\t Weight1: [8.89238151]\t Weight2: [1.47009272]\t Bias: [2.90135426]\t Cost: 15.450758900045503\n",
            "Iteration: 1247\t Weight1: [8.89283738]\t Weight2: [1.46944937]\t Bias: [2.90050105]\t Cost: 15.450691510950495\n",
            "Iteration: 1248\t Weight1: [8.89329211]\t Weight2: [1.46880744]\t Bias: [2.8996506]\t Cost: 15.450624497917872\n",
            "Iteration: 1249\t Weight1: [8.89374571]\t Weight2: [1.46816691]\t Bias: [2.89880288]\t Cost: 15.45055785879037\n",
            "Iteration: 1250\t Weight1: [8.89419817]\t Weight2: [1.4675278]\t Bias: [2.89795788]\t Cost: 15.450491591423498\n",
            "Iteration: 1251\t Weight1: [8.89464951]\t Weight2: [1.4668901]\t Bias: [2.89711561]\t Cost: 15.450425693685538\n",
            "Iteration: 1252\t Weight1: [8.89509972]\t Weight2: [1.4662538]\t Bias: [2.89627604]\t Cost: 15.45036016345738\n",
            "Iteration: 1253\t Weight1: [8.8955488]\t Weight2: [1.4656189]\t Bias: [2.89543918]\t Cost: 15.450294998632499\n",
            "Iteration: 1254\t Weight1: [8.89599677]\t Weight2: [1.4649854]\t Bias: [2.894605]\t Cost: 15.450230197116852\n",
            "Iteration: 1255\t Weight1: [8.89644362]\t Weight2: [1.4643533]\t Bias: [2.89377351]\t Cost: 15.45016575682883\n",
            "Iteration: 1256\t Weight1: [8.89688935]\t Weight2: [1.46372259]\t Bias: [2.89294469]\t Cost: 15.450101675699134\n",
            "Iteration: 1257\t Weight1: [8.89733397]\t Weight2: [1.46309327]\t Bias: [2.89211853]\t Cost: 15.45003795167074\n",
            "Iteration: 1258\t Weight1: [8.89777748]\t Weight2: [1.46246534]\t Bias: [2.89129503]\t Cost: 15.449974582698815\n",
            "Iteration: 1259\t Weight1: [8.89821988]\t Weight2: [1.4618388]\t Bias: [2.89047418]\t Cost: 15.449911566750645\n",
            "Iteration: 1260\t Weight1: [8.89866118]\t Weight2: [1.46121364]\t Bias: [2.88965596]\t Cost: 15.449848901805513\n",
            "Iteration: 1261\t Weight1: [8.89910137]\t Weight2: [1.46058986]\t Bias: [2.88884037]\t Cost: 15.449786585854715\n",
            "Iteration: 1262\t Weight1: [8.89954047]\t Weight2: [1.45996746]\t Bias: [2.8880274]\t Cost: 15.449724616901385\n",
            "Iteration: 1263\t Weight1: [8.89997847]\t Weight2: [1.45934643]\t Bias: [2.88721704]\t Cost: 15.449662992960524\n",
            "Iteration: 1264\t Weight1: [8.90041537]\t Weight2: [1.45872678]\t Bias: [2.88640929]\t Cost: 15.449601712058847\n",
            "Iteration: 1265\t Weight1: [8.90085119]\t Weight2: [1.45810849]\t Bias: [2.88560412]\t Cost: 15.449540772234734\n",
            "Iteration: 1266\t Weight1: [8.90128591]\t Weight2: [1.45749158]\t Bias: [2.88480154]\t Cost: 15.449480171538157\n",
            "Iteration: 1267\t Weight1: [8.90171956]\t Weight2: [1.45687603]\t Bias: [2.88400154]\t Cost: 15.449419908030665\n",
            "Iteration: 1268\t Weight1: [8.90215211]\t Weight2: [1.45626184]\t Bias: [2.88320411]\t Cost: 15.449359979785186\n",
            "Iteration: 1269\t Weight1: [8.90258359]\t Weight2: [1.45564901]\t Bias: [2.88240923]\t Cost: 15.449300384886126\n",
            "Iteration: 1270\t Weight1: [8.90301399]\t Weight2: [1.45503754]\t Bias: [2.8816169]\t Cost: 15.449241121429129\n",
            "Iteration: 1271\t Weight1: [8.90344331]\t Weight2: [1.45442742]\t Bias: [2.88082712]\t Cost: 15.449182187521112\n",
            "Iteration: 1272\t Weight1: [8.90387156]\t Weight2: [1.45381866]\t Bias: [2.88003987]\t Cost: 15.44912358128018\n",
            "Iteration: 1273\t Weight1: [8.90429874]\t Weight2: [1.45321124]\t Bias: [2.87925514]\t Cost: 15.44906530083554\n",
            "Iteration: 1274\t Weight1: [8.90472486]\t Weight2: [1.45260517]\t Bias: [2.87847293]\t Cost: 15.449007344327448\n",
            "Iteration: 1275\t Weight1: [8.9051499]\t Weight2: [1.45200045]\t Bias: [2.87769323]\t Cost: 15.448949709907112\n",
            "Iteration: 1276\t Weight1: [8.90557389]\t Weight2: [1.45139706]\t Bias: [2.87691603]\t Cost: 15.448892395736644\n",
            "Iteration: 1277\t Weight1: [8.90599682]\t Weight2: [1.45079502]\t Bias: [2.87614131]\t Cost: 15.448835399989056\n",
            "Iteration: 1278\t Weight1: [8.90641869]\t Weight2: [1.45019431]\t Bias: [2.87536908]\t Cost: 15.448778720848045\n",
            "Iteration: 1279\t Weight1: [8.9068395]\t Weight2: [1.44959494]\t Bias: [2.87459933]\t Cost: 15.448722356508046\n",
            "Iteration: 1280\t Weight1: [8.90725926]\t Weight2: [1.44899689]\t Bias: [2.87383204]\t Cost: 15.448666305174196\n",
            "Iteration: 1281\t Weight1: [8.90767798]\t Weight2: [1.44840018]\t Bias: [2.87306721]\t Cost: 15.448610565062104\n",
            "Iteration: 1282\t Weight1: [8.90809564]\t Weight2: [1.44780479]\t Bias: [2.87230483]\t Cost: 15.448555134397989\n",
            "Iteration: 1283\t Weight1: [8.90851227]\t Weight2: [1.44721073]\t Bias: [2.87154489]\t Cost: 15.448500011418428\n",
            "Iteration: 1284\t Weight1: [8.90892785]\t Weight2: [1.44661798]\t Bias: [2.87078739]\t Cost: 15.448445194370432\n",
            "Iteration: 1285\t Weight1: [8.90934239]\t Weight2: [1.44602656]\t Bias: [2.87003231]\t Cost: 15.448390681511338\n",
            "Iteration: 1286\t Weight1: [8.9097559]\t Weight2: [1.44543645]\t Bias: [2.86927965]\t Cost: 15.448336471108707\n",
            "Iteration: 1287\t Weight1: [8.91016837]\t Weight2: [1.44484765]\t Bias: [2.86852939]\t Cost: 15.448282561440323\n",
            "Iteration: 1288\t Weight1: [8.91057981]\t Weight2: [1.44426017]\t Bias: [2.86778154]\t Cost: 15.448228950794068\n",
            "Iteration: 1289\t Weight1: [8.91099022]\t Weight2: [1.44367399]\t Bias: [2.86703608]\t Cost: 15.448175637467934\n",
            "Iteration: 1290\t Weight1: [8.9113996]\t Weight2: [1.44308912]\t Bias: [2.86629301]\t Cost: 15.448122619769881\n",
            "Iteration: 1291\t Weight1: [8.91180796]\t Weight2: [1.44250555]\t Bias: [2.86555231]\t Cost: 15.448069896017827\n",
            "Iteration: 1292\t Weight1: [8.9122153]\t Weight2: [1.44192329]\t Bias: [2.86481398]\t Cost: 15.448017464539609\n",
            "Iteration: 1293\t Weight1: [8.91262162]\t Weight2: [1.44134232]\t Bias: [2.86407802]\t Cost: 15.447965323672856\n",
            "Iteration: 1294\t Weight1: [8.91302692]\t Weight2: [1.44076265]\t Bias: [2.8633444]\t Cost: 15.447913471764945\n",
            "Iteration: 1295\t Weight1: [8.91343121]\t Weight2: [1.44018427]\t Bias: [2.86261314]\t Cost: 15.447861907172996\n",
            "Iteration: 1296\t Weight1: [8.91383449]\t Weight2: [1.43960718]\t Bias: [2.86188421]\t Cost: 15.447810628263758\n",
            "Iteration: 1297\t Weight1: [8.91423676]\t Weight2: [1.43903138]\t Bias: [2.86115761]\t Cost: 15.44775963341358\n",
            "Iteration: 1298\t Weight1: [8.91463802]\t Weight2: [1.43845686]\t Bias: [2.86043333]\t Cost: 15.447708921008338\n",
            "Iteration: 1299\t Weight1: [8.91503828]\t Weight2: [1.43788363]\t Bias: [2.85971137]\t Cost: 15.447658489443352\n",
            "Iteration: 1300\t Weight1: [8.91543753]\t Weight2: [1.43731168]\t Bias: [2.85899171]\t Cost: 15.447608337123388\n",
            "Iteration: 1301\t Weight1: [8.91583579]\t Weight2: [1.436741]\t Bias: [2.85827435]\t Cost: 15.44755846246256\n",
            "Iteration: 1302\t Weight1: [8.91623305]\t Weight2: [1.43617161]\t Bias: [2.85755929]\t Cost: 15.447508863884254\n",
            "Iteration: 1303\t Weight1: [8.91662931]\t Weight2: [1.43560348]\t Bias: [2.85684651]\t Cost: 15.447459539821155\n",
            "Iteration: 1304\t Weight1: [8.91702459]\t Weight2: [1.43503663]\t Bias: [2.856136]\t Cost: 15.447410488715084\n",
            "Iteration: 1305\t Weight1: [8.91741887]\t Weight2: [1.43447104]\t Bias: [2.85542777]\t Cost: 15.447361709017011\n",
            "Iteration: 1306\t Weight1: [8.91781217]\t Weight2: [1.43390672]\t Bias: [2.85472179]\t Cost: 15.447313199186983\n",
            "Iteration: 1307\t Weight1: [8.91820448]\t Weight2: [1.43334366]\t Bias: [2.85401807]\t Cost: 15.447264957694056\n",
            "Iteration: 1308\t Weight1: [8.91859581]\t Weight2: [1.43278186]\t Bias: [2.85331659]\t Cost: 15.44721698301626\n",
            "Iteration: 1309\t Weight1: [8.91898616]\t Weight2: [1.43222133]\t Bias: [2.85261735]\t Cost: 15.447169273640537\n",
            "Iteration: 1310\t Weight1: [8.91937553]\t Weight2: [1.43166204]\t Bias: [2.85192035]\t Cost: 15.44712182806267\n",
            "Iteration: 1311\t Weight1: [8.91976393]\t Weight2: [1.43110401]\t Bias: [2.85122556]\t Cost: 15.447074644787262\n",
            "Iteration: 1312\t Weight1: [8.92015136]\t Weight2: [1.43054723]\t Bias: [2.850533]\t Cost: 15.447027722327674\n",
            "Iteration: 1313\t Weight1: [8.92053781]\t Weight2: [1.4299917]\t Bias: [2.84984264]\t Cost: 15.4469810592059\n",
            "Iteration: 1314\t Weight1: [8.9209233]\t Weight2: [1.42943742]\t Bias: [2.84915448]\t Cost: 15.446934653952681\n",
            "Iteration: 1315\t Weight1: [8.92130782]\t Weight2: [1.42888438]\t Bias: [2.84846852]\t Cost: 15.446888505107237\n",
            "Iteration: 1316\t Weight1: [8.92169138]\t Weight2: [1.42833258]\t Bias: [2.84778475]\t Cost: 15.446842611217416\n",
            "Iteration: 1317\t Weight1: [8.92207397]\t Weight2: [1.42778201]\t Bias: [2.84710315]\t Cost: 15.4467969708395\n",
            "Iteration: 1318\t Weight1: [8.92245561]\t Weight2: [1.42723269]\t Bias: [2.84642373]\t Cost: 15.446751582538223\n",
            "Iteration: 1319\t Weight1: [8.92283629]\t Weight2: [1.4266846]\t Bias: [2.84574647]\t Cost: 15.446706444886697\n",
            "Iteration: 1320\t Weight1: [8.92321602]\t Weight2: [1.42613773]\t Bias: [2.84507137]\t Cost: 15.446661556466387\n",
            "Iteration: 1321\t Weight1: [8.9235948]\t Weight2: [1.4255921]\t Bias: [2.84439842]\t Cost: 15.446616915866993\n",
            "Iteration: 1322\t Weight1: [8.92397263]\t Weight2: [1.4250477]\t Bias: [2.84372762]\t Cost: 15.446572521686516\n",
            "Iteration: 1323\t Weight1: [8.92434951]\t Weight2: [1.42450451]\t Bias: [2.84305895]\t Cost: 15.446528372531082\n",
            "Iteration: 1324\t Weight1: [8.92472545]\t Weight2: [1.42396255]\t Bias: [2.84239241]\t Cost: 15.446484467014965\n",
            "Iteration: 1325\t Weight1: [8.92510044]\t Weight2: [1.42342181]\t Bias: [2.84172799]\t Cost: 15.44644080376054\n",
            "Iteration: 1326\t Weight1: [8.9254745]\t Weight2: [1.42288228]\t Bias: [2.84106569]\t Cost: 15.446397381398185\n",
            "Iteration: 1327\t Weight1: [8.92584762]\t Weight2: [1.42234397]\t Bias: [2.8404055]\t Cost: 15.44635419856631\n",
            "Iteration: 1328\t Weight1: [8.9262198]\t Weight2: [1.42180687]\t Bias: [2.8397474]\t Cost: 15.446311253911219\n",
            "Iteration: 1329\t Weight1: [8.92659105]\t Weight2: [1.42127098]\t Bias: [2.83909141]\t Cost: 15.446268546087122\n",
            "Iteration: 1330\t Weight1: [8.92696137]\t Weight2: [1.4207363]\t Bias: [2.8384375]\t Cost: 15.446226073756051\n",
            "Iteration: 1331\t Weight1: [8.92733076]\t Weight2: [1.42020282]\t Bias: [2.83778567]\t Cost: 15.446183835587902\n",
            "Iteration: 1332\t Weight1: [8.92769922]\t Weight2: [1.41967055]\t Bias: [2.83713591]\t Cost: 15.446141830260233\n",
            "Iteration: 1333\t Weight1: [8.92806676]\t Weight2: [1.41913947]\t Bias: [2.83648822]\t Cost: 15.446100056458329\n",
            "Iteration: 1334\t Weight1: [8.92843338]\t Weight2: [1.41860959]\t Bias: [2.83584259]\t Cost: 15.446058512875169\n",
            "Iteration: 1335\t Weight1: [8.92879908]\t Weight2: [1.4180809]\t Bias: [2.83519901]\t Cost: 15.446017198211294\n",
            "Iteration: 1336\t Weight1: [8.92916386]\t Weight2: [1.41755341]\t Bias: [2.83455748]\t Cost: 15.445976111174819\n",
            "Iteration: 1337\t Weight1: [8.92952773]\t Weight2: [1.41702711]\t Bias: [2.83391799]\t Cost: 15.445935250481378\n",
            "Iteration: 1338\t Weight1: [8.92989069]\t Weight2: [1.416502]\t Bias: [2.83328053]\t Cost: 15.445894614854087\n",
            "Iteration: 1339\t Weight1: [8.93025273]\t Weight2: [1.41597807]\t Bias: [2.8326451]\t Cost: 15.44585420302346\n",
            "Iteration: 1340\t Weight1: [8.93061387]\t Weight2: [1.41545532]\t Bias: [2.83201169]\t Cost: 15.445814013727414\n",
            "Iteration: 1341\t Weight1: [8.9309741]\t Weight2: [1.41493376]\t Bias: [2.83138029]\t Cost: 15.445774045711218\n",
            "Iteration: 1342\t Weight1: [8.93133343]\t Weight2: [1.41441337]\t Bias: [2.83075089]\t Cost: 15.445734297727384\n",
            "Iteration: 1343\t Weight1: [8.93169185]\t Weight2: [1.41389416]\t Bias: [2.83012349]\t Cost: 15.445694768535715\n",
            "Iteration: 1344\t Weight1: [8.93204938]\t Weight2: [1.41337613]\t Bias: [2.82949809]\t Cost: 15.445655456903204\n",
            "Iteration: 1345\t Weight1: [8.93240601]\t Weight2: [1.41285926]\t Bias: [2.82887467]\t Cost: 15.445616361603992\n",
            "Iteration: 1346\t Weight1: [8.93276174]\t Weight2: [1.41234356]\t Bias: [2.82825323]\t Cost: 15.445577481419368\n",
            "Iteration: 1347\t Weight1: [8.93311659]\t Weight2: [1.41182903]\t Bias: [2.82763377]\t Cost: 15.445538815137676\n",
            "Iteration: 1348\t Weight1: [8.93347054]\t Weight2: [1.41131567]\t Bias: [2.82701627]\t Cost: 15.445500361554302\n",
            "Iteration: 1349\t Weight1: [8.9338236]\t Weight2: [1.41080346]\t Bias: [2.82640073]\t Cost: 15.445462119471598\n",
            "Iteration: 1350\t Weight1: [8.93417578]\t Weight2: [1.41029242]\t Bias: [2.82578714]\t Cost: 15.445424087698905\n",
            "Iteration: 1351\t Weight1: [8.93452707]\t Weight2: [1.40978253]\t Bias: [2.8251755]\t Cost: 15.445386265052441\n",
            "Iteration: 1352\t Weight1: [8.93487749]\t Weight2: [1.4092738]\t Bias: [2.8245658]\t Cost: 15.445348650355276\n",
            "Iteration: 1353\t Weight1: [8.93522702]\t Weight2: [1.40876622]\t Bias: [2.82395804]\t Cost: 15.445311242437358\n",
            "Iteration: 1354\t Weight1: [8.93557568]\t Weight2: [1.40825979]\t Bias: [2.8233522]\t Cost: 15.44527404013537\n",
            "Iteration: 1355\t Weight1: [8.93592346]\t Weight2: [1.40775451]\t Bias: [2.82274828]\t Cost: 15.445237042292737\n",
            "Iteration: 1356\t Weight1: [8.93627036]\t Weight2: [1.40725037]\t Bias: [2.82214628]\t Cost: 15.445200247759619\n",
            "Iteration: 1357\t Weight1: [8.9366164]\t Weight2: [1.40674738]\t Bias: [2.82154619]\t Cost: 15.445163655392816\n",
            "Iteration: 1358\t Weight1: [8.93696157]\t Weight2: [1.40624553]\t Bias: [2.820948]\t Cost: 15.445127264055715\n",
            "Iteration: 1359\t Weight1: [8.93730587]\t Weight2: [1.40574481]\t Bias: [2.8203517]\t Cost: 15.445091072618382\n",
            "Iteration: 1360\t Weight1: [8.93764931]\t Weight2: [1.40524524]\t Bias: [2.81975729]\t Cost: 15.445055079957303\n",
            "Iteration: 1361\t Weight1: [8.93799188]\t Weight2: [1.40474679]\t Bias: [2.81916477]\t Cost: 15.445019284955558\n",
            "Iteration: 1362\t Weight1: [8.93833359]\t Weight2: [1.40424948]\t Bias: [2.81857413]\t Cost: 15.444983686502649\n",
            "Iteration: 1363\t Weight1: [8.93867445]\t Weight2: [1.4037533]\t Bias: [2.81798535]\t Cost: 15.444948283494519\n",
            "Iteration: 1364\t Weight1: [8.93901445]\t Weight2: [1.40325825]\t Bias: [2.81739844]\t Cost: 15.444913074833485\n",
            "Iteration: 1365\t Weight1: [8.9393536]\t Weight2: [1.40276432]\t Bias: [2.81681339]\t Cost: 15.444878059428211\n",
            "Iteration: 1366\t Weight1: [8.93969189]\t Weight2: [1.40227151]\t Bias: [2.81623019]\t Cost: 15.444843236193693\n",
            "Iteration: 1367\t Weight1: [8.94002933]\t Weight2: [1.40177982]\t Bias: [2.81564884]\t Cost: 15.444808604051177\n",
            "Iteration: 1368\t Weight1: [8.94036593]\t Weight2: [1.40128925]\t Bias: [2.81506933]\t Cost: 15.444774161928155\n",
            "Iteration: 1369\t Weight1: [8.94070168]\t Weight2: [1.4007998]\t Bias: [2.81449165]\t Cost: 15.444739908758292\n",
            "Iteration: 1370\t Weight1: [8.94103659]\t Weight2: [1.40031146]\t Bias: [2.8139158]\t Cost: 15.444705843481456\n",
            "Iteration: 1371\t Weight1: [8.94137066]\t Weight2: [1.39982423]\t Bias: [2.81334177]\t Cost: 15.444671965043618\n",
            "Iteration: 1372\t Weight1: [8.94170388]\t Weight2: [1.39933811]\t Bias: [2.81276956]\t Cost: 15.444638272396823\n",
            "Iteration: 1373\t Weight1: [8.94203627]\t Weight2: [1.3988531]\t Bias: [2.81219916]\t Cost: 15.444604764499172\n",
            "Iteration: 1374\t Weight1: [8.94236783]\t Weight2: [1.39836919]\t Bias: [2.81163056]\t Cost: 15.444571440314778\n",
            "Iteration: 1375\t Weight1: [8.94269855]\t Weight2: [1.39788638]\t Bias: [2.81106376]\t Cost: 15.444538298813749\n",
            "Iteration: 1376\t Weight1: [8.94302844]\t Weight2: [1.39740468]\t Bias: [2.81049875]\t Cost: 15.444505338972139\n",
            "Iteration: 1377\t Weight1: [8.9433575]\t Weight2: [1.39692407]\t Bias: [2.80993553]\t Cost: 15.444472559771873\n",
            "Iteration: 1378\t Weight1: [8.94368574]\t Weight2: [1.39644456]\t Bias: [2.80937409]\t Cost: 15.444439960200773\n",
            "Iteration: 1379\t Weight1: [8.94401315]\t Weight2: [1.39596614]\t Bias: [2.80881442]\t Cost: 15.444407539252495\n",
            "Iteration: 1380\t Weight1: [8.94433974]\t Weight2: [1.39548881]\t Bias: [2.80825653]\t Cost: 15.444375295926509\n",
            "Iteration: 1381\t Weight1: [8.9446655]\t Weight2: [1.39501257]\t Bias: [2.80770039]\t Cost: 15.444343229228027\n",
            "Iteration: 1382\t Weight1: [8.94499045]\t Weight2: [1.39453741]\t Bias: [2.80714601]\t Cost: 15.44431133816799\n",
            "Iteration: 1383\t Weight1: [8.94531458]\t Weight2: [1.39406334]\t Bias: [2.80659339]\t Cost: 15.444279621763078\n",
            "Iteration: 1384\t Weight1: [8.94563789]\t Weight2: [1.39359035]\t Bias: [2.80604251]\t Cost: 15.444248079035589\n",
            "Iteration: 1385\t Weight1: [8.9459604]\t Weight2: [1.39311845]\t Bias: [2.80549336]\t Cost: 15.44421670901349\n",
            "Iteration: 1386\t Weight1: [8.94628209]\t Weight2: [1.39264761]\t Bias: [2.80494596]\t Cost: 15.444185510730323\n",
            "Iteration: 1387\t Weight1: [8.94660297]\t Weight2: [1.39217786]\t Bias: [2.80440028]\t Cost: 15.444154483225178\n",
            "Iteration: 1388\t Weight1: [8.94692305]\t Weight2: [1.39170918]\t Bias: [2.80385632]\t Cost: 15.444123625542726\n",
            "Iteration: 1389\t Weight1: [8.94724232]\t Weight2: [1.39124157]\t Bias: [2.80331408]\t Cost: 15.44409293673309\n",
            "Iteration: 1390\t Weight1: [8.94756079]\t Weight2: [1.39077503]\t Bias: [2.80277355]\t Cost: 15.444062415851866\n",
            "Iteration: 1391\t Weight1: [8.94787846]\t Weight2: [1.39030955]\t Bias: [2.80223473]\t Cost: 15.444032061960096\n",
            "Iteration: 1392\t Weight1: [8.94819532]\t Weight2: [1.38984514]\t Bias: [2.80169761]\t Cost: 15.44400187412421\n",
            "Iteration: 1393\t Weight1: [8.9485114]\t Weight2: [1.38938179]\t Bias: [2.80116218]\t Cost: 15.443971851416018\n",
            "Iteration: 1394\t Weight1: [8.94882667]\t Weight2: [1.3889195]\t Bias: [2.80062844]\t Cost: 15.44394199291266\n",
            "Iteration: 1395\t Weight1: [8.94914116]\t Weight2: [1.38845827]\t Bias: [2.80009638]\t Cost: 15.443912297696567\n",
            "Iteration: 1396\t Weight1: [8.94945485]\t Weight2: [1.38799809]\t Bias: [2.799566]\t Cost: 15.443882764855463\n",
            "Iteration: 1397\t Weight1: [8.94976775]\t Weight2: [1.38753897]\t Bias: [2.7990373]\t Cost: 15.443853393482296\n",
            "Iteration: 1398\t Weight1: [8.95007987]\t Weight2: [1.3870809]\t Bias: [2.79851026]\t Cost: 15.443824182675224\n",
            "Iteration: 1399\t Weight1: [8.9503912]\t Weight2: [1.38662388]\t Bias: [2.79798488]\t Cost: 15.443795131537618\n",
            "Iteration: 1400\t Weight1: [8.95070175]\t Weight2: [1.3861679]\t Bias: [2.79746115]\t Cost: 15.44376623917795\n",
            "Iteration: 1401\t Weight1: [8.95101152]\t Weight2: [1.38571297]\t Bias: [2.79693908]\t Cost: 15.44373750470983\n",
            "Iteration: 1402\t Weight1: [8.9513205]\t Weight2: [1.38525909]\t Bias: [2.79641865]\t Cost: 15.443708927251961\n",
            "Iteration: 1403\t Weight1: [8.95162871]\t Weight2: [1.38480624]\t Bias: [2.79589987]\t Cost: 15.443680505928114\n",
            "Iteration: 1404\t Weight1: [8.95193615]\t Weight2: [1.38435443]\t Bias: [2.79538271]\t Cost: 15.443652239867035\n",
            "Iteration: 1405\t Weight1: [8.95224281]\t Weight2: [1.38390366]\t Bias: [2.79486719]\t Cost: 15.443624128202536\n",
            "Iteration: 1406\t Weight1: [8.9525487]\t Weight2: [1.38345392]\t Bias: [2.79435328]\t Cost: 15.443596170073342\n",
            "Iteration: 1407\t Weight1: [8.95285382]\t Weight2: [1.38300521]\t Bias: [2.793841]\t Cost: 15.443568364623147\n",
            "Iteration: 1408\t Weight1: [8.95315817]\t Weight2: [1.38255754]\t Bias: [2.79333033]\t Cost: 15.443540711000544\n",
            "Iteration: 1409\t Weight1: [8.95346175]\t Weight2: [1.38211089]\t Bias: [2.79282126]\t Cost: 15.443513208358997\n",
            "Iteration: 1410\t Weight1: [8.95376457]\t Weight2: [1.38166526]\t Bias: [2.7923138]\t Cost: 15.443485855856828\n",
            "Iteration: 1411\t Weight1: [8.95406663]\t Weight2: [1.38122066]\t Bias: [2.79180794]\t Cost: 15.443458652657213\n",
            "Iteration: 1412\t Weight1: [8.95436793]\t Weight2: [1.38077708]\t Bias: [2.79130366]\t Cost: 15.443431597928047\n",
            "Iteration: 1413\t Weight1: [8.95466847]\t Weight2: [1.38033452]\t Bias: [2.79080098]\t Cost: 15.443404690842051\n",
            "Iteration: 1414\t Weight1: [8.95496825]\t Weight2: [1.37989298]\t Bias: [2.79029987]\t Cost: 15.443377930576666\n",
            "Iteration: 1415\t Weight1: [8.95526728]\t Weight2: [1.37945245]\t Bias: [2.78980034]\t Cost: 15.443351316314061\n",
            "Iteration: 1416\t Weight1: [8.95556556]\t Weight2: [1.37901294]\t Bias: [2.78930238]\t Cost: 15.443324847241017\n",
            "Iteration: 1417\t Weight1: [8.95586308]\t Weight2: [1.37857443]\t Bias: [2.78880599]\t Cost: 15.443298522549068\n",
            "Iteration: 1418\t Weight1: [8.95615986]\t Weight2: [1.37813693]\t Bias: [2.78831116]\t Cost: 15.443272341434295\n",
            "Iteration: 1419\t Weight1: [8.95645589]\t Weight2: [1.37770044]\t Bias: [2.78781788]\t Cost: 15.443246303097393\n",
            "Iteration: 1420\t Weight1: [8.95675117]\t Weight2: [1.37726496]\t Bias: [2.78732615]\t Cost: 15.443220406743665\n",
            "Iteration: 1421\t Weight1: [8.95704571]\t Weight2: [1.37683047]\t Bias: [2.78683597]\t Cost: 15.44319465158293\n",
            "Iteration: 1422\t Weight1: [8.9573395]\t Weight2: [1.37639699]\t Bias: [2.78634733]\t Cost: 15.443169036829508\n",
            "Iteration: 1423\t Weight1: [8.95763256]\t Weight2: [1.3759645]\t Bias: [2.78586022]\t Cost: 15.443143561702243\n",
            "Iteration: 1424\t Weight1: [8.95792488]\t Weight2: [1.37553301]\t Bias: [2.78537465]\t Cost: 15.443118225424422\n",
            "Iteration: 1425\t Weight1: [8.95821646]\t Weight2: [1.37510252]\t Bias: [2.7848906]\t Cost: 15.443093027223775\n",
            "Iteration: 1426\t Weight1: [8.95850731]\t Weight2: [1.37467301]\t Bias: [2.78440807]\t Cost: 15.443067966332434\n",
            "Iteration: 1427\t Weight1: [8.95879743]\t Weight2: [1.3742445]\t Bias: [2.78392705]\t Cost: 15.443043041986952\n",
            "Iteration: 1428\t Weight1: [8.95908681]\t Weight2: [1.37381697]\t Bias: [2.78344755]\t Cost: 15.44301825342819\n",
            "Iteration: 1429\t Weight1: [8.95937547]\t Weight2: [1.37339043]\t Bias: [2.78296954]\t Cost: 15.442993599901378\n",
            "Iteration: 1430\t Weight1: [8.95966339]\t Weight2: [1.37296487]\t Bias: [2.78249304]\t Cost: 15.44296908065604\n",
            "Iteration: 1431\t Weight1: [8.9599506]\t Weight2: [1.3725403]\t Bias: [2.78201804]\t Cost: 15.442944694945979\n",
            "Iteration: 1432\t Weight1: [8.96023708]\t Weight2: [1.3721167]\t Bias: [2.78154453]\t Cost: 15.442920442029292\n",
            "Iteration: 1433\t Weight1: [8.96052283]\t Weight2: [1.37169408]\t Bias: [2.7810725]\t Cost: 15.44289632116823\n",
            "Iteration: 1434\t Weight1: [8.96080787]\t Weight2: [1.37127244]\t Bias: [2.78060195]\t Cost: 15.442872331629355\n",
            "Iteration: 1435\t Weight1: [8.96109219]\t Weight2: [1.37085177]\t Bias: [2.78013288]\t Cost: 15.442848472683322\n",
            "Iteration: 1436\t Weight1: [8.96137579]\t Weight2: [1.37043207]\t Bias: [2.77966528]\t Cost: 15.442824743604971\n",
            "Iteration: 1437\t Weight1: [8.96165868]\t Weight2: [1.37001334]\t Bias: [2.77919914]\t Cost: 15.442801143673329\n",
            "Iteration: 1438\t Weight1: [8.96194085]\t Weight2: [1.36959557]\t Bias: [2.77873447]\t Cost: 15.442777672171419\n",
            "Iteration: 1439\t Weight1: [8.96222232]\t Weight2: [1.36917877]\t Bias: [2.77827125]\t Cost: 15.442754328386478\n",
            "Iteration: 1440\t Weight1: [8.96250307]\t Weight2: [1.36876294]\t Bias: [2.77780949]\t Cost: 15.442731111609715\n",
            "Iteration: 1441\t Weight1: [8.96278312]\t Weight2: [1.36834806]\t Bias: [2.77734917]\t Cost: 15.442708021136388\n",
            "Iteration: 1442\t Weight1: [8.96306246]\t Weight2: [1.36793415]\t Bias: [2.77689029]\t Cost: 15.442685056265816\n",
            "Iteration: 1443\t Weight1: [8.96334109]\t Weight2: [1.36752119]\t Bias: [2.77643285]\t Cost: 15.442662216301231\n",
            "Iteration: 1444\t Weight1: [8.96361903]\t Weight2: [1.36710918]\t Bias: [2.77597685]\t Cost: 15.442639500549912\n",
            "Iteration: 1445\t Weight1: [8.96389626]\t Weight2: [1.36669813]\t Bias: [2.77552227]\t Cost: 15.44261690832304\n",
            "Iteration: 1446\t Weight1: [8.96417279]\t Weight2: [1.36628803]\t Bias: [2.77506912]\t Cost: 15.442594438935695\n",
            "Iteration: 1447\t Weight1: [8.96444863]\t Weight2: [1.36587888]\t Bias: [2.77461739]\t Cost: 15.442572091706886\n",
            "Iteration: 1448\t Weight1: [8.96472377]\t Weight2: [1.36547068]\t Bias: [2.77416707]\t Cost: 15.442549865959501\n",
            "Iteration: 1449\t Weight1: [8.96499822]\t Weight2: [1.36506342]\t Bias: [2.77371816]\t Cost: 15.442527761020228\n",
            "Iteration: 1450\t Weight1: [8.96527197]\t Weight2: [1.3646571]\t Bias: [2.77327065]\t Cost: 15.442505776219681\n",
            "Iteration: 1451\t Weight1: [8.96554504]\t Weight2: [1.36425173]\t Bias: [2.77282455]\t Cost: 15.442483910892156\n",
            "Iteration: 1452\t Weight1: [8.96581741]\t Weight2: [1.36384729]\t Bias: [2.77237984]\t Cost: 15.442462164375838\n",
            "Iteration: 1453\t Weight1: [8.9660891]\t Weight2: [1.36344379]\t Bias: [2.77193653]\t Cost: 15.44244053601261\n",
            "Iteration: 1454\t Weight1: [8.9663601]\t Weight2: [1.36304123]\t Bias: [2.7714946]\t Cost: 15.442419025148117\n",
            "Iteration: 1455\t Weight1: [8.96663042]\t Weight2: [1.36263959]\t Bias: [2.77105405]\t Cost: 15.442397631131701\n",
            "Iteration: 1456\t Weight1: [8.96690006]\t Weight2: [1.36223889]\t Bias: [2.77061488]\t Cost: 15.442376353316448\n",
            "Iteration: 1457\t Weight1: [8.96716902]\t Weight2: [1.36183912]\t Bias: [2.77017708]\t Cost: 15.442355191059088\n",
            "Iteration: 1458\t Weight1: [8.9674373]\t Weight2: [1.36144028]\t Bias: [2.76974066]\t Cost: 15.442334143719954\n",
            "Iteration: 1459\t Weight1: [8.9677049]\t Weight2: [1.36104236]\t Bias: [2.76930559]\t Cost: 15.442313210663107\n",
            "Iteration: 1460\t Weight1: [8.96797183]\t Weight2: [1.36064536]\t Bias: [2.76887189]\t Cost: 15.442292391256144\n",
            "Iteration: 1461\t Weight1: [8.96823809]\t Weight2: [1.36024929]\t Bias: [2.76843954]\t Cost: 15.442271684870283\n",
            "Iteration: 1462\t Weight1: [8.96850367]\t Weight2: [1.35985413]\t Bias: [2.76800855]\t Cost: 15.442251090880308\n",
            "Iteration: 1463\t Weight1: [8.96876858]\t Weight2: [1.35945989]\t Bias: [2.7675789]\t Cost: 15.442230608664513\n",
            "Iteration: 1464\t Weight1: [8.96903282]\t Weight2: [1.35906657]\t Bias: [2.76715059]\t Cost: 15.442210237604785\n",
            "Iteration: 1465\t Weight1: [8.9692964]\t Weight2: [1.35867416]\t Bias: [2.76672362]\t Cost: 15.442189977086446\n",
            "Iteration: 1466\t Weight1: [8.96955931]\t Weight2: [1.35828266]\t Bias: [2.76629798]\t Cost: 15.44216982649836\n",
            "Iteration: 1467\t Weight1: [8.96982156]\t Weight2: [1.35789207]\t Bias: [2.76587368]\t Cost: 15.442149785232807\n",
            "Iteration: 1468\t Weight1: [8.97008315]\t Weight2: [1.35750239]\t Bias: [2.76545069]\t Cost: 15.442129852685545\n",
            "Iteration: 1469\t Weight1: [8.97034407]\t Weight2: [1.35711361]\t Bias: [2.76502903]\t Cost: 15.442110028255758\n",
            "Iteration: 1470\t Weight1: [8.97060434]\t Weight2: [1.35672574]\t Bias: [2.76460869]\t Cost: 15.442090311345979\n",
            "Iteration: 1471\t Weight1: [8.97086395]\t Weight2: [1.35633877]\t Bias: [2.76418966]\t Cost: 15.442070701362196\n",
            "Iteration: 1472\t Weight1: [8.97112291]\t Weight2: [1.3559527]\t Bias: [2.76377193]\t Cost: 15.442051197713717\n",
            "Iteration: 1473\t Weight1: [8.97138121]\t Weight2: [1.35556752]\t Bias: [2.76335551]\t Cost: 15.44203179981324\n",
            "Iteration: 1474\t Weight1: [8.97163886]\t Weight2: [1.35518325]\t Bias: [2.76294039]\t Cost: 15.442012507076711\n",
            "Iteration: 1475\t Weight1: [8.97189586]\t Weight2: [1.35479986]\t Bias: [2.76252656]\t Cost: 15.441993318923467\n",
            "Iteration: 1476\t Weight1: [8.97215221]\t Weight2: [1.35441737]\t Bias: [2.76211402]\t Cost: 15.44197423477606\n",
            "Iteration: 1477\t Weight1: [8.97240791]\t Weight2: [1.35403577]\t Bias: [2.76170277]\t Cost: 15.441955254060357\n",
            "Iteration: 1478\t Weight1: [8.97266297]\t Weight2: [1.35365506]\t Bias: [2.7612928]\t Cost: 15.441936376205438\n",
            "Iteration: 1479\t Weight1: [8.97291738]\t Weight2: [1.35327523]\t Bias: [2.76088411]\t Cost: 15.441917600643656\n",
            "Iteration: 1480\t Weight1: [8.97317115]\t Weight2: [1.35289629]\t Bias: [2.7604767]\t Cost: 15.441898926810524\n",
            "Iteration: 1481\t Weight1: [8.97342428]\t Weight2: [1.35251823]\t Bias: [2.76007055]\t Cost: 15.441880354144766\n",
            "Iteration: 1482\t Weight1: [8.97367677]\t Weight2: [1.35214106]\t Bias: [2.75966567]\t Cost: 15.441861882088302\n",
            "Iteration: 1483\t Weight1: [8.97392863]\t Weight2: [1.35176476]\t Bias: [2.75926205]\t Cost: 15.441843510086182\n",
            "Iteration: 1484\t Weight1: [8.97417984]\t Weight2: [1.35138934]\t Bias: [2.75885969]\t Cost: 15.44182523758659\n",
            "Iteration: 1485\t Weight1: [8.97443043]\t Weight2: [1.35101479]\t Bias: [2.75845858]\t Cost: 15.441807064040843\n",
            "Iteration: 1486\t Weight1: [8.97468038]\t Weight2: [1.35064112]\t Bias: [2.75805872]\t Cost: 15.441788988903337\n",
            "Iteration: 1487\t Weight1: [8.9749297]\t Weight2: [1.35026831]\t Bias: [2.75766011]\t Cost: 15.441771011631559\n",
            "Iteration: 1488\t Weight1: [8.97517838]\t Weight2: [1.34989638]\t Bias: [2.75726274]\t Cost: 15.441753131686085\n",
            "Iteration: 1489\t Weight1: [8.97542644]\t Weight2: [1.34952532]\t Bias: [2.75686661]\t Cost: 15.441735348530486\n",
            "Iteration: 1490\t Weight1: [8.97567388]\t Weight2: [1.34915512]\t Bias: [2.7564717]\t Cost: 15.441717661631403\n",
            "Iteration: 1491\t Weight1: [8.97592069]\t Weight2: [1.34878578]\t Bias: [2.75607803]\t Cost: 15.441700070458477\n",
            "Iteration: 1492\t Weight1: [8.97616687]\t Weight2: [1.34841731]\t Bias: [2.75568559]\t Cost: 15.44168257448432\n",
            "Iteration: 1493\t Weight1: [8.97641244]\t Weight2: [1.34804969]\t Bias: [2.75529436]\t Cost: 15.441665173184543\n",
            "Iteration: 1494\t Weight1: [8.97665738]\t Weight2: [1.34768294]\t Bias: [2.75490435]\t Cost: 15.441647866037723\n",
            "Iteration: 1495\t Weight1: [8.9769017]\t Weight2: [1.34731704]\t Bias: [2.75451556]\t Cost: 15.441630652525339\n",
            "Iteration: 1496\t Weight1: [8.97714541]\t Weight2: [1.346952]\t Bias: [2.75412797]\t Cost: 15.44161353213184\n",
            "Iteration: 1497\t Weight1: [8.9773885]\t Weight2: [1.34658781]\t Bias: [2.75374159]\t Cost: 15.441596504344531\n",
            "Iteration: 1498\t Weight1: [8.97763098]\t Weight2: [1.34622447]\t Bias: [2.75335641]\t Cost: 15.44157956865368\n",
            "Iteration: 1499\t Weight1: [8.97787284]\t Weight2: [1.34586198]\t Bias: [2.75297243]\t Cost: 15.441562724552325\n",
            "Iteration: 1500\t Weight1: [8.97811409]\t Weight2: [1.34550033]\t Bias: [2.75258965]\t Cost: 15.441545971536483\n",
            "Iteration: 1501\t Weight1: [8.97835473]\t Weight2: [1.34513953]\t Bias: [2.75220805]\t Cost: 15.441529309104894\n",
            "Iteration: 1502\t Weight1: [8.97859477]\t Weight2: [1.34477958]\t Bias: [2.75182764]\t Cost: 15.441512736759208\n",
            "Iteration: 1503\t Weight1: [8.9788342]\t Weight2: [1.34442047]\t Bias: [2.75144841]\t Cost: 15.44149625400384\n",
            "Iteration: 1504\t Weight1: [8.97907302]\t Weight2: [1.34406219]\t Bias: [2.75107036]\t Cost: 15.441479860345966\n",
            "Iteration: 1505\t Weight1: [8.97931124]\t Weight2: [1.34370476]\t Bias: [2.75069348]\t Cost: 15.44146355529563\n",
            "Iteration: 1506\t Weight1: [8.97954885]\t Weight2: [1.34334816]\t Bias: [2.75031778]\t Cost: 15.441447338365549\n",
            "Iteration: 1507\t Weight1: [8.97978587]\t Weight2: [1.3429924]\t Bias: [2.74994324]\t Cost: 15.441431209071217\n",
            "Iteration: 1508\t Weight1: [8.98002229]\t Weight2: [1.34263747]\t Bias: [2.74956987]\t Cost: 15.44141516693085\n",
            "Iteration: 1509\t Weight1: [8.9802581]\t Weight2: [1.34228337]\t Bias: [2.74919765]\t Cost: 15.441399211465376\n",
            "Iteration: 1510\t Weight1: [8.98049333]\t Weight2: [1.3419301]\t Bias: [2.74882659]\t Cost: 15.4413833421984\n",
            "Iteration: 1511\t Weight1: [8.98072796]\t Weight2: [1.34157766]\t Bias: [2.74845668]\t Cost: 15.441367558656252\n",
            "Iteration: 1512\t Weight1: [8.98096199]\t Weight2: [1.34122604]\t Bias: [2.74808792]\t Cost: 15.441351860367863\n",
            "Iteration: 1513\t Weight1: [8.98119543]\t Weight2: [1.34087524]\t Bias: [2.74772031]\t Cost: 15.441336246864852\n",
            "Iteration: 1514\t Weight1: [8.98142829]\t Weight2: [1.34052527]\t Bias: [2.74735383]\t Cost: 15.441320717681483\n",
            "Iteration: 1515\t Weight1: [8.98166055]\t Weight2: [1.34017612]\t Bias: [2.74698849]\t Cost: 15.441305272354604\n",
            "Iteration: 1516\t Weight1: [8.98189223]\t Weight2: [1.33982779]\t Bias: [2.74662429]\t Cost: 15.441289910423688\n",
            "Iteration: 1517\t Weight1: [8.98212332]\t Weight2: [1.33948027]\t Bias: [2.74626122]\t Cost: 15.44127463143078\n",
            "Iteration: 1518\t Weight1: [8.98235382]\t Weight2: [1.33913357]\t Bias: [2.74589927]\t Cost: 15.441259434920509\n",
            "Iteration: 1519\t Weight1: [8.98258375]\t Weight2: [1.33878768]\t Bias: [2.74553844]\t Cost: 15.441244320440052\n",
            "Iteration: 1520\t Weight1: [8.98281309]\t Weight2: [1.33844261]\t Bias: [2.74517873]\t Cost: 15.441229287539146\n",
            "Iteration: 1521\t Weight1: [8.98304185]\t Weight2: [1.33809834]\t Bias: [2.74482014]\t Cost: 15.441214335770033\n",
            "Iteration: 1522\t Weight1: [8.98327003]\t Weight2: [1.33775488]\t Bias: [2.74446266]\t Cost: 15.441199464687493\n",
            "Iteration: 1523\t Weight1: [8.98349764]\t Weight2: [1.33741223]\t Bias: [2.74410629]\t Cost: 15.441184673848793\n",
            "Iteration: 1524\t Weight1: [8.98372467]\t Weight2: [1.33707038]\t Bias: [2.74375102]\t Cost: 15.441169962813676\n",
            "Iteration: 1525\t Weight1: [8.98395112]\t Weight2: [1.33672933]\t Bias: [2.74339685]\t Cost: 15.44115533114437\n",
            "Iteration: 1526\t Weight1: [8.984177]\t Weight2: [1.33638909]\t Bias: [2.74304378]\t Cost: 15.44114077840553\n",
            "Iteration: 1527\t Weight1: [8.98440231]\t Weight2: [1.33604964]\t Bias: [2.74269181]\t Cost: 15.441126304164314\n",
            "Iteration: 1528\t Weight1: [8.98462706]\t Weight2: [1.33571099]\t Bias: [2.74234092]\t Cost: 15.441111907990237\n",
            "Iteration: 1529\t Weight1: [8.98485123]\t Weight2: [1.33537314]\t Bias: [2.74199112]\t Cost: 15.441097589455287\n",
            "Iteration: 1530\t Weight1: [8.98507483]\t Weight2: [1.33503608]\t Bias: [2.7416424]\t Cost: 15.441083348133803\n",
            "Iteration: 1531\t Weight1: [8.98529787]\t Weight2: [1.33469981]\t Bias: [2.74129477]\t Cost: 15.441069183602536\n",
            "Iteration: 1532\t Weight1: [8.98552035]\t Weight2: [1.33436434]\t Bias: [2.7409482]\t Cost: 15.441055095440621\n",
            "Iteration: 1533\t Weight1: [8.98574226]\t Weight2: [1.33402965]\t Bias: [2.74060272]\t Cost: 15.441041083229518\n",
            "Iteration: 1534\t Weight1: [8.98596361]\t Weight2: [1.33369575]\t Bias: [2.7402583]\t Cost: 15.441027146553061\n",
            "Iteration: 1535\t Weight1: [8.9861844]\t Weight2: [1.33336263]\t Bias: [2.73991494]\t Cost: 15.44101328499738\n",
            "Iteration: 1536\t Weight1: [8.98640463]\t Weight2: [1.3330303]\t Bias: [2.73957265]\t Cost: 15.440999498150966\n",
            "Iteration: 1537\t Weight1: [8.9866243]\t Weight2: [1.33269875]\t Bias: [2.73923142]\t Cost: 15.440985785604592\n",
            "Iteration: 1538\t Weight1: [8.98684342]\t Weight2: [1.33236798]\t Bias: [2.73889124]\t Cost: 15.440972146951324\n",
            "Iteration: 1539\t Weight1: [8.98706198]\t Weight2: [1.33203799]\t Bias: [2.73855212]\t Cost: 15.440958581786509\n",
            "Iteration: 1540\t Weight1: [8.98727999]\t Weight2: [1.33170877]\t Bias: [2.73821404]\t Cost: 15.440945089707759\n",
            "Iteration: 1541\t Weight1: [8.98749745]\t Weight2: [1.33138033]\t Bias: [2.73787701]\t Cost: 15.440931670314916\n",
            "Iteration: 1542\t Weight1: [8.98771436]\t Weight2: [1.33105267]\t Bias: [2.73754102]\t Cost: 15.440918323210127\n",
            "Iteration: 1543\t Weight1: [8.98793072]\t Weight2: [1.33072577]\t Bias: [2.73720607]\t Cost: 15.440905047997672\n",
            "Iteration: 1544\t Weight1: [8.98814653]\t Weight2: [1.33039965]\t Bias: [2.73687216]\t Cost: 15.440891844284106\n",
            "Iteration: 1545\t Weight1: [8.98836179]\t Weight2: [1.33007429]\t Bias: [2.73653928]\t Cost: 15.440878711678184\n",
            "Iteration: 1546\t Weight1: [8.98857651]\t Weight2: [1.3297497]\t Bias: [2.73620742]\t Cost: 15.44086564979081\n",
            "Iteration: 1547\t Weight1: [8.98879068]\t Weight2: [1.32942587]\t Bias: [2.73587659]\t Cost: 15.440852658235116\n",
            "Iteration: 1548\t Weight1: [8.98900432]\t Weight2: [1.32910281]\t Bias: [2.73554678]\t Cost: 15.440839736626348\n",
            "Iteration: 1549\t Weight1: [8.98921741]\t Weight2: [1.32878051]\t Bias: [2.735218]\t Cost: 15.440826884581927\n",
            "Iteration: 1550\t Weight1: [8.98942996]\t Weight2: [1.32845897]\t Bias: [2.73489022]\t Cost: 15.440814101721411\n",
            "Iteration: 1551\t Weight1: [8.98964198]\t Weight2: [1.32813819]\t Bias: [2.73456346]\t Cost: 15.440801387666488\n",
            "Iteration: 1552\t Weight1: [8.98985345]\t Weight2: [1.32781816]\t Bias: [2.73423771]\t Cost: 15.440788742040937\n",
            "Iteration: 1553\t Weight1: [8.99006439]\t Weight2: [1.32749889]\t Bias: [2.73391296]\t Cost: 15.440776164470657\n",
            "Iteration: 1554\t Weight1: [8.9902748]\t Weight2: [1.32718038]\t Bias: [2.73358922]\t Cost: 15.440763654583643\n",
            "Iteration: 1555\t Weight1: [8.99048468]\t Weight2: [1.32686261]\t Bias: [2.73326647]\t Cost: 15.440751212009948\n",
            "Iteration: 1556\t Weight1: [8.99069402]\t Weight2: [1.32654559]\t Bias: [2.73294472]\t Cost: 15.440738836381708\n",
            "Iteration: 1557\t Weight1: [8.99090283]\t Weight2: [1.32622933]\t Bias: [2.73262396]\t Cost: 15.440726527333089\n",
            "Iteration: 1558\t Weight1: [8.99111111]\t Weight2: [1.3259138]\t Bias: [2.7323042]\t Cost: 15.440714284500336\n",
            "Iteration: 1559\t Weight1: [8.99131887]\t Weight2: [1.32559903]\t Bias: [2.73198542]\t Cost: 15.440702107521675\n",
            "Iteration: 1560\t Weight1: [8.9915261]\t Weight2: [1.325285]\t Bias: [2.73166762]\t Cost: 15.440689996037397\n",
            "Iteration: 1561\t Weight1: [8.9917328]\t Weight2: [1.3249717]\t Bias: [2.7313508]\t Cost: 15.440677949689768\n",
            "Iteration: 1562\t Weight1: [8.99193898]\t Weight2: [1.32465915]\t Bias: [2.73103496]\t Cost: 15.440665968123076\n",
            "Iteration: 1563\t Weight1: [8.99214464]\t Weight2: [1.32434734]\t Bias: [2.73072009]\t Cost: 15.440654050983555\n",
            "Iteration: 1564\t Weight1: [8.99234978]\t Weight2: [1.32403627]\t Bias: [2.73040619]\t Cost: 15.440642197919447\n",
            "Iteration: 1565\t Weight1: [8.9925544]\t Weight2: [1.32372593]\t Bias: [2.73009326]\t Cost: 15.440630408580944\n",
            "Iteration: 1566\t Weight1: [8.9927585]\t Weight2: [1.32341632]\t Bias: [2.7297813]\t Cost: 15.440618682620183\n",
            "Iteration: 1567\t Weight1: [8.99296208]\t Weight2: [1.32310744]\t Bias: [2.72947029]\t Cost: 15.44060701969124\n",
            "Iteration: 1568\t Weight1: [8.99316515]\t Weight2: [1.3227993]\t Bias: [2.72916025]\t Cost: 15.44059541945013\n",
            "Iteration: 1569\t Weight1: [8.9933677]\t Weight2: [1.32249188]\t Bias: [2.72885116]\t Cost: 15.440583881554769\n",
            "Iteration: 1570\t Weight1: [8.99356973]\t Weight2: [1.32218519]\t Bias: [2.72854302]\t Cost: 15.440572405664991\n",
            "Iteration: 1571\t Weight1: [8.99377126]\t Weight2: [1.32187923]\t Bias: [2.72823583]\t Cost: 15.440560991442505\n",
            "Iteration: 1572\t Weight1: [8.99397228]\t Weight2: [1.32157399]\t Bias: [2.72792958]\t Cost: 15.440549638550936\n",
            "Iteration: 1573\t Weight1: [8.99417278]\t Weight2: [1.32126948]\t Bias: [2.72762428]\t Cost: 15.440538346655767\n",
            "Iteration: 1574\t Weight1: [8.99437278]\t Weight2: [1.32096568]\t Bias: [2.72731992]\t Cost: 15.44052711542432\n",
            "Iteration: 1575\t Weight1: [8.99457227]\t Weight2: [1.3206626]\t Bias: [2.7270165]\t Cost: 15.440515944525819\n",
            "Iteration: 1576\t Weight1: [8.99477126]\t Weight2: [1.32036024]\t Bias: [2.726714]\t Cost: 15.440504833631277\n",
            "Iteration: 1577\t Weight1: [8.99496974]\t Weight2: [1.3200586]\t Bias: [2.72641244]\t Cost: 15.440493782413558\n",
            "Iteration: 1578\t Weight1: [8.99516771]\t Weight2: [1.31975767]\t Bias: [2.72611181]\t Cost: 15.44048279054736\n",
            "Iteration: 1579\t Weight1: [8.99536519]\t Weight2: [1.31945745]\t Bias: [2.7258121]\t Cost: 15.440471857709184\n",
            "Iteration: 1580\t Weight1: [8.99556216]\t Weight2: [1.31915795]\t Bias: [2.72551332]\t Cost: 15.44046098357731\n",
            "Iteration: 1581\t Weight1: [8.99575864]\t Weight2: [1.31885915]\t Bias: [2.72521545]\t Cost: 15.440450167831829\n",
            "Iteration: 1582\t Weight1: [8.99595462]\t Weight2: [1.31856107]\t Bias: [2.7249185]\t Cost: 15.440439410154605\n",
            "Iteration: 1583\t Weight1: [8.9961501]\t Weight2: [1.31826369]\t Bias: [2.72462246]\t Cost: 15.44042871022927\n",
            "Iteration: 1584\t Weight1: [8.99634508]\t Weight2: [1.31796701]\t Bias: [2.72432733]\t Cost: 15.440418067741232\n",
            "Iteration: 1585\t Weight1: [8.99653957]\t Weight2: [1.31767104]\t Bias: [2.72403311]\t Cost: 15.440407482377605\n",
            "Iteration: 1586\t Weight1: [8.99673357]\t Weight2: [1.31737577]\t Bias: [2.7237398]\t Cost: 15.440396953827282\n",
            "Iteration: 1587\t Weight1: [8.99692707]\t Weight2: [1.3170812]\t Bias: [2.72344738]\t Cost: 15.440386481780857\n",
            "Iteration: 1588\t Weight1: [8.99712009]\t Weight2: [1.31678732]\t Bias: [2.72315587]\t Cost: 15.44037606593068\n",
            "Iteration: 1589\t Weight1: [8.99731261]\t Weight2: [1.31649415]\t Bias: [2.72286524]\t Cost: 15.440365705970764\n",
            "Iteration: 1590\t Weight1: [8.99750465]\t Weight2: [1.31620167]\t Bias: [2.72257552]\t Cost: 15.440355401596852\n",
            "Iteration: 1591\t Weight1: [8.9976962]\t Weight2: [1.31590988]\t Bias: [2.72228668]\t Cost: 15.440345152506362\n",
            "Iteration: 1592\t Weight1: [8.99788726]\t Weight2: [1.31561879]\t Bias: [2.72199873]\t Cost: 15.440334958398406\n",
            "Iteration: 1593\t Weight1: [8.99807784]\t Weight2: [1.31532839]\t Bias: [2.72171166]\t Cost: 15.44032481897376\n",
            "Iteration: 1594\t Weight1: [8.99826794]\t Weight2: [1.31503868]\t Bias: [2.72142547]\t Cost: 15.440314733934844\n",
            "Iteration: 1595\t Weight1: [8.99845755]\t Weight2: [1.31474965]\t Bias: [2.72114017]\t Cost: 15.440304702985765\n",
            "Iteration: 1596\t Weight1: [8.99864668]\t Weight2: [1.31446132]\t Bias: [2.72085573]\t Cost: 15.440294725832237\n",
            "Iteration: 1597\t Weight1: [8.99883534]\t Weight2: [1.31417366]\t Bias: [2.72057217]\t Cost: 15.440284802181624\n",
            "Iteration: 1598\t Weight1: [8.99902351]\t Weight2: [1.31388669]\t Bias: [2.72028949]\t Cost: 15.44027493174292\n",
            "Iteration: 1599\t Weight1: [8.99921121]\t Weight2: [1.31360041]\t Bias: [2.72000766]\t Cost: 15.440265114226712\n",
            "Iteration: 1600\t Weight1: [8.99939843]\t Weight2: [1.3133148]\t Bias: [2.71972671]\t Cost: 15.440255349345211\n",
            "Iteration: 1601\t Weight1: [8.99958517]\t Weight2: [1.31302987]\t Bias: [2.71944661]\t Cost: 15.440245636812222\n",
            "Iteration: 1602\t Weight1: [8.99977145]\t Weight2: [1.31274562]\t Bias: [2.71916738]\t Cost: 15.44023597634311\n",
            "Iteration: 1603\t Weight1: [8.99995724]\t Weight2: [1.31246204]\t Bias: [2.718889]\t Cost: 15.44022636765486\n",
            "Iteration: 1604\t Weight1: [9.00014257]\t Weight2: [1.31217914]\t Bias: [2.71861147]\t Cost: 15.440216810465992\n",
            "Iteration: 1605\t Weight1: [9.00032743]\t Weight2: [1.31189691]\t Bias: [2.71833479]\t Cost: 15.440207304496607\n",
            "Iteration: 1606\t Weight1: [9.00051182]\t Weight2: [1.31161535]\t Bias: [2.71805897]\t Cost: 15.440197849468353\n",
            "Iteration: 1607\t Weight1: [9.00069574]\t Weight2: [1.31133446]\t Bias: [2.71778398]\t Cost: 15.440188445104388\n",
            "Iteration: 1608\t Weight1: [9.00087919]\t Weight2: [1.31105424]\t Bias: [2.71750985]\t Cost: 15.440179091129476\n",
            "Iteration: 1609\t Weight1: [9.00106218]\t Weight2: [1.31077469]\t Bias: [2.71723655]\t Cost: 15.44016978726983\n",
            "Iteration: 1610\t Weight1: [9.0012447]\t Weight2: [1.3104958]\t Bias: [2.71696408]\t Cost: 15.440160533253223\n",
            "Iteration: 1611\t Weight1: [9.00142676]\t Weight2: [1.31021758]\t Bias: [2.71669246]\t Cost: 15.44015132880891\n",
            "Iteration: 1612\t Weight1: [9.00160836]\t Weight2: [1.30994002]\t Bias: [2.71642166]\t Cost: 15.440142173667663\n",
            "Iteration: 1613\t Weight1: [9.0017895]\t Weight2: [1.30966312]\t Bias: [2.71615169]\t Cost: 15.44013306756174\n",
            "Iteration: 1614\t Weight1: [9.00197018]\t Weight2: [1.30938688]\t Bias: [2.71588255]\t Cost: 15.440124010224869\n",
            "Iteration: 1615\t Weight1: [9.00215039]\t Weight2: [1.30911129]\t Bias: [2.71561424]\t Cost: 15.440115001392268\n",
            "Iteration: 1616\t Weight1: [9.00233016]\t Weight2: [1.30883636]\t Bias: [2.71534674]\t Cost: 15.44010604080063\n",
            "Iteration: 1617\t Weight1: [9.00250946]\t Weight2: [1.30856209]\t Bias: [2.71508007]\t Cost: 15.440097128188057\n",
            "Iteration: 1618\t Weight1: [9.00268831]\t Weight2: [1.30828847]\t Bias: [2.71481421]\t Cost: 15.440088263294165\n",
            "Iteration: 1619\t Weight1: [9.00286671]\t Weight2: [1.30801551]\t Bias: [2.71454916]\t Cost: 15.440079445859952\n",
            "Iteration: 1620\t Weight1: [9.00304465]\t Weight2: [1.30774319]\t Bias: [2.71428493]\t Cost: 15.44007067562788\n",
            "Iteration: 1621\t Weight1: [9.00322214]\t Weight2: [1.30747152]\t Bias: [2.7140215]\t Cost: 15.440061952341821\n",
            "Iteration: 1622\t Weight1: [9.00339918]\t Weight2: [1.3072005]\t Bias: [2.71375888]\t Cost: 15.440053275747081\n",
            "Iteration: 1623\t Weight1: [9.00357577]\t Weight2: [1.30693013]\t Bias: [2.71349706]\t Cost: 15.440044645590357\n",
            "Iteration: 1624\t Weight1: [9.00375191]\t Weight2: [1.3066604]\t Bias: [2.71323605]\t Cost: 15.440036061619743\n",
            "Iteration: 1625\t Weight1: [9.00392761]\t Weight2: [1.30639131]\t Bias: [2.71297583]\t Cost: 15.440027523584748\n",
            "Iteration: 1626\t Weight1: [9.00410286]\t Weight2: [1.30612287]\t Bias: [2.71271641]\t Cost: 15.440019031236238\n",
            "Iteration: 1627\t Weight1: [9.00427766]\t Weight2: [1.30585507]\t Bias: [2.71245778]\t Cost: 15.440010584326464\n",
            "Iteration: 1628\t Weight1: [9.00445202]\t Weight2: [1.3055879]\t Bias: [2.71219994]\t Cost: 15.44000218260907\n",
            "Iteration: 1629\t Weight1: [9.00462594]\t Weight2: [1.30532137]\t Bias: [2.71194288]\t Cost: 15.439993825839021\n",
            "Iteration: 1630\t Weight1: [9.00479941]\t Weight2: [1.30505548]\t Bias: [2.71168662]\t Cost: 15.439985513772664\n",
            "Iteration: 1631\t Weight1: [9.00497245]\t Weight2: [1.30479023]\t Bias: [2.71143113]\t Cost: 15.439977246167672\n",
            "Iteration: 1632\t Weight1: [9.00514504]\t Weight2: [1.3045256]\t Bias: [2.71117643]\t Cost: 15.439969022783076\n",
            "Iteration: 1633\t Weight1: [9.0053172]\t Weight2: [1.30426161]\t Bias: [2.71092251]\t Cost: 15.43996084337921\n",
            "Iteration: 1634\t Weight1: [9.00548892]\t Weight2: [1.30399825]\t Bias: [2.71066936]\t Cost: 15.439952707717767\n",
            "Iteration: 1635\t Weight1: [9.0056602]\t Weight2: [1.30373552]\t Bias: [2.71041698]\t Cost: 15.439944615561705\n",
            "Iteration: 1636\t Weight1: [9.00583105]\t Weight2: [1.30347341]\t Bias: [2.71016537]\t Cost: 15.43993656667535\n",
            "Iteration: 1637\t Weight1: [9.00600147]\t Weight2: [1.30321194]\t Bias: [2.70991454]\t Cost: 15.439928560824281\n",
            "Iteration: 1638\t Weight1: [9.00617145]\t Weight2: [1.30295108]\t Bias: [2.70966446]\t Cost: 15.439920597775403\n",
            "Iteration: 1639\t Weight1: [9.006341]\t Weight2: [1.30269085]\t Bias: [2.70941516]\t Cost: 15.439912677296874\n",
            "Iteration: 1640\t Weight1: [9.00651012]\t Weight2: [1.30243124]\t Bias: [2.70916661]\t Cost: 15.439904799158146\n",
            "Iteration: 1641\t Weight1: [9.00667881]\t Weight2: [1.30217225]\t Bias: [2.70891882]\t Cost: 15.439896963129964\n",
            "Iteration: 1642\t Weight1: [9.00684707]\t Weight2: [1.30191389]\t Bias: [2.70867178]\t Cost: 15.439889168984301\n",
            "Iteration: 1643\t Weight1: [9.0070149]\t Weight2: [1.30165613]\t Bias: [2.7084255]\t Cost: 15.4398814164944\n",
            "Iteration: 1644\t Weight1: [9.00718231]\t Weight2: [1.301399]\t Bias: [2.70817997]\t Cost: 15.439873705434756\n",
            "Iteration: 1645\t Weight1: [9.00734929]\t Weight2: [1.30114248]\t Bias: [2.70793519]\t Cost: 15.439866035581117\n",
            "Iteration: 1646\t Weight1: [9.00751584]\t Weight2: [1.30088657]\t Bias: [2.70769116]\t Cost: 15.439858406710437\n",
            "Iteration: 1647\t Weight1: [9.00768198]\t Weight2: [1.30063128]\t Bias: [2.70744787]\t Cost: 15.439850818600947\n",
            "Iteration: 1648\t Weight1: [9.00784769]\t Weight2: [1.3003766]\t Bias: [2.70720532]\t Cost: 15.439843271032055\n",
            "Iteration: 1649\t Weight1: [9.00801298]\t Weight2: [1.30012252]\t Bias: [2.70696351]\t Cost: 15.439835763784377\n",
            "Iteration: 1650\t Weight1: [9.00817785]\t Weight2: [1.29986906]\t Bias: [2.70672244]\t Cost: 15.439828296639822\n",
            "Iteration: 1651\t Weight1: [9.0083423]\t Weight2: [1.2996162]\t Bias: [2.7064821]\t Cost: 15.43982086938138\n",
            "Iteration: 1652\t Weight1: [9.00850633]\t Weight2: [1.29936394]\t Bias: [2.7062425]\t Cost: 15.439813481793312\n",
            "Iteration: 1653\t Weight1: [9.00866995]\t Weight2: [1.29911229]\t Bias: [2.70600362]\t Cost: 15.439806133661055\n",
            "Iteration: 1654\t Weight1: [9.00883315]\t Weight2: [1.29886124]\t Bias: [2.70576548]\t Cost: 15.439798824771223\n",
            "Iteration: 1655\t Weight1: [9.00899594]\t Weight2: [1.2986108]\t Bias: [2.70552806]\t Cost: 15.439791554911585\n",
            "Iteration: 1656\t Weight1: [9.00915831]\t Weight2: [1.29836095]\t Bias: [2.70529136]\t Cost: 15.439784323871121\n",
            "Iteration: 1657\t Weight1: [9.00932027]\t Weight2: [1.2981117]\t Bias: [2.70505538]\t Cost: 15.439777131439913\n",
            "Iteration: 1658\t Weight1: [9.00948181]\t Weight2: [1.29786305]\t Bias: [2.70482012]\t Cost: 15.43976997740925\n",
            "Iteration: 1659\t Weight1: [9.00964295]\t Weight2: [1.297615]\t Bias: [2.70458557]\t Cost: 15.439762861571563\n",
            "Iteration: 1660\t Weight1: [9.00980368]\t Weight2: [1.29736754]\t Bias: [2.70435174]\t Cost: 15.439755783720377\n",
            "Iteration: 1661\t Weight1: [9.00996399]\t Weight2: [1.29712067]\t Bias: [2.70411863]\t Cost: 15.439748743650416\n",
            "Iteration: 1662\t Weight1: [9.0101239]\t Weight2: [1.29687439]\t Bias: [2.70388622]\t Cost: 15.439741741157505\n",
            "Iteration: 1663\t Weight1: [9.01028341]\t Weight2: [1.29662871]\t Bias: [2.70365451]\t Cost: 15.439734776038579\n",
            "Iteration: 1664\t Weight1: [9.01044251]\t Weight2: [1.29638361]\t Bias: [2.70342352]\t Cost: 15.43972784809168\n",
            "Iteration: 1665\t Weight1: [9.0106012]\t Weight2: [1.2961391]\t Bias: [2.70319322]\t Cost: 15.439720957116021\n",
            "Iteration: 1666\t Weight1: [9.01075949]\t Weight2: [1.29589518]\t Bias: [2.70296363]\t Cost: 15.439714102911863\n",
            "Iteration: 1667\t Weight1: [9.01091738]\t Weight2: [1.29565184]\t Bias: [2.70273473]\t Cost: 15.439707285280553\n",
            "Iteration: 1668\t Weight1: [9.01107487]\t Weight2: [1.29540909]\t Bias: [2.70250653]\t Cost: 15.439700504024604\n",
            "Iteration: 1669\t Weight1: [9.01123195]\t Weight2: [1.29516691]\t Bias: [2.70227903]\t Cost: 15.439693758947532\n",
            "Iteration: 1670\t Weight1: [9.01138864]\t Weight2: [1.29492532]\t Bias: [2.70205221]\t Cost: 15.43968704985397\n",
            "Iteration: 1671\t Weight1: [9.01154493]\t Weight2: [1.29468431]\t Bias: [2.70182609]\t Cost: 15.439680376549626\n",
            "Iteration: 1672\t Weight1: [9.01170082]\t Weight2: [1.29444388]\t Bias: [2.70160065]\t Cost: 15.439673738841282\n",
            "Iteration: 1673\t Weight1: [9.01185631]\t Weight2: [1.29420403]\t Bias: [2.7013759]\t Cost: 15.439667136536734\n",
            "Iteration: 1674\t Weight1: [9.01201141]\t Weight2: [1.29396475]\t Bias: [2.70115183]\t Cost: 15.439660569444905\n",
            "Iteration: 1675\t Weight1: [9.01216611]\t Weight2: [1.29372604]\t Bias: [2.70092844]\t Cost: 15.4396540373757\n",
            "Iteration: 1676\t Weight1: [9.01232042]\t Weight2: [1.29348791]\t Bias: [2.70070573]\t Cost: 15.43964754014013\n",
            "Iteration: 1677\t Weight1: [9.01247434]\t Weight2: [1.29325035]\t Bias: [2.70048369]\t Cost: 15.439641077550187\n",
            "Iteration: 1678\t Weight1: [9.01262787]\t Weight2: [1.29301336]\t Bias: [2.70026233]\t Cost: 15.439634649418906\n",
            "Iteration: 1679\t Weight1: [9.012781]\t Weight2: [1.29277694]\t Bias: [2.70004165]\t Cost: 15.439628255560386\n",
            "Iteration: 1680\t Weight1: [9.01293375]\t Weight2: [1.29254109]\t Bias: [2.69982163]\t Cost: 15.439621895789704\n",
            "Iteration: 1681\t Weight1: [9.01308611]\t Weight2: [1.29230581]\t Bias: [2.69960228]\t Cost: 15.439615569922967\n",
            "Iteration: 1682\t Weight1: [9.01323808]\t Weight2: [1.29207109]\t Bias: [2.69938359]\t Cost: 15.439609277777288\n",
            "Iteration: 1683\t Weight1: [9.01338966]\t Weight2: [1.29183693]\t Bias: [2.69916557]\t Cost: 15.439603019170807\n",
            "Iteration: 1684\t Weight1: [9.01354086]\t Weight2: [1.29160334]\t Bias: [2.69894821]\t Cost: 15.4395967939226\n",
            "Iteration: 1685\t Weight1: [9.01369167]\t Weight2: [1.29137031]\t Bias: [2.69873151]\t Cost: 15.439590601852805\n",
            "Iteration: 1686\t Weight1: [9.0138421]\t Weight2: [1.29113784]\t Bias: [2.69851547]\t Cost: 15.4395844427825\n",
            "Iteration: 1687\t Weight1: [9.01399215]\t Weight2: [1.29090592]\t Bias: [2.69830008]\t Cost: 15.439578316533789\n",
            "Iteration: 1688\t Weight1: [9.01414181]\t Weight2: [1.29067457]\t Bias: [2.69808535]\t Cost: 15.43957222292968\n",
            "Iteration: 1689\t Weight1: [9.01429109]\t Weight2: [1.29044377]\t Bias: [2.69787127]\t Cost: 15.439566161794206\n",
            "Iteration: 1690\t Weight1: [9.01444]\t Weight2: [1.29021353]\t Bias: [2.69765783]\t Cost: 15.43956013295236\n",
            "Iteration: 1691\t Weight1: [9.01458852]\t Weight2: [1.28998384]\t Bias: [2.69744504]\t Cost: 15.43955413623007\n",
            "Iteration: 1692\t Weight1: [9.01473667]\t Weight2: [1.28975471]\t Bias: [2.6972329]\t Cost: 15.439548171454245\n",
            "Iteration: 1693\t Weight1: [9.01488444]\t Weight2: [1.28952612]\t Bias: [2.6970214]\t Cost: 15.439542238452715\n",
            "Iteration: 1694\t Weight1: [9.01503183]\t Weight2: [1.28929809]\t Bias: [2.69681055]\t Cost: 15.439536337054275\n",
            "Iteration: 1695\t Weight1: [9.01517885]\t Weight2: [1.2890706]\t Bias: [2.69660033]\t Cost: 15.439530467088645\n",
            "Iteration: 1696\t Weight1: [9.0153255]\t Weight2: [1.28884367]\t Bias: [2.69639074]\t Cost: 15.439524628386483\n",
            "Iteration: 1697\t Weight1: [9.01547177]\t Weight2: [1.28861727]\t Bias: [2.6961818]\t Cost: 15.439518820779362\n",
            "Iteration: 1698\t Weight1: [9.01561767]\t Weight2: [1.28839143]\t Bias: [2.69597348]\t Cost: 15.439513044099808\n",
            "Iteration: 1699\t Weight1: [9.01576319]\t Weight2: [1.28816613]\t Bias: [2.6957658]\t Cost: 15.439507298181235\n",
            "Iteration: 1700\t Weight1: [9.01590835]\t Weight2: [1.28794137]\t Bias: [2.69555875]\t Cost: 15.43950158285797\n",
            "Iteration: 1701\t Weight1: [9.01605314]\t Weight2: [1.28771715]\t Bias: [2.69535232]\t Cost: 15.439495897965227\n",
            "Iteration: 1702\t Weight1: [9.01619756]\t Weight2: [1.28749347]\t Bias: [2.69514651]\t Cost: 15.439490243339195\n",
            "Iteration: 1703\t Weight1: [9.01634161]\t Weight2: [1.28727033]\t Bias: [2.69494133]\t Cost: 15.43948461881689\n",
            "Iteration: 1704\t Weight1: [9.01648529]\t Weight2: [1.28704773]\t Bias: [2.69473678]\t Cost: 15.439479024236247\n",
            "Iteration: 1705\t Weight1: [9.01662861]\t Weight2: [1.28682567]\t Bias: [2.69453284]\t Cost: 15.439473459436071\n",
            "Iteration: 1706\t Weight1: [9.01677157]\t Weight2: [1.28660414]\t Bias: [2.69432951]\t Cost: 15.439467924256054\n",
            "Iteration: 1707\t Weight1: [9.01691416]\t Weight2: [1.28638314]\t Bias: [2.69412681]\t Cost: 15.439462418536786\n",
            "Iteration: 1708\t Weight1: [9.01705638]\t Weight2: [1.28616268]\t Bias: [2.69392471]\t Cost: 15.439456942119714\n",
            "Iteration: 1709\t Weight1: [9.01719825]\t Weight2: [1.28594275]\t Bias: [2.69372323]\t Cost: 15.439451494847138\n",
            "Iteration: 1710\t Weight1: [9.01733975]\t Weight2: [1.28572335]\t Bias: [2.69352235]\t Cost: 15.439446076562238\n",
            "Iteration: 1711\t Weight1: [9.01748089]\t Weight2: [1.28550447]\t Bias: [2.69332209]\t Cost: 15.439440687109032\n",
            "Iteration: 1712\t Weight1: [9.01762168]\t Weight2: [1.28528613]\t Bias: [2.69312243]\t Cost: 15.439435326332413\n",
            "Iteration: 1713\t Weight1: [9.0177621]\t Weight2: [1.28506831]\t Bias: [2.69292337]\t Cost: 15.439429994078115\n",
            "Iteration: 1714\t Weight1: [9.01790217]\t Weight2: [1.28485102]\t Bias: [2.69272491]\t Cost: 15.439424690192713\n",
            "Iteration: 1715\t Weight1: [9.01804188]\t Weight2: [1.28463426]\t Bias: [2.69252706]\t Cost: 15.4394194145236\n",
            "Iteration: 1716\t Weight1: [9.01818124]\t Weight2: [1.28441801]\t Bias: [2.6923298]\t Cost: 15.439414166919038\n",
            "Iteration: 1717\t Weight1: [9.01832024]\t Weight2: [1.28420229]\t Bias: [2.69213314]\t Cost: 15.439408947228102\n",
            "Iteration: 1718\t Weight1: [9.01845888]\t Weight2: [1.28398709]\t Bias: [2.69193707]\t Cost: 15.439403755300685\n",
            "Iteration: 1719\t Weight1: [9.01859718]\t Weight2: [1.28377241]\t Bias: [2.69174159]\t Cost: 15.439398590987501\n",
            "Iteration: 1720\t Weight1: [9.01873512]\t Weight2: [1.28355824]\t Bias: [2.69154671]\t Cost: 15.439393454140085\n",
            "Iteration: 1721\t Weight1: [9.01887271]\t Weight2: [1.2833446]\t Bias: [2.69135241]\t Cost: 15.439388344610784\n",
            "Iteration: 1722\t Weight1: [9.01900994]\t Weight2: [1.28313147]\t Bias: [2.6911587]\t Cost: 15.439383262252745\n",
            "Iteration: 1723\t Weight1: [9.01914683]\t Weight2: [1.28291885]\t Bias: [2.69096558]\t Cost: 15.439378206919928\n",
            "Iteration: 1724\t Weight1: [9.01928337]\t Weight2: [1.28270675]\t Bias: [2.69077303]\t Cost: 15.439373178467049\n",
            "Iteration: 1725\t Weight1: [9.01941957]\t Weight2: [1.28249516]\t Bias: [2.69058107]\t Cost: 15.439368176749703\n",
            "Iteration: 1726\t Weight1: [9.01955541]\t Weight2: [1.28228408]\t Bias: [2.69038969]\t Cost: 15.439363201624163\n",
            "Iteration: 1727\t Weight1: [9.01969091]\t Weight2: [1.28207351]\t Bias: [2.69019889]\t Cost: 15.43935825294756\n",
            "Iteration: 1728\t Weight1: [9.01982607]\t Weight2: [1.28186345]\t Bias: [2.69000866]\t Cost: 15.439353330577797\n",
            "Iteration: 1729\t Weight1: [9.01996088]\t Weight2: [1.2816539]\t Bias: [2.689819]\t Cost: 15.439348434373532\n",
            "Iteration: 1730\t Weight1: [9.02009534]\t Weight2: [1.28144485]\t Bias: [2.68962992]\t Cost: 15.439343564194196\n",
            "Iteration: 1731\t Weight1: [9.02022947]\t Weight2: [1.28123631]\t Bias: [2.68944141]\t Cost: 15.439338719900007\n",
            "Iteration: 1732\t Weight1: [9.02036325]\t Weight2: [1.28102828]\t Bias: [2.68925347]\t Cost: 15.439333901351919\n",
            "Iteration: 1733\t Weight1: [9.02049669]\t Weight2: [1.28082075]\t Bias: [2.68906609]\t Cost: 15.439329108411668\n",
            "Iteration: 1734\t Weight1: [9.02062979]\t Weight2: [1.28061372]\t Bias: [2.68887928]\t Cost: 15.439324340941706\n",
            "Iteration: 1735\t Weight1: [9.02076255]\t Weight2: [1.28040719]\t Bias: [2.68869303]\t Cost: 15.439319598805293\n",
            "Iteration: 1736\t Weight1: [9.02089498]\t Weight2: [1.28020115]\t Bias: [2.68850734]\t Cost: 15.439314881866382\n",
            "Iteration: 1737\t Weight1: [9.02102706]\t Weight2: [1.27999562]\t Bias: [2.68832221]\t Cost: 15.43931018998968\n",
            "Iteration: 1738\t Weight1: [9.02115881]\t Weight2: [1.27979059]\t Bias: [2.68813764]\t Cost: 15.439305523040671\n",
            "Iteration: 1739\t Weight1: [9.02129023]\t Weight2: [1.27958605]\t Bias: [2.68795363]\t Cost: 15.439300880885506\n",
            "Iteration: 1740\t Weight1: [9.02142131]\t Weight2: [1.27938201]\t Bias: [2.68777017]\t Cost: 15.439296263391107\n",
            "Iteration: 1741\t Weight1: [9.02155205]\t Weight2: [1.27917846]\t Bias: [2.68758726]\t Cost: 15.439291670425112\n",
            "Iteration: 1742\t Weight1: [9.02168246]\t Weight2: [1.2789754]\t Bias: [2.68740491]\t Cost: 15.43928710185588\n",
            "Iteration: 1743\t Weight1: [9.02181254]\t Weight2: [1.27877283]\t Bias: [2.6872231]\t Cost: 15.43928255755249\n",
            "Iteration: 1744\t Weight1: [9.02194229]\t Weight2: [1.27857076]\t Bias: [2.68704184]\t Cost: 15.439278037384726\n",
            "Iteration: 1745\t Weight1: [9.02207171]\t Weight2: [1.27836917]\t Bias: [2.68686113]\t Cost: 15.439273541223073\n",
            "Iteration: 1746\t Weight1: [9.0222008]\t Weight2: [1.27816807]\t Bias: [2.68668096]\t Cost: 15.439269068938748\n",
            "Iteration: 1747\t Weight1: [9.02232955]\t Weight2: [1.27796746]\t Bias: [2.68650133]\t Cost: 15.439264620403675\n",
            "Iteration: 1748\t Weight1: [9.02245798]\t Weight2: [1.27776734]\t Bias: [2.68632225]\t Cost: 15.439260195490418\n",
            "Iteration: 1749\t Weight1: [9.02258609]\t Weight2: [1.2775677]\t Bias: [2.6861437]\t Cost: 15.439255794072276\n",
            "Iteration: 1750\t Weight1: [9.02271386]\t Weight2: [1.27736854]\t Bias: [2.68596569]\t Cost: 15.439251416023247\n",
            "Iteration: 1751\t Weight1: [9.02284131]\t Weight2: [1.27716987]\t Bias: [2.68578821]\t Cost: 15.43924706121798\n",
            "Iteration: 1752\t Weight1: [9.02296844]\t Weight2: [1.27697168]\t Bias: [2.68561127]\t Cost: 15.439242729531848\n",
            "Iteration: 1753\t Weight1: [9.02309524]\t Weight2: [1.27677397]\t Bias: [2.68543486]\t Cost: 15.439238420840882\n",
            "Iteration: 1754\t Weight1: [9.02322172]\t Weight2: [1.27657673]\t Bias: [2.68525899]\t Cost: 15.439234135021751\n",
            "Iteration: 1755\t Weight1: [9.02334787]\t Weight2: [1.27637998]\t Bias: [2.68508364]\t Cost: 15.439229871951854\n",
            "Iteration: 1756\t Weight1: [9.0234737]\t Weight2: [1.2761837]\t Bias: [2.68490882]\t Cost: 15.439225631509233\n",
            "Iteration: 1757\t Weight1: [9.02359922]\t Weight2: [1.2759879]\t Bias: [2.68473452]\t Cost: 15.439221413572561\n",
            "Iteration: 1758\t Weight1: [9.02372441]\t Weight2: [1.27579257]\t Bias: [2.68456075]\t Cost: 15.439217218021248\n",
            "Iteration: 1759\t Weight1: [9.02384928]\t Weight2: [1.27559772]\t Bias: [2.6843875]\t Cost: 15.439213044735268\n",
            "Iteration: 1760\t Weight1: [9.02397384]\t Weight2: [1.27540334]\t Bias: [2.68421477]\t Cost: 15.439208893595328\n",
            "Iteration: 1761\t Weight1: [9.02409808]\t Weight2: [1.27520943]\t Bias: [2.68404256]\t Cost: 15.43920476448273\n",
            "Iteration: 1762\t Weight1: [9.024222]\t Weight2: [1.27501599]\t Bias: [2.68387086]\t Cost: 15.439200657279434\n",
            "Iteration: 1763\t Weight1: [9.0243456]\t Weight2: [1.27482302]\t Bias: [2.68369969]\t Cost: 15.439196571868054\n",
            "Iteration: 1764\t Weight1: [9.02446889]\t Weight2: [1.27463052]\t Bias: [2.68352902]\t Cost: 15.439192508131816\n",
            "Iteration: 1765\t Weight1: [9.02459186]\t Weight2: [1.27443849]\t Bias: [2.68335887]\t Cost: 15.439188465954615\n",
            "Iteration: 1766\t Weight1: [9.02471453]\t Weight2: [1.27424692]\t Bias: [2.68318923]\t Cost: 15.439184445220956\n",
            "Iteration: 1767\t Weight1: [9.02483687]\t Weight2: [1.27405582]\t Bias: [2.6830201]\t Cost: 15.43918044581597\n",
            "Iteration: 1768\t Weight1: [9.02495891]\t Weight2: [1.27386518]\t Bias: [2.68285148]\t Cost: 15.439176467625428\n",
            "Iteration: 1769\t Weight1: [9.02508064]\t Weight2: [1.273675]\t Bias: [2.68268336]\t Cost: 15.439172510535691\n",
            "Iteration: 1770\t Weight1: [9.02520205]\t Weight2: [1.27348529]\t Bias: [2.68251575]\t Cost: 15.439168574433774\n",
            "Iteration: 1771\t Weight1: [9.02532315]\t Weight2: [1.27329603]\t Bias: [2.68234864]\t Cost: 15.439164659207261\n",
            "Iteration: 1772\t Weight1: [9.02544395]\t Weight2: [1.27310724]\t Bias: [2.68218203]\t Cost: 15.439160764744404\n",
            "Iteration: 1773\t Weight1: [9.02556444]\t Weight2: [1.2729189]\t Bias: [2.68201593]\t Cost: 15.439156890934012\n",
            "Iteration: 1774\t Weight1: [9.02568462]\t Weight2: [1.27273103]\t Bias: [2.68185032]\t Cost: 15.439153037665521\n",
            "Iteration: 1775\t Weight1: [9.02580449]\t Weight2: [1.27254361]\t Bias: [2.68168521]\t Cost: 15.439149204828954\n",
            "Iteration: 1776\t Weight1: [9.02592406]\t Weight2: [1.27235664]\t Bias: [2.68152059]\t Cost: 15.43914539231495\n",
            "Iteration: 1777\t Weight1: [9.02604332]\t Weight2: [1.27217013]\t Bias: [2.68135646]\t Cost: 15.43914160001472\n",
            "Iteration: 1778\t Weight1: [9.02616228]\t Weight2: [1.27198407]\t Bias: [2.68119283]\t Cost: 15.43913782782006\n",
            "Iteration: 1779\t Weight1: [9.02628094]\t Weight2: [1.27179846]\t Bias: [2.68102969]\t Cost: 15.439134075623418\n",
            "Iteration: 1780\t Weight1: [9.02639929]\t Weight2: [1.27161331]\t Bias: [2.68086704]\t Cost: 15.439130343317713\n",
            "Iteration: 1781\t Weight1: [9.02651734]\t Weight2: [1.2714286]\t Bias: [2.68070488]\t Cost: 15.439126630796565\n",
            "Iteration: 1782\t Weight1: [9.02663509]\t Weight2: [1.27124435]\t Bias: [2.6805432]\t Cost: 15.439122937954059\n",
            "Iteration: 1783\t Weight1: [9.02675254]\t Weight2: [1.27106054]\t Bias: [2.680382]\t Cost: 15.439119264684935\n",
            "Iteration: 1784\t Weight1: [9.02686968]\t Weight2: [1.27087718]\t Bias: [2.68022129]\t Cost: 15.439115610884487\n",
            "Iteration: 1785\t Weight1: [9.02698653]\t Weight2: [1.27069426]\t Bias: [2.68006106]\t Cost: 15.439111976448547\n",
            "Iteration: 1786\t Weight1: [9.02710309]\t Weight2: [1.27051179]\t Bias: [2.67990131]\t Cost: 15.439108361273535\n",
            "Iteration: 1787\t Weight1: [9.02721934]\t Weight2: [1.27032977]\t Bias: [2.67974204]\t Cost: 15.439104765256419\n",
            "Iteration: 1788\t Weight1: [9.0273353]\t Weight2: [1.27014818]\t Bias: [2.67958325]\t Cost: 15.43910118829476\n",
            "Iteration: 1789\t Weight1: [9.02745096]\t Weight2: [1.26996704]\t Bias: [2.67942493]\t Cost: 15.439097630286614\n",
            "Iteration: 1790\t Weight1: [9.02756633]\t Weight2: [1.26978634]\t Bias: [2.67926708]\t Cost: 15.439094091130677\n",
            "Iteration: 1791\t Weight1: [9.0276814]\t Weight2: [1.26960608]\t Bias: [2.67910971]\t Cost: 15.439090570726087\n",
            "Iteration: 1792\t Weight1: [9.02779618]\t Weight2: [1.26942626]\t Bias: [2.67895281]\t Cost: 15.439087068972624\n",
            "Iteration: 1793\t Weight1: [9.02791066]\t Weight2: [1.26924687]\t Bias: [2.67879638]\t Cost: 15.439083585770538\n",
            "Iteration: 1794\t Weight1: [9.02802486]\t Weight2: [1.26906792]\t Bias: [2.67864042]\t Cost: 15.439080121020655\n",
            "Iteration: 1795\t Weight1: [9.02813876]\t Weight2: [1.26888941]\t Bias: [2.67848492]\t Cost: 15.439076674624369\n",
            "Iteration: 1796\t Weight1: [9.02825237]\t Weight2: [1.26871133]\t Bias: [2.67832989]\t Cost: 15.439073246483524\n",
            "Iteration: 1797\t Weight1: [9.02836569]\t Weight2: [1.26853369]\t Bias: [2.67817532]\t Cost: 15.43906983650058\n",
            "Iteration: 1798\t Weight1: [9.02847872]\t Weight2: [1.26835648]\t Bias: [2.67802122]\t Cost: 15.439066444578469\n",
            "Iteration: 1799\t Weight1: [9.02859146]\t Weight2: [1.2681797]\t Bias: [2.67786757]\t Cost: 15.43906307062068\n",
            "Iteration: 1800\t Weight1: [9.02870392]\t Weight2: [1.26800335]\t Bias: [2.67771439]\t Cost: 15.439059714531211\n",
            "Iteration: 1801\t Weight1: [9.02881609]\t Weight2: [1.26782743]\t Bias: [2.67756166]\t Cost: 15.439056376214577\n",
            "Iteration: 1802\t Weight1: [9.02892797]\t Weight2: [1.26765194]\t Bias: [2.67740939]\t Cost: 15.43905305557582\n",
            "Iteration: 1803\t Weight1: [9.02903956]\t Weight2: [1.26747688]\t Bias: [2.67725757]\t Cost: 15.43904975252049\n",
            "Iteration: 1804\t Weight1: [9.02915088]\t Weight2: [1.26730224]\t Bias: [2.67710621]\t Cost: 15.43904646695464\n",
            "Iteration: 1805\t Weight1: [9.0292619]\t Weight2: [1.26712803]\t Bias: [2.6769553]\t Cost: 15.439043198784862\n",
            "Iteration: 1806\t Weight1: [9.02937265]\t Weight2: [1.26695424]\t Bias: [2.67680485]\t Cost: 15.439039947918207\n",
            "Iteration: 1807\t Weight1: [9.02948311]\t Weight2: [1.26678088]\t Bias: [2.67665484]\t Cost: 15.439036714262265\n",
            "Iteration: 1808\t Weight1: [9.02959329]\t Weight2: [1.26660794]\t Bias: [2.67650528]\t Cost: 15.439033497725111\n",
            "Iteration: 1809\t Weight1: [9.02970318]\t Weight2: [1.26643542]\t Bias: [2.67635616]\t Cost: 15.439030298215325\n",
            "Iteration: 1810\t Weight1: [9.0298128]\t Weight2: [1.26626332]\t Bias: [2.67620749]\t Cost: 15.439027115641982\n",
            "Iteration: 1811\t Weight1: [9.02992214]\t Weight2: [1.26609164]\t Bias: [2.67605927]\t Cost: 15.439023949914626\n",
            "Iteration: 1812\t Weight1: [9.03003119]\t Weight2: [1.26592038]\t Bias: [2.67591149]\t Cost: 15.439020800943325\n",
            "Iteration: 1813\t Weight1: [9.03013997]\t Weight2: [1.26574954]\t Bias: [2.67576415]\t Cost: 15.439017668638595\n",
            "Iteration: 1814\t Weight1: [9.03024847]\t Weight2: [1.26557911]\t Bias: [2.67561725]\t Cost: 15.439014552911475\n",
            "Iteration: 1815\t Weight1: [9.0303567]\t Weight2: [1.2654091]\t Bias: [2.67547078]\t Cost: 15.439011453673455\n",
            "Iteration: 1816\t Weight1: [9.03046465]\t Weight2: [1.26523951]\t Bias: [2.67532476]\t Cost: 15.439008370836525\n",
            "Iteration: 1817\t Weight1: [9.03057232]\t Weight2: [1.26507033]\t Bias: [2.67517917]\t Cost: 15.43900530431314\n",
            "Iteration: 1818\t Weight1: [9.03067972]\t Weight2: [1.26490156]\t Bias: [2.67503401]\t Cost: 15.439002254016208\n",
            "Iteration: 1819\t Weight1: [9.03078684]\t Weight2: [1.2647332]\t Bias: [2.67488929]\t Cost: 15.438999219859161\n",
            "Iteration: 1820\t Weight1: [9.03089369]\t Weight2: [1.26456526]\t Bias: [2.674745]\t Cost: 15.438996201755826\n",
            "Iteration: 1821\t Weight1: [9.03100026]\t Weight2: [1.26439772]\t Bias: [2.67460114]\t Cost: 15.438993199620569\n",
            "Iteration: 1822\t Weight1: [9.03110657]\t Weight2: [1.2642306]\t Bias: [2.67445771]\t Cost: 15.438990213368166\n",
            "Iteration: 1823\t Weight1: [9.0312126]\t Weight2: [1.26406388]\t Bias: [2.67431471]\t Cost: 15.438987242913907\n",
            "Iteration: 1824\t Weight1: [9.03131836]\t Weight2: [1.26389757]\t Bias: [2.67417213]\t Cost: 15.438984288173467\n",
            "Iteration: 1825\t Weight1: [9.03142385]\t Weight2: [1.26373166]\t Bias: [2.67402998]\t Cost: 15.438981349063006\n",
            "Iteration: 1826\t Weight1: [9.03152907]\t Weight2: [1.26356616]\t Bias: [2.67388825]\t Cost: 15.438978425499162\n",
            "Iteration: 1827\t Weight1: [9.03163403]\t Weight2: [1.26340107]\t Bias: [2.67374694]\t Cost: 15.438975517399006\n",
            "Iteration: 1828\t Weight1: [9.03173871]\t Weight2: [1.26323637]\t Bias: [2.67360606]\t Cost: 15.438972624680062\n",
            "Iteration: 1829\t Weight1: [9.03184313]\t Weight2: [1.26307208]\t Bias: [2.67346559]\t Cost: 15.4389697472603\n",
            "Iteration: 1830\t Weight1: [9.03194728]\t Weight2: [1.26290819]\t Bias: [2.67332555]\t Cost: 15.4389668850581\n",
            "Iteration: 1831\t Weight1: [9.03205116]\t Weight2: [1.26274471]\t Bias: [2.67318592]\t Cost: 15.438964037992326\n",
            "Iteration: 1832\t Weight1: [9.03215478]\t Weight2: [1.26258162]\t Bias: [2.6730467]\t Cost: 15.438961205982263\n",
            "Iteration: 1833\t Weight1: [9.03225814]\t Weight2: [1.26241893]\t Bias: [2.67290791]\t Cost: 15.438958388947633\n",
            "Iteration: 1834\t Weight1: [9.03236123]\t Weight2: [1.26225663]\t Bias: [2.67276952]\t Cost: 15.438955586808595\n",
            "Iteration: 1835\t Weight1: [9.03246406]\t Weight2: [1.26209474]\t Bias: [2.67263155]\t Cost: 15.438952799485694\n",
            "Iteration: 1836\t Weight1: [9.03256662]\t Weight2: [1.26193324]\t Bias: [2.67249398]\t Cost: 15.438950026899994\n",
            "Iteration: 1837\t Weight1: [9.03266892]\t Weight2: [1.26177213]\t Bias: [2.67235683]\t Cost: 15.43894726897292\n",
            "Iteration: 1838\t Weight1: [9.03277096]\t Weight2: [1.26161142]\t Bias: [2.67222009]\t Cost: 15.438944525626322\n",
            "Iteration: 1839\t Weight1: [9.03287274]\t Weight2: [1.2614511]\t Bias: [2.67208375]\t Cost: 15.438941796782487\n",
            "Iteration: 1840\t Weight1: [9.03297426]\t Weight2: [1.26129118]\t Bias: [2.67194782]\t Cost: 15.438939082364127\n",
            "Iteration: 1841\t Weight1: [9.03307552]\t Weight2: [1.26113164]\t Bias: [2.67181229]\t Cost: 15.438936382294365\n",
            "Iteration: 1842\t Weight1: [9.03317652]\t Weight2: [1.26097249]\t Bias: [2.67167716]\t Cost: 15.438933696496715\n",
            "Iteration: 1843\t Weight1: [9.03327727]\t Weight2: [1.26081374]\t Bias: [2.67154244]\t Cost: 15.438931024895135\n",
            "Iteration: 1844\t Weight1: [9.03337775]\t Weight2: [1.26065537]\t Bias: [2.67140812]\t Cost: 15.438928367413997\n",
            "Iteration: 1845\t Weight1: [9.03347798]\t Weight2: [1.26049739]\t Bias: [2.6712742]\t Cost: 15.438925723978038\n",
            "Iteration: 1846\t Weight1: [9.03357796]\t Weight2: [1.2603398]\t Bias: [2.67114067]\t Cost: 15.438923094512447\n",
            "Iteration: 1847\t Weight1: [9.03367767]\t Weight2: [1.26018259]\t Bias: [2.67100755]\t Cost: 15.438920478942801\n",
            "Iteration: 1848\t Weight1: [9.03377713]\t Weight2: [1.26002577]\t Bias: [2.67087482]\t Cost: 15.438917877195063\n",
            "Iteration: 1849\t Weight1: [9.03387634]\t Weight2: [1.25986933]\t Bias: [2.67074248]\t Cost: 15.438915289195615\n",
            "Iteration: 1850\t Weight1: [9.0339753]\t Weight2: [1.25971327]\t Bias: [2.67061054]\t Cost: 15.438912714871217\n",
            "Iteration: 1851\t Weight1: [9.034074]\t Weight2: [1.2595576]\t Bias: [2.67047898]\t Cost: 15.438910154149042\n",
            "Iteration: 1852\t Weight1: [9.03417245]\t Weight2: [1.2594023]\t Bias: [2.67034782]\t Cost: 15.438907606956642\n",
            "Iteration: 1853\t Weight1: [9.03427065]\t Weight2: [1.25924739]\t Bias: [2.67021705]\t Cost: 15.438905073221957\n",
            "Iteration: 1854\t Weight1: [9.03436859]\t Weight2: [1.25909286]\t Bias: [2.67008667]\t Cost: 15.438902552873351\n",
            "Iteration: 1855\t Weight1: [9.03446629]\t Weight2: [1.2589387]\t Bias: [2.66995668]\t Cost: 15.438900045839512\n",
            "Iteration: 1856\t Weight1: [9.03456374]\t Weight2: [1.25878492]\t Bias: [2.66982707]\t Cost: 15.438897552049578\n",
            "Iteration: 1857\t Weight1: [9.03466093]\t Weight2: [1.25863152]\t Bias: [2.66969784]\t Cost: 15.438895071433\n",
            "Iteration: 1858\t Weight1: [9.03475788]\t Weight2: [1.2584785]\t Bias: [2.669569]\t Cost: 15.438892603919674\n",
            "Iteration: 1859\t Weight1: [9.03485458]\t Weight2: [1.25832585]\t Bias: [2.66944054]\t Cost: 15.438890149439832\n",
            "Iteration: 1860\t Weight1: [9.03495104]\t Weight2: [1.25817357]\t Bias: [2.66931247]\t Cost: 15.438887707924097\n",
            "Iteration: 1861\t Weight1: [9.03504724]\t Weight2: [1.25802167]\t Bias: [2.66918477]\t Cost: 15.43888527930346\n",
            "Iteration: 1862\t Weight1: [9.03514321]\t Weight2: [1.25787014]\t Bias: [2.66905745]\t Cost: 15.43888286350929\n",
            "Iteration: 1863\t Weight1: [9.03523892]\t Weight2: [1.25771898]\t Bias: [2.66893051]\t Cost: 15.438880460473305\n",
            "Iteration: 1864\t Weight1: [9.03533439]\t Weight2: [1.25756819]\t Bias: [2.66880395]\t Cost: 15.43887807012764\n",
            "Iteration: 1865\t Weight1: [9.03542962]\t Weight2: [1.25741777]\t Bias: [2.66867776]\t Cost: 15.438875692404718\n",
            "Iteration: 1866\t Weight1: [9.0355246]\t Weight2: [1.25726772]\t Bias: [2.66855195]\t Cost: 15.438873327237408\n",
            "Iteration: 1867\t Weight1: [9.03561934]\t Weight2: [1.25711804]\t Bias: [2.66842651]\t Cost: 15.43887097455888\n",
            "Iteration: 1868\t Weight1: [9.03571384]\t Weight2: [1.25696872]\t Bias: [2.66830144]\t Cost: 15.438868634302688\n",
            "Iteration: 1869\t Weight1: [9.0358081]\t Weight2: [1.25681977]\t Bias: [2.66817675]\t Cost: 15.438866306402746\n",
            "Iteration: 1870\t Weight1: [9.03590211]\t Weight2: [1.25667119]\t Bias: [2.66805242]\t Cost: 15.43886399079331\n",
            "Iteration: 1871\t Weight1: [9.03599589]\t Weight2: [1.25652297]\t Bias: [2.66792846]\t Cost: 15.438861687409029\n",
            "Iteration: 1872\t Weight1: [9.03608942]\t Weight2: [1.25637511]\t Bias: [2.66780487]\t Cost: 15.438859396184828\n",
            "Iteration: 1873\t Weight1: [9.03618272]\t Weight2: [1.25622762]\t Bias: [2.66768165]\t Cost: 15.438857117056045\n",
            "Iteration: 1874\t Weight1: [9.03627578]\t Weight2: [1.25608048]\t Bias: [2.66755879]\t Cost: 15.438854849958348\n",
            "Iteration: 1875\t Weight1: [9.0363686]\t Weight2: [1.25593371]\t Bias: [2.66743629]\t Cost: 15.438852594827745\n",
            "Iteration: 1876\t Weight1: [9.03646118]\t Weight2: [1.2557873]\t Bias: [2.66731416]\t Cost: 15.438850351600596\n",
            "Iteration: 1877\t Weight1: [9.03655352]\t Weight2: [1.25564125]\t Bias: [2.66719239]\t Cost: 15.438848120213612\n",
            "Iteration: 1878\t Weight1: [9.03664563]\t Weight2: [1.25549556]\t Bias: [2.66707098]\t Cost: 15.438845900603816\n",
            "Iteration: 1879\t Weight1: [9.0367375]\t Weight2: [1.25535022]\t Bias: [2.66694993]\t Cost: 15.43884369270858\n",
            "Iteration: 1880\t Weight1: [9.03682914]\t Weight2: [1.25520524]\t Bias: [2.66682923]\t Cost: 15.438841496465624\n",
            "Iteration: 1881\t Weight1: [9.03692055]\t Weight2: [1.25506062]\t Bias: [2.6667089]\t Cost: 15.438839311813002\n",
            "Iteration: 1882\t Weight1: [9.03701172]\t Weight2: [1.25491635]\t Bias: [2.66658892]\t Cost: 15.438837138689115\n",
            "Iteration: 1883\t Weight1: [9.03710265]\t Weight2: [1.25477244]\t Bias: [2.6664693]\t Cost: 15.438834977032636\n",
            "Iteration: 1884\t Weight1: [9.03719336]\t Weight2: [1.25462888]\t Bias: [2.66635003]\t Cost: 15.438832826782614\n",
            "Iteration: 1885\t Weight1: [9.03728383]\t Weight2: [1.25448567]\t Bias: [2.66623111]\t Cost: 15.438830687878449\n",
            "Iteration: 1886\t Weight1: [9.03737407]\t Weight2: [1.25434281]\t Bias: [2.66611255]\t Cost: 15.438828560259807\n",
            "Iteration: 1887\t Weight1: [9.03746408]\t Weight2: [1.25420031]\t Bias: [2.66599434]\t Cost: 15.43882644386672\n",
            "Iteration: 1888\t Weight1: [9.03755386]\t Weight2: [1.25405815]\t Bias: [2.66587647]\t Cost: 15.438824338639536\n",
            "Iteration: 1889\t Weight1: [9.03764341]\t Weight2: [1.25391635]\t Bias: [2.66575896]\t Cost: 15.438822244518892\n",
            "Iteration: 1890\t Weight1: [9.03773273]\t Weight2: [1.25377489]\t Bias: [2.66564179]\t Cost: 15.43882016144579\n",
            "Iteration: 1891\t Weight1: [9.03782182]\t Weight2: [1.25363378]\t Bias: [2.66552497]\t Cost: 15.438818089361526\n",
            "Iteration: 1892\t Weight1: [9.03791069]\t Weight2: [1.25349302]\t Bias: [2.6654085]\t Cost: 15.43881602820769\n",
            "Iteration: 1893\t Weight1: [9.03799932]\t Weight2: [1.2533526]\t Bias: [2.66529236]\t Cost: 15.43881397792624\n",
            "Iteration: 1894\t Weight1: [9.03808773]\t Weight2: [1.25321253]\t Bias: [2.66517658]\t Cost: 15.438811938459388\n",
            "Iteration: 1895\t Weight1: [9.03817592]\t Weight2: [1.2530728]\t Bias: [2.66506113]\t Cost: 15.438809909749702\n",
            "Iteration: 1896\t Weight1: [9.03826387]\t Weight2: [1.25293341]\t Bias: [2.66494603]\t Cost: 15.438807891740025\n",
            "Iteration: 1897\t Weight1: [9.03835161]\t Weight2: [1.25279437]\t Bias: [2.66483127]\t Cost: 15.43880588437351\n",
            "Iteration: 1898\t Weight1: [9.03843912]\t Weight2: [1.25265567]\t Bias: [2.66471684]\t Cost: 15.438803887593659\n",
            "Iteration: 1899\t Weight1: [9.0385264]\t Weight2: [1.25251731]\t Bias: [2.66460275]\t Cost: 15.438801901344213\n",
            "Iteration: 1900\t Weight1: [9.03861346]\t Weight2: [1.25237929]\t Bias: [2.66448901]\t Cost: 15.438799925569247\n",
            "Iteration: 1901\t Weight1: [9.0387003]\t Weight2: [1.25224161]\t Bias: [2.66437559]\t Cost: 15.438797960213144\n",
            "Iteration: 1902\t Weight1: [9.03878691]\t Weight2: [1.25210427]\t Bias: [2.66426251]\t Cost: 15.438796005220569\n",
            "Iteration: 1903\t Weight1: [9.03887331]\t Weight2: [1.25196727]\t Bias: [2.66414977]\t Cost: 15.438794060536509\n",
            "Iteration: 1904\t Weight1: [9.03895948]\t Weight2: [1.2518306]\t Bias: [2.66403736]\t Cost: 15.438792126106202\n",
            "Iteration: 1905\t Weight1: [9.03904543]\t Weight2: [1.25169427]\t Bias: [2.66392528]\t Cost: 15.438790201875214\n",
            "Iteration: 1906\t Weight1: [9.03913117]\t Weight2: [1.25155828]\t Bias: [2.66381353]\t Cost: 15.438788287789382\n",
            "Iteration: 1907\t Weight1: [9.03921668]\t Weight2: [1.25142262]\t Bias: [2.66370211]\t Cost: 15.438786383794897\n",
            "Iteration: 1908\t Weight1: [9.03930197]\t Weight2: [1.25128729]\t Bias: [2.66359102]\t Cost: 15.438784489838104\n",
            "Iteration: 1909\t Weight1: [9.03938705]\t Weight2: [1.2511523]\t Bias: [2.66348026]\t Cost: 15.438782605865786\n",
            "Iteration: 1910\t Weight1: [9.03947191]\t Weight2: [1.25101764]\t Bias: [2.66336983]\t Cost: 15.43878073182492\n",
            "Iteration: 1911\t Weight1: [9.03955655]\t Weight2: [1.25088331]\t Bias: [2.66325972]\t Cost: 15.438778867662784\n",
            "Iteration: 1912\t Weight1: [9.03964097]\t Weight2: [1.25074931]\t Bias: [2.66314993]\t Cost: 15.438777013326945\n",
            "Iteration: 1913\t Weight1: [9.03972518]\t Weight2: [1.25061564]\t Bias: [2.66304047]\t Cost: 15.438775168765284\n",
            "Iteration: 1914\t Weight1: [9.03980917]\t Weight2: [1.2504823]\t Bias: [2.66293134]\t Cost: 15.438773333925894\n",
            "Iteration: 1915\t Weight1: [9.03989295]\t Weight2: [1.25034929]\t Bias: [2.66282252]\t Cost: 15.438771508757199\n",
            "Iteration: 1916\t Weight1: [9.03997651]\t Weight2: [1.25021661]\t Bias: [2.66271403]\t Cost: 15.438769693207876\n",
            "Iteration: 1917\t Weight1: [9.04005986]\t Weight2: [1.25008425]\t Bias: [2.66260585]\t Cost: 15.438767887226879\n",
            "Iteration: 1918\t Weight1: [9.040143]\t Weight2: [1.24995222]\t Bias: [2.662498]\t Cost: 15.438766090763446\n",
            "Iteration: 1919\t Weight1: [9.04022592]\t Weight2: [1.24982051]\t Bias: [2.66239046]\t Cost: 15.438764303767083\n",
            "Iteration: 1920\t Weight1: [9.04030863]\t Weight2: [1.24968913]\t Bias: [2.66228324]\t Cost: 15.438762526187556\n",
            "Iteration: 1921\t Weight1: [9.04039113]\t Weight2: [1.24955807]\t Bias: [2.66217633]\t Cost: 15.438760757974915\n",
            "Iteration: 1922\t Weight1: [9.04047342]\t Weight2: [1.24942733]\t Bias: [2.66206974]\t Cost: 15.438758999079461\n",
            "Iteration: 1923\t Weight1: [9.0405555]\t Weight2: [1.24929692]\t Bias: [2.66196347]\t Cost: 15.43875724945178\n",
            "Iteration: 1924\t Weight1: [9.04063736]\t Weight2: [1.24916683]\t Bias: [2.6618575]\t Cost: 15.438755509042716\n",
            "Iteration: 1925\t Weight1: [9.04071902]\t Weight2: [1.24903706]\t Bias: [2.66175185]\t Cost: 15.438753777803363\n",
            "Iteration: 1926\t Weight1: [9.04080047]\t Weight2: [1.24890761]\t Bias: [2.66164651]\t Cost: 15.438752055685104\n",
            "Iteration: 1927\t Weight1: [9.04088171]\t Weight2: [1.24877847]\t Bias: [2.66154149]\t Cost: 15.438750342639556\n",
            "Iteration: 1928\t Weight1: [9.04096274]\t Weight2: [1.24864966]\t Bias: [2.66143677]\t Cost: 15.4387486386186\n",
            "Iteration: 1929\t Weight1: [9.04104356]\t Weight2: [1.24852116]\t Bias: [2.66133236]\t Cost: 15.438746943574385\n",
            "Iteration: 1930\t Weight1: [9.04112418]\t Weight2: [1.24839298]\t Bias: [2.66122825]\t Cost: 15.438745257459303\n",
            "Iteration: 1931\t Weight1: [9.04120459]\t Weight2: [1.24826512]\t Bias: [2.66112445]\t Cost: 15.438743580226028\n",
            "Iteration: 1932\t Weight1: [9.04128479]\t Weight2: [1.24813757]\t Bias: [2.66102096]\t Cost: 15.438741911827437\n",
            "Iteration: 1933\t Weight1: [9.04136479]\t Weight2: [1.24801033]\t Bias: [2.66091778]\t Cost: 15.438740252216727\n",
            "Iteration: 1934\t Weight1: [9.04144459]\t Weight2: [1.24788341]\t Bias: [2.66081489]\t Cost: 15.438738601347286\n",
            "Iteration: 1935\t Weight1: [9.04152418]\t Weight2: [1.2477568]\t Bias: [2.66071231]\t Cost: 15.438736959172784\n",
            "Iteration: 1936\t Weight1: [9.04160356]\t Weight2: [1.24763051]\t Bias: [2.66061003]\t Cost: 15.438735325647118\n",
            "Iteration: 1937\t Weight1: [9.04168274]\t Weight2: [1.24750452]\t Bias: [2.66050805]\t Cost: 15.438733700724455\n",
            "Iteration: 1938\t Weight1: [9.04176172]\t Weight2: [1.24737885]\t Bias: [2.66040638]\t Cost: 15.43873208435919\n",
            "Iteration: 1939\t Weight1: [9.0418405]\t Weight2: [1.24725349]\t Bias: [2.660305]\t Cost: 15.438730476505963\n",
            "Iteration: 1940\t Weight1: [9.04191908]\t Weight2: [1.24712843]\t Bias: [2.66020392]\t Cost: 15.438728877119676\n",
            "Iteration: 1941\t Weight1: [9.04199745]\t Weight2: [1.24700369]\t Bias: [2.66010313]\t Cost: 15.43872728615543\n",
            "Iteration: 1942\t Weight1: [9.04207562]\t Weight2: [1.24687925]\t Bias: [2.66000265]\t Cost: 15.438725703568624\n",
            "Iteration: 1943\t Weight1: [9.0421536]\t Weight2: [1.24675512]\t Bias: [2.65990245]\t Cost: 15.438724129314844\n",
            "Iteration: 1944\t Weight1: [9.04223137]\t Weight2: [1.2466313]\t Bias: [2.65980256]\t Cost: 15.438722563349943\n",
            "Iteration: 1945\t Weight1: [9.04230894]\t Weight2: [1.24650778]\t Bias: [2.65970295]\t Cost: 15.438721005629986\n",
            "Iteration: 1946\t Weight1: [9.04238632]\t Weight2: [1.24638456]\t Bias: [2.65960364]\t Cost: 15.438719456111306\n",
            "Iteration: 1947\t Weight1: [9.0424635]\t Weight2: [1.24626165]\t Bias: [2.65950462]\t Cost: 15.43871791475045\n",
            "Iteration: 1948\t Weight1: [9.04254048]\t Weight2: [1.24613905]\t Bias: [2.65940589]\t Cost: 15.438716381504202\n",
            "Iteration: 1949\t Weight1: [9.04261726]\t Weight2: [1.24601674]\t Bias: [2.65930746]\t Cost: 15.43871485632955\n",
            "Iteration: 1950\t Weight1: [9.04269384]\t Weight2: [1.24589474]\t Bias: [2.65920931]\t Cost: 15.43871333918378\n",
            "Iteration: 1951\t Weight1: [9.04277023]\t Weight2: [1.24577304]\t Bias: [2.65911145]\t Cost: 15.4387118300243\n",
            "Iteration: 1952\t Weight1: [9.04284643]\t Weight2: [1.24565164]\t Bias: [2.65901387]\t Cost: 15.438710328808876\n",
            "Iteration: 1953\t Weight1: [9.04292243]\t Weight2: [1.24553054]\t Bias: [2.65891659]\t Cost: 15.43870883549538\n",
            "Iteration: 1954\t Weight1: [9.04299823]\t Weight2: [1.24540974]\t Bias: [2.65881958]\t Cost: 15.438707350041991\n",
            "Iteration: 1955\t Weight1: [9.04307384]\t Weight2: [1.24528924]\t Bias: [2.65872287]\t Cost: 15.43870587240707\n",
            "Iteration: 1956\t Weight1: [9.04314925]\t Weight2: [1.24516904]\t Bias: [2.65862644]\t Cost: 15.438704402549213\n",
            "Iteration: 1957\t Weight1: [9.04322448]\t Weight2: [1.24504913]\t Bias: [2.65853029]\t Cost: 15.43870294042723\n",
            "Iteration: 1958\t Weight1: [9.04329951]\t Weight2: [1.24492952]\t Bias: [2.65843442]\t Cost: 15.438701486000175\n",
            "Iteration: 1959\t Weight1: [9.04337434]\t Weight2: [1.2448102]\t Bias: [2.65833883]\t Cost: 15.438700039227285\n",
            "Iteration: 1960\t Weight1: [9.04344899]\t Weight2: [1.24469118]\t Bias: [2.65824353]\t Cost: 15.438698600068046\n",
            "Iteration: 1961\t Weight1: [9.04352344]\t Weight2: [1.24457245]\t Bias: [2.6581485]\t Cost: 15.438697168482138\n",
            "Iteration: 1962\t Weight1: [9.04359771]\t Weight2: [1.24445402]\t Bias: [2.65805375]\t Cost: 15.43869574442947\n",
            "Iteration: 1963\t Weight1: [9.04367178]\t Weight2: [1.24433588]\t Bias: [2.65795929]\t Cost: 15.438694327870135\n",
            "Iteration: 1964\t Weight1: [9.04374566]\t Weight2: [1.24421803]\t Bias: [2.65786509]\t Cost: 15.438692918764525\n",
            "Iteration: 1965\t Weight1: [9.04381936]\t Weight2: [1.24410047]\t Bias: [2.65777118]\t Cost: 15.438691517073133\n",
            "Iteration: 1966\t Weight1: [9.04389286]\t Weight2: [1.2439832]\t Bias: [2.65767754]\t Cost: 15.438690122756721\n",
            "Iteration: 1967\t Weight1: [9.04396618]\t Weight2: [1.24386623]\t Bias: [2.65758417]\t Cost: 15.438688735776266\n",
            "Iteration: 1968\t Weight1: [9.04403931]\t Weight2: [1.24374954]\t Bias: [2.65749108]\t Cost: 15.438687356092926\n",
            "Iteration: 1969\t Weight1: [9.04411225]\t Weight2: [1.24363314]\t Bias: [2.65739826]\t Cost: 15.438685983668103\n",
            "Iteration: 1970\t Weight1: [9.044185]\t Weight2: [1.24351703]\t Bias: [2.65730571]\t Cost: 15.438684618463354\n",
            "Iteration: 1971\t Weight1: [9.04425757]\t Weight2: [1.2434012]\t Bias: [2.65721344]\t Cost: 15.438683260440486\n",
            "Iteration: 1972\t Weight1: [9.04432995]\t Weight2: [1.24328567]\t Bias: [2.65712143]\t Cost: 15.438681909561502\n",
            "Iteration: 1973\t Weight1: [9.04440215]\t Weight2: [1.24317041]\t Bias: [2.65702969]\t Cost: 15.43868056578858\n",
            "Iteration: 1974\t Weight1: [9.04447416]\t Weight2: [1.24305545]\t Bias: [2.65693823]\t Cost: 15.43867922908412\n",
            "Iteration: 1975\t Weight1: [9.04454599]\t Weight2: [1.24294076]\t Bias: [2.65684703]\t Cost: 15.438677899410754\n",
            "Iteration: 1976\t Weight1: [9.04461763]\t Weight2: [1.24282636]\t Bias: [2.65675609]\t Cost: 15.43867657673124\n",
            "Iteration: 1977\t Weight1: [9.04468909]\t Weight2: [1.24271225]\t Bias: [2.65666543]\t Cost: 15.438675261008594\n",
            "Iteration: 1978\t Weight1: [9.04476037]\t Weight2: [1.24259842]\t Bias: [2.65657503]\t Cost: 15.438673952206019\n",
            "Iteration: 1979\t Weight1: [9.04483146]\t Weight2: [1.24248486]\t Bias: [2.65648489]\t Cost: 15.438672650286897\n",
            "Iteration: 1980\t Weight1: [9.04490237]\t Weight2: [1.24237159]\t Bias: [2.65639502]\t Cost: 15.43867135521482\n",
            "Iteration: 1981\t Weight1: [9.0449731]\t Weight2: [1.2422586]\t Bias: [2.65630541]\t Cost: 15.438670066953554\n",
            "Iteration: 1982\t Weight1: [9.04504365]\t Weight2: [1.24214589]\t Bias: [2.65621606]\t Cost: 15.438668785467101\n",
            "Iteration: 1983\t Weight1: [9.04511401]\t Weight2: [1.24203346]\t Bias: [2.65612698]\t Cost: 15.438667510719602\n",
            "Iteration: 1984\t Weight1: [9.0451842]\t Weight2: [1.24192131]\t Bias: [2.65603815]\t Cost: 15.438666242675444\n",
            "Iteration: 1985\t Weight1: [9.04525421]\t Weight2: [1.24180943]\t Bias: [2.65594959]\t Cost: 15.438664981299148\n",
            "Iteration: 1986\t Weight1: [9.04532403]\t Weight2: [1.24169783]\t Bias: [2.65586128]\t Cost: 15.438663726555463\n",
            "Iteration: 1987\t Weight1: [9.04539368]\t Weight2: [1.24158651]\t Bias: [2.65577324]\t Cost: 15.4386624784093\n",
            "Iteration: 1988\t Weight1: [9.04546315]\t Weight2: [1.24147546]\t Bias: [2.65568545]\t Cost: 15.4386612368258\n",
            "Iteration: 1989\t Weight1: [9.04553244]\t Weight2: [1.24136469]\t Bias: [2.65559791]\t Cost: 15.438660001770236\n",
            "Iteration: 1990\t Weight1: [9.04560155]\t Weight2: [1.24125419]\t Bias: [2.65551064]\t Cost: 15.438658773208093\n",
            "Iteration: 1991\t Weight1: [9.04567049]\t Weight2: [1.24114397]\t Bias: [2.65542361]\t Cost: 15.438657551105063\n",
            "Iteration: 1992\t Weight1: [9.04573925]\t Weight2: [1.24103402]\t Bias: [2.65533685]\t Cost: 15.438656335426963\n",
            "Iteration: 1993\t Weight1: [9.04580783]\t Weight2: [1.24092434]\t Bias: [2.65525033]\t Cost: 15.438655126139846\n",
            "Iteration: 1994\t Weight1: [9.04587624]\t Weight2: [1.24081493]\t Bias: [2.65516407]\t Cost: 15.438653923209916\n",
            "Iteration: 1995\t Weight1: [9.04594447]\t Weight2: [1.2407058]\t Bias: [2.65507806]\t Cost: 15.438652726603578\n",
            "Iteration: 1996\t Weight1: [9.04601253]\t Weight2: [1.24059693]\t Bias: [2.65499231]\t Cost: 15.43865153628738\n",
            "Iteration: 1997\t Weight1: [9.04608041]\t Weight2: [1.24048834]\t Bias: [2.6549068]\t Cost: 15.438650352228105\n",
            "Iteration: 1998\t Weight1: [9.04614812]\t Weight2: [1.24038001]\t Bias: [2.65482154]\t Cost: 15.438649174392669\n",
            "Iteration: 1999\t Weight1: [9.04621565]\t Weight2: [1.24027195]\t Bias: [2.65473654]\t Cost: 15.438648002748153\n",
            "Iteration: 2000\t Weight1: [9.04628301]\t Weight2: [1.24016416]\t Bias: [2.65465178]\t Cost: 15.43864683726187\n",
            "Iteration: 2001\t Weight1: [9.0463502]\t Weight2: [1.24005664]\t Bias: [2.65456726]\t Cost: 15.438645677901253\n",
            "Iteration: 2002\t Weight1: [9.04641722]\t Weight2: [1.23994938]\t Bias: [2.654483]\t Cost: 15.438644524633938\n",
            "Iteration: 2003\t Weight1: [9.04648406]\t Weight2: [1.23984239]\t Bias: [2.65439898]\t Cost: 15.438643377427713\n",
            "Iteration: 2004\t Weight1: [9.04655074]\t Weight2: [1.23973567]\t Bias: [2.65431521]\t Cost: 15.438642236250582\n",
            "Iteration: 2005\t Weight1: [9.04661724]\t Weight2: [1.23962921]\t Bias: [2.65423168]\t Cost: 15.438641101070637\n",
            "Iteration: 2006\t Weight1: [9.04668357]\t Weight2: [1.23952301]\t Bias: [2.65414839]\t Cost: 15.438639971856238\n",
            "Iteration: 2007\t Weight1: [9.04674973]\t Weight2: [1.23941708]\t Bias: [2.65406535]\t Cost: 15.438638848575819\n",
            "Iteration: 2008\t Weight1: [9.04681572]\t Weight2: [1.23931141]\t Bias: [2.65398255]\t Cost: 15.438637731198066\n",
            "Iteration: 2009\t Weight1: [9.04688154]\t Weight2: [1.239206]\t Bias: [2.65389999]\t Cost: 15.438636619691778\n",
            "Iteration: 2010\t Weight1: [9.0469472]\t Weight2: [1.23910085]\t Bias: [2.65381767]\t Cost: 15.438635514025929\n",
            "Iteration: 2011\t Weight1: [9.04701268]\t Weight2: [1.23899596]\t Bias: [2.65373559]\t Cost: 15.438634414169684\n",
            "Iteration: 2012\t Weight1: [9.047078]\t Weight2: [1.23889134]\t Bias: [2.65365376]\t Cost: 15.438633320092345\n",
            "Iteration: 2013\t Weight1: [9.04714315]\t Weight2: [1.23878697]\t Bias: [2.65357216]\t Cost: 15.438632231763371\n",
            "Iteration: 2014\t Weight1: [9.04720813]\t Weight2: [1.23868286]\t Bias: [2.6534908]\t Cost: 15.438631149152418\n",
            "Iteration: 2015\t Weight1: [9.04727295]\t Weight2: [1.23857901]\t Bias: [2.65340967]\t Cost: 15.438630072229271\n",
            "Iteration: 2016\t Weight1: [9.04733759]\t Weight2: [1.23847542]\t Bias: [2.65332878]\t Cost: 15.438629000963909\n",
            "Iteration: 2017\t Weight1: [9.04740208]\t Weight2: [1.23837209]\t Bias: [2.65324813]\t Cost: 15.438627935326425\n",
            "Iteration: 2018\t Weight1: [9.0474664]\t Weight2: [1.23826901]\t Bias: [2.65316772]\t Cost: 15.438626875287113\n",
            "Iteration: 2019\t Weight1: [9.04753055]\t Weight2: [1.23816619]\t Bias: [2.65308753]\t Cost: 15.438625820816405\n",
            "Iteration: 2020\t Weight1: [9.04759454]\t Weight2: [1.23806362]\t Bias: [2.65300759]\t Cost: 15.438624771884895\n",
            "Iteration: 2021\t Weight1: [9.04765836]\t Weight2: [1.23796131]\t Bias: [2.65292787]\t Cost: 15.438623728463314\n",
            "Iteration: 2022\t Weight1: [9.04772202]\t Weight2: [1.23785925]\t Bias: [2.65284839]\t Cost: 15.438622690522603\n",
            "Iteration: 2023\t Weight1: [9.04778552]\t Weight2: [1.23775744]\t Bias: [2.65276914]\t Cost: 15.438621658033796\n",
            "Iteration: 2024\t Weight1: [9.04784885]\t Weight2: [1.23765589]\t Bias: [2.65269012]\t Cost: 15.43862063096812\n",
            "Iteration: 2025\t Weight1: [9.04791202]\t Weight2: [1.23755459]\t Bias: [2.65261133]\t Cost: 15.43861960929694\n",
            "Iteration: 2026\t Weight1: [9.04797503]\t Weight2: [1.23745354]\t Bias: [2.65253276]\t Cost: 15.438618592991778\n",
            "Iteration: 2027\t Weight1: [9.04803788]\t Weight2: [1.23735274]\t Bias: [2.65245443]\t Cost: 15.43861758202427\n",
            "Iteration: 2028\t Weight1: [9.04810057]\t Weight2: [1.2372522]\t Bias: [2.65237633]\t Cost: 15.438616576366298\n",
            "Iteration: 2029\t Weight1: [9.04816309]\t Weight2: [1.2371519]\t Bias: [2.65229845]\t Cost: 15.438615575989799\n",
            "Iteration: 2030\t Weight1: [9.04822546]\t Weight2: [1.23705185]\t Bias: [2.6522208]\t Cost: 15.438614580866897\n",
            "Iteration: 2031\t Weight1: [9.04828766]\t Weight2: [1.23695205]\t Bias: [2.65214338]\t Cost: 15.438613590969863\n",
            "Iteration: 2032\t Weight1: [9.04834971]\t Weight2: [1.2368525]\t Bias: [2.65206618]\t Cost: 15.438612606271105\n",
            "Iteration: 2033\t Weight1: [9.04841159]\t Weight2: [1.23675319]\t Bias: [2.65198921]\t Cost: 15.438611626743183\n",
            "Iteration: 2034\t Weight1: [9.04847332]\t Weight2: [1.23665413]\t Bias: [2.65191246]\t Cost: 15.438610652358841\n",
            "Iteration: 2035\t Weight1: [9.04853489]\t Weight2: [1.23655532]\t Bias: [2.65183593]\t Cost: 15.438609683090903\n",
            "Iteration: 2036\t Weight1: [9.0485963]\t Weight2: [1.23645676]\t Bias: [2.65175963]\t Cost: 15.438608718912361\n",
            "Iteration: 2037\t Weight1: [9.04865755]\t Weight2: [1.23635843]\t Bias: [2.65168354]\t Cost: 15.438607759796382\n",
            "Iteration: 2038\t Weight1: [9.04871865]\t Weight2: [1.23626036]\t Bias: [2.65160768]\t Cost: 15.438606805716237\n",
            "Iteration: 2039\t Weight1: [9.04877959]\t Weight2: [1.23616252]\t Bias: [2.65153204]\t Cost: 15.438605856645356\n",
            "Iteration: 2040\t Weight1: [9.04884037]\t Weight2: [1.23606493]\t Bias: [2.65145662]\t Cost: 15.438604912557304\n",
            "Iteration: 2041\t Weight1: [9.048901]\t Weight2: [1.23596758]\t Bias: [2.65138142]\t Cost: 15.43860397342579\n",
            "Iteration: 2042\t Weight1: [9.04896147]\t Weight2: [1.23587048]\t Bias: [2.65130644]\t Cost: 15.438603039224652\n",
            "Iteration: 2043\t Weight1: [9.04902179]\t Weight2: [1.23577361]\t Bias: [2.65123168]\t Cost: 15.438602109927906\n",
            "Iteration: 2044\t Weight1: [9.04908195]\t Weight2: [1.23567699]\t Bias: [2.65115713]\t Cost: 15.43860118550966\n",
            "Iteration: 2045\t Weight1: [9.04914195]\t Weight2: [1.23558061]\t Bias: [2.6510828]\t Cost: 15.438600265944176\n",
            "Iteration: 2046\t Weight1: [9.04920181]\t Weight2: [1.23548446]\t Bias: [2.65100869]\t Cost: 15.438599351205848\n",
            "Iteration: 2047\t Weight1: [9.0492615]\t Weight2: [1.23538856]\t Bias: [2.65093479]\t Cost: 15.43859844126922\n",
            "Iteration: 2048\t Weight1: [9.04932105]\t Weight2: [1.23529289]\t Bias: [2.6508611]\t Cost: 15.438597536108965\n",
            "Iteration: 2049\t Weight1: [9.04938044]\t Weight2: [1.23519746]\t Bias: [2.65078763]\t Cost: 15.438596635699886\n",
            "Iteration: 2050\t Weight1: [9.04943968]\t Weight2: [1.23510227]\t Bias: [2.65071438]\t Cost: 15.43859574001693\n",
            "Iteration: 2051\t Weight1: [9.04949877]\t Weight2: [1.23500732]\t Bias: [2.65064133]\t Cost: 15.438594849035141\n",
            "Iteration: 2052\t Weight1: [9.04955771]\t Weight2: [1.2349126]\t Bias: [2.6505685]\t Cost: 15.438593962729774\n",
            "Iteration: 2053\t Weight1: [9.04961649]\t Weight2: [1.23481812]\t Bias: [2.65049588]\t Cost: 15.438593081076114\n",
            "Iteration: 2054\t Weight1: [9.04967513]\t Weight2: [1.23472387]\t Bias: [2.65042347]\t Cost: 15.438592204049653\n",
            "Iteration: 2055\t Weight1: [9.04973361]\t Weight2: [1.23462986]\t Bias: [2.65035128]\t Cost: 15.438591331626002\n",
            "Iteration: 2056\t Weight1: [9.04979195]\t Weight2: [1.23453608]\t Bias: [2.65027929]\t Cost: 15.438590463780864\n",
            "Iteration: 2057\t Weight1: [9.04985013]\t Weight2: [1.23444253]\t Bias: [2.65020751]\t Cost: 15.43858960049012\n",
            "Iteration: 2058\t Weight1: [9.04990816]\t Weight2: [1.23434922]\t Bias: [2.65013594]\t Cost: 15.438588741729726\n",
            "Iteration: 2059\t Weight1: [9.04996605]\t Weight2: [1.23425614]\t Bias: [2.65006457]\t Cost: 15.438587887475828\n",
            "Iteration: 2060\t Weight1: [9.05002379]\t Weight2: [1.23416329]\t Bias: [2.64999341]\t Cost: 15.438587037704634\n",
            "Iteration: 2061\t Weight1: [9.05008137]\t Weight2: [1.23407067]\t Bias: [2.64992246]\t Cost: 15.438586192392519\n",
            "Iteration: 2062\t Weight1: [9.05013882]\t Weight2: [1.23397829]\t Bias: [2.64985172]\t Cost: 15.43858535151597\n",
            "Iteration: 2063\t Weight1: [9.05019611]\t Weight2: [1.23388613]\t Bias: [2.64978118]\t Cost: 15.43858451505162\n",
            "Iteration: 2064\t Weight1: [9.05025325]\t Weight2: [1.2337942]\t Bias: [2.64971085]\t Cost: 15.438583682976201\n",
            "Iteration: 2065\t Weight1: [9.05031025]\t Weight2: [1.2337025]\t Bias: [2.64964071]\t Cost: 15.438582855266572\n",
            "Iteration: 2066\t Weight1: [9.05036711]\t Weight2: [1.23361103]\t Bias: [2.64957079]\t Cost: 15.438582031899724\n",
            "Iteration: 2067\t Weight1: [9.05042381]\t Weight2: [1.23351979]\t Bias: [2.64950106]\t Cost: 15.438581212852752\n",
            "Iteration: 2068\t Weight1: [9.05048037]\t Weight2: [1.23342877]\t Bias: [2.64943154]\t Cost: 15.438580398102896\n",
            "Iteration: 2069\t Weight1: [9.05053679]\t Weight2: [1.23333798]\t Bias: [2.64936222]\t Cost: 15.438579587627519\n",
            "Iteration: 2070\t Weight1: [9.05059306]\t Weight2: [1.23324742]\t Bias: [2.6492931]\t Cost: 15.438578781404066\n",
            "Iteration: 2071\t Weight1: [9.05064919]\t Weight2: [1.23315708]\t Bias: [2.64922418]\t Cost: 15.438577979410141\n",
            "Iteration: 2072\t Weight1: [9.05070517]\t Weight2: [1.23306697]\t Bias: [2.64915546]\t Cost: 15.438577181623447\n",
            "Iteration: 2073\t Weight1: [9.05076101]\t Weight2: [1.23297708]\t Bias: [2.64908694]\t Cost: 15.438576388021819\n",
            "Iteration: 2074\t Weight1: [9.05081671]\t Weight2: [1.23288742]\t Bias: [2.64901862]\t Cost: 15.438575598583215\n",
            "Iteration: 2075\t Weight1: [9.05087226]\t Weight2: [1.23279798]\t Bias: [2.64895049]\t Cost: 15.438574813285664\n",
            "Iteration: 2076\t Weight1: [9.05092767]\t Weight2: [1.23270876]\t Bias: [2.64888257]\t Cost: 15.438574032107374\n",
            "Iteration: 2077\t Weight1: [9.05098293]\t Weight2: [1.23261976]\t Bias: [2.64881484]\t Cost: 15.438573255026611\n",
            "Iteration: 2078\t Weight1: [9.05103806]\t Weight2: [1.23253099]\t Bias: [2.6487473]\t Cost: 15.438572482021813\n",
            "Iteration: 2079\t Weight1: [9.05109304]\t Weight2: [1.23244244]\t Bias: [2.64867996]\t Cost: 15.438571713071488\n",
            "Iteration: 2080\t Weight1: [9.05114789]\t Weight2: [1.2323541]\t Bias: [2.64861282]\t Cost: 15.438570948154286\n",
            "Iteration: 2081\t Weight1: [9.05120259]\t Weight2: [1.23226599]\t Bias: [2.64854587]\t Cost: 15.438570187248942\n",
            "Iteration: 2082\t Weight1: [9.05125715]\t Weight2: [1.2321781]\t Bias: [2.64847912]\t Cost: 15.438569430334322\n",
            "Iteration: 2083\t Weight1: [9.05131157]\t Weight2: [1.23209043]\t Bias: [2.64841255]\t Cost: 15.438568677389405\n",
            "Iteration: 2084\t Weight1: [9.05136585]\t Weight2: [1.23200297]\t Bias: [2.64834619]\t Cost: 15.438567928393287\n",
            "Iteration: 2085\t Weight1: [9.05141999]\t Weight2: [1.23191574]\t Bias: [2.64828001]\t Cost: 15.438567183325164\n",
            "Iteration: 2086\t Weight1: [9.05147399]\t Weight2: [1.23182872]\t Bias: [2.64821402]\t Cost: 15.438566442164348\n",
            "Iteration: 2087\t Weight1: [9.05152786]\t Weight2: [1.23174191]\t Bias: [2.64814823]\t Cost: 15.438565704890237\n",
            "Iteration: 2088\t Weight1: [9.05158158]\t Weight2: [1.23165533]\t Bias: [2.64808262]\t Cost: 15.438564971482373\n",
            "Iteration: 2089\t Weight1: [9.05163517]\t Weight2: [1.23156896]\t Bias: [2.64801721]\t Cost: 15.438564241920387\n",
            "Iteration: 2090\t Weight1: [9.05168862]\t Weight2: [1.2314828]\t Bias: [2.64795198]\t Cost: 15.438563516184034\n",
            "Iteration: 2091\t Weight1: [9.05174193]\t Weight2: [1.23139686]\t Bias: [2.64788695]\t Cost: 15.438562794253142\n",
            "Iteration: 2092\t Weight1: [9.05179511]\t Weight2: [1.23131114]\t Bias: [2.6478221]\t Cost: 15.438562076107704\n",
            "Iteration: 2093\t Weight1: [9.05184815]\t Weight2: [1.23122563]\t Bias: [2.64775744]\t Cost: 15.438561361727759\n",
            "Iteration: 2094\t Weight1: [9.05190105]\t Weight2: [1.23114033]\t Bias: [2.64769297]\t Cost: 15.438560651093477\n",
            "Iteration: 2095\t Weight1: [9.05195382]\t Weight2: [1.23105524]\t Bias: [2.64762868]\t Cost: 15.438559944185137\n",
            "Iteration: 2096\t Weight1: [9.05200645]\t Weight2: [1.23097037]\t Bias: [2.64756458]\t Cost: 15.438559240983126\n",
            "Iteration: 2097\t Weight1: [9.05205894]\t Weight2: [1.23088571]\t Bias: [2.64750066]\t Cost: 15.438558541467922\n",
            "Iteration: 2098\t Weight1: [9.05211131]\t Weight2: [1.23080126]\t Bias: [2.64743693]\t Cost: 15.43855784562011\n",
            "Iteration: 2099\t Weight1: [9.05216353]\t Weight2: [1.23071702]\t Bias: [2.64737338]\t Cost: 15.438557153420383\n",
            "Iteration: 2100\t Weight1: [9.05221562]\t Weight2: [1.23063299]\t Bias: [2.64731002]\t Cost: 15.438556464849528\n",
            "Iteration: 2101\t Weight1: [9.05226758]\t Weight2: [1.23054917]\t Bias: [2.64724684]\t Cost: 15.438555779888452\n",
            "Iteration: 2102\t Weight1: [9.05231941]\t Weight2: [1.23046556]\t Bias: [2.64718384]\t Cost: 15.438555098518137\n",
            "Iteration: 2103\t Weight1: [9.0523711]\t Weight2: [1.23038216]\t Bias: [2.64712102]\t Cost: 15.43855442071969\n",
            "Iteration: 2104\t Weight1: [9.05242266]\t Weight2: [1.23029896]\t Bias: [2.64705839]\t Cost: 15.438553746474296\n",
            "Iteration: 2105\t Weight1: [9.05247408]\t Weight2: [1.23021598]\t Bias: [2.64699593]\t Cost: 15.43855307576325\n",
            "Iteration: 2106\t Weight1: [9.05252538]\t Weight2: [1.2301332]\t Bias: [2.64693366]\t Cost: 15.438552408567952\n",
            "Iteration: 2107\t Weight1: [9.05257654]\t Weight2: [1.23005063]\t Bias: [2.64687157]\t Cost: 15.438551744869905\n",
            "Iteration: 2108\t Weight1: [9.05262757]\t Weight2: [1.22996826]\t Bias: [2.64680965]\t Cost: 15.438551084650687\n",
            "Iteration: 2109\t Weight1: [9.05267847]\t Weight2: [1.2298861]\t Bias: [2.64674792]\t Cost: 15.438550427891991\n",
            "Iteration: 2110\t Weight1: [9.05272924]\t Weight2: [1.22980414]\t Bias: [2.64668636]\t Cost: 15.4385497745756\n",
            "Iteration: 2111\t Weight1: [9.05277988]\t Weight2: [1.22972239]\t Bias: [2.64662498]\t Cost: 15.438549124683394\n",
            "Iteration: 2112\t Weight1: [9.05283039]\t Weight2: [1.22964085]\t Bias: [2.64656378]\t Cost: 15.438548478197362\n",
            "Iteration: 2113\t Weight1: [9.05288077]\t Weight2: [1.2295595]\t Bias: [2.64650275]\t Cost: 15.438547835099575\n",
            "Iteration: 2114\t Weight1: [9.05293102]\t Weight2: [1.22947836]\t Bias: [2.6464419]\t Cost: 15.438547195372186\n",
            "Iteration: 2115\t Weight1: [9.05298114]\t Weight2: [1.22939743]\t Bias: [2.64638123]\t Cost: 15.438546558997475\n",
            "Iteration: 2116\t Weight1: [9.05303113]\t Weight2: [1.22931669]\t Bias: [2.64632073]\t Cost: 15.43854592595779\n",
            "Iteration: 2117\t Weight1: [9.05308099]\t Weight2: [1.22923616]\t Bias: [2.6462604]\t Cost: 15.43854529623559\n",
            "Iteration: 2118\t Weight1: [9.05313072]\t Weight2: [1.22915583]\t Bias: [2.64620025]\t Cost: 15.438544669813417\n",
            "Iteration: 2119\t Weight1: [9.05318033]\t Weight2: [1.22907569]\t Bias: [2.64614027]\t Cost: 15.4385440466739\n",
            "Iteration: 2120\t Weight1: [9.05322981]\t Weight2: [1.22899576]\t Bias: [2.64608047]\t Cost: 15.438543426799772\n",
            "Iteration: 2121\t Weight1: [9.05327916]\t Weight2: [1.22891603]\t Bias: [2.64602084]\t Cost: 15.438542810173852\n",
            "Iteration: 2122\t Weight1: [9.05332839]\t Weight2: [1.2288365]\t Bias: [2.64596138]\t Cost: 15.43854219677904\n",
            "Iteration: 2123\t Weight1: [9.05337748]\t Weight2: [1.22875717]\t Bias: [2.64590209]\t Cost: 15.43854158659834\n",
            "Iteration: 2124\t Weight1: [9.05342646]\t Weight2: [1.22867803]\t Bias: [2.64584297]\t Cost: 15.438540979614844\n",
            "Iteration: 2125\t Weight1: [9.0534753]\t Weight2: [1.22859909]\t Bias: [2.64578402]\t Cost: 15.438540375811744\n",
            "Iteration: 2126\t Weight1: [9.05352402]\t Weight2: [1.22852035]\t Bias: [2.64572525]\t Cost: 15.438539775172304\n",
            "Iteration: 2127\t Weight1: [9.05357262]\t Weight2: [1.22844181]\t Bias: [2.64566664]\t Cost: 15.438539177679864\n",
            "Iteration: 2128\t Weight1: [9.05362109]\t Weight2: [1.22836346]\t Bias: [2.6456082]\t Cost: 15.43853858331788\n",
            "Iteration: 2129\t Weight1: [9.05366944]\t Weight2: [1.22828531]\t Bias: [2.64554993]\t Cost: 15.438537992069895\n",
            "Iteration: 2130\t Weight1: [9.05371766]\t Weight2: [1.22820735]\t Bias: [2.64549183]\t Cost: 15.438537403919517\n",
            "Iteration: 2131\t Weight1: [9.05376576]\t Weight2: [1.22812959]\t Bias: [2.64543389]\t Cost: 15.438536818850455\n",
            "Iteration: 2132\t Weight1: [9.05381373]\t Weight2: [1.22805202]\t Bias: [2.64537612]\t Cost: 15.438536236846502\n",
            "Iteration: 2133\t Weight1: [9.05386158]\t Weight2: [1.22797465]\t Bias: [2.64531852]\t Cost: 15.438535657891538\n",
            "Iteration: 2134\t Weight1: [9.05390931]\t Weight2: [1.22789747]\t Bias: [2.64526108]\t Cost: 15.438535081969551\n",
            "Iteration: 2135\t Weight1: [9.05395691]\t Weight2: [1.22782048]\t Bias: [2.64520381]\t Cost: 15.43853450906455\n",
            "Iteration: 2136\t Weight1: [9.0540044]\t Weight2: [1.22774369]\t Bias: [2.64514671]\t Cost: 15.438533939160685\n",
            "Iteration: 2137\t Weight1: [9.05405176]\t Weight2: [1.22766709]\t Bias: [2.64508977]\t Cost: 15.438533372242171\n",
            "Iteration: 2138\t Weight1: [9.054099]\t Weight2: [1.22759068]\t Bias: [2.64503299]\t Cost: 15.438532808293305\n",
            "Iteration: 2139\t Weight1: [9.05414611]\t Weight2: [1.22751446]\t Bias: [2.64497637]\t Cost: 15.438532247298479\n",
            "Iteration: 2140\t Weight1: [9.05419311]\t Weight2: [1.22743843]\t Bias: [2.64491992]\t Cost: 15.438531689242161\n",
            "Iteration: 2141\t Weight1: [9.05423998]\t Weight2: [1.22736259]\t Bias: [2.64486363]\t Cost: 15.438531134108896\n",
            "Iteration: 2142\t Weight1: [9.05428674]\t Weight2: [1.22728694]\t Bias: [2.64480751]\t Cost: 15.43853058188332\n",
            "Iteration: 2143\t Weight1: [9.05433337]\t Weight2: [1.22721148]\t Bias: [2.64475154]\t Cost: 15.438530032550128\n",
            "Iteration: 2144\t Weight1: [9.05437989]\t Weight2: [1.22713621]\t Bias: [2.64469574]\t Cost: 15.438529486094133\n",
            "Iteration: 2145\t Weight1: [9.05442628]\t Weight2: [1.22706113]\t Bias: [2.64464009]\t Cost: 15.438528942500186\n",
            "Iteration: 2146\t Weight1: [9.05447256]\t Weight2: [1.22698623]\t Bias: [2.64458461]\t Cost: 15.438528401753265\n",
            "Iteration: 2147\t Weight1: [9.05451872]\t Weight2: [1.22691153]\t Bias: [2.64452928]\t Cost: 15.43852786383837\n",
            "Iteration: 2148\t Weight1: [9.05456475]\t Weight2: [1.22683701]\t Bias: [2.64447412]\t Cost: 15.438527328740637\n",
            "Iteration: 2149\t Weight1: [9.05461067]\t Weight2: [1.22676267]\t Bias: [2.64441911]\t Cost: 15.438526796445249\n",
            "Iteration: 2150\t Weight1: [9.05465648]\t Weight2: [1.22668853]\t Bias: [2.64436426]\t Cost: 15.438526266937473\n",
            "Iteration: 2151\t Weight1: [9.05470216]\t Weight2: [1.22661456]\t Bias: [2.64430957]\t Cost: 15.438525740202662\n",
            "Iteration: 2152\t Weight1: [9.05474773]\t Weight2: [1.22654079]\t Bias: [2.64425504]\t Cost: 15.438525216226235\n",
            "Iteration: 2153\t Weight1: [9.05479317]\t Weight2: [1.22646719]\t Bias: [2.64420066]\t Cost: 15.43852469499369\n",
            "Iteration: 2154\t Weight1: [9.05483851]\t Weight2: [1.22639379]\t Bias: [2.64414644]\t Cost: 15.438524176490619\n",
            "Iteration: 2155\t Weight1: [9.05488372]\t Weight2: [1.22632056]\t Bias: [2.64409237]\t Cost: 15.43852366070265\n",
            "Iteration: 2156\t Weight1: [9.05492882]\t Weight2: [1.22624752]\t Bias: [2.64403847]\t Cost: 15.438523147615529\n",
            "Iteration: 2157\t Weight1: [9.0549738]\t Weight2: [1.22617466]\t Bias: [2.64398471]\t Cost: 15.438522637215058\n",
            "Iteration: 2158\t Weight1: [9.05501867]\t Weight2: [1.22610199]\t Bias: [2.64393111]\t Cost: 15.438522129487126\n",
            "Iteration: 2159\t Weight1: [9.05506342]\t Weight2: [1.22602949]\t Bias: [2.64387766]\t Cost: 15.438521624417662\n",
            "Iteration: 2160\t Weight1: [9.05510806]\t Weight2: [1.22595718]\t Bias: [2.64382437]\t Cost: 15.438521121992714\n",
            "Iteration: 2161\t Weight1: [9.05515258]\t Weight2: [1.22588505]\t Bias: [2.64377123]\t Cost: 15.438520622198386\n",
            "Iteration: 2162\t Weight1: [9.05519699]\t Weight2: [1.2258131]\t Bias: [2.64371824]\t Cost: 15.438520125020855\n",
            "Iteration: 2163\t Weight1: [9.05524129]\t Weight2: [1.22574133]\t Bias: [2.64366541]\t Cost: 15.438519630446368\n",
            "Iteration: 2164\t Weight1: [9.05528546]\t Weight2: [1.22566974]\t Bias: [2.64361273]\t Cost: 15.438519138461238\n",
            "Iteration: 2165\t Weight1: [9.05532953]\t Weight2: [1.22559832]\t Bias: [2.64356019]\t Cost: 15.438518649051863\n",
            "Iteration: 2166\t Weight1: [9.05537348]\t Weight2: [1.22552709]\t Bias: [2.64350781]\t Cost: 15.438518162204723\n",
            "Iteration: 2167\t Weight1: [9.05541732]\t Weight2: [1.22545604]\t Bias: [2.64345558]\t Cost: 15.438517677906326\n",
            "Iteration: 2168\t Weight1: [9.05546105]\t Weight2: [1.22538516]\t Bias: [2.6434035]\t Cost: 15.438517196143298\n",
            "Iteration: 2169\t Weight1: [9.05550466]\t Weight2: [1.22531446]\t Bias: [2.64335157]\t Cost: 15.438516716902319\n",
            "Iteration: 2170\t Weight1: [9.05554817]\t Weight2: [1.22524394]\t Bias: [2.64329979]\t Cost: 15.43851624017014\n",
            "Iteration: 2171\t Weight1: [9.05559156]\t Weight2: [1.2251736]\t Bias: [2.64324815]\t Cost: 15.438515765933582\n",
            "Iteration: 2172\t Weight1: [9.05563483]\t Weight2: [1.22510343]\t Bias: [2.64319667]\t Cost: 15.43851529417952\n",
            "Iteration: 2173\t Weight1: [9.055678]\t Weight2: [1.22503344]\t Bias: [2.64314533]\t Cost: 15.438514824894936\n",
            "Iteration: 2174\t Weight1: [9.05572106]\t Weight2: [1.22496362]\t Bias: [2.64309414]\t Cost: 15.438514358066834\n",
            "Iteration: 2175\t Weight1: [9.055764]\t Weight2: [1.22489398]\t Bias: [2.64304309]\t Cost: 15.438513893682305\n",
            "Iteration: 2176\t Weight1: [9.05580684]\t Weight2: [1.22482451]\t Bias: [2.64299219]\t Cost: 15.438513431728545\n",
            "Iteration: 2177\t Weight1: [9.05584956]\t Weight2: [1.22475521]\t Bias: [2.64294144]\t Cost: 15.438512972192763\n",
            "Iteration: 2178\t Weight1: [9.05589218]\t Weight2: [1.22468609]\t Bias: [2.64289084]\t Cost: 15.438512515062271\n",
            "Iteration: 2179\t Weight1: [9.05593468]\t Weight2: [1.22461715]\t Bias: [2.64284037]\t Cost: 15.438512060324415\n",
            "Iteration: 2180\t Weight1: [9.05597708]\t Weight2: [1.22454837]\t Bias: [2.64279006]\t Cost: 15.438511607966655\n",
            "Iteration: 2181\t Weight1: [9.05601937]\t Weight2: [1.22447977]\t Bias: [2.64273988]\t Cost: 15.438511157976459\n",
            "Iteration: 2182\t Weight1: [9.05606154]\t Weight2: [1.22441134]\t Bias: [2.64268986]\t Cost: 15.438510710341417\n",
            "Iteration: 2183\t Weight1: [9.05610361]\t Weight2: [1.22434308]\t Bias: [2.64263997]\t Cost: 15.438510265049135\n",
            "Iteration: 2184\t Weight1: [9.05614557]\t Weight2: [1.224275]\t Bias: [2.64259023]\t Cost: 15.438509822087342\n",
            "Iteration: 2185\t Weight1: [9.05618743]\t Weight2: [1.22420708]\t Bias: [2.64254063]\t Cost: 15.438509381443774\n",
            "Iteration: 2186\t Weight1: [9.05622917]\t Weight2: [1.22413934]\t Bias: [2.64249117]\t Cost: 15.438508943106278\n",
            "Iteration: 2187\t Weight1: [9.05627081]\t Weight2: [1.22407176]\t Bias: [2.64244185]\t Cost: 15.438508507062709\n",
            "Iteration: 2188\t Weight1: [9.05631234]\t Weight2: [1.22400435]\t Bias: [2.64239268]\t Cost: 15.438508073301055\n",
            "Iteration: 2189\t Weight1: [9.05635377]\t Weight2: [1.22393712]\t Bias: [2.64234364]\t Cost: 15.438507641809327\n",
            "Iteration: 2190\t Weight1: [9.05639508]\t Weight2: [1.22387005]\t Bias: [2.64229475]\t Cost: 15.438507212575589\n",
            "Iteration: 2191\t Weight1: [9.05643629]\t Weight2: [1.22380315]\t Bias: [2.642246]\t Cost: 15.438506785588013\n",
            "Iteration: 2192\t Weight1: [9.0564774]\t Weight2: [1.22373641]\t Bias: [2.64219738]\t Cost: 15.438506360834772\n",
            "Iteration: 2193\t Weight1: [9.0565184]\t Weight2: [1.22366985]\t Bias: [2.64214891]\t Cost: 15.438505938304157\n",
            "Iteration: 2194\t Weight1: [9.05655929]\t Weight2: [1.22360345]\t Bias: [2.64210057]\t Cost: 15.438505517984481\n",
            "Iteration: 2195\t Weight1: [9.05660008]\t Weight2: [1.22353722]\t Bias: [2.64205237]\t Cost: 15.438505099864168\n",
            "Iteration: 2196\t Weight1: [9.05664076]\t Weight2: [1.22347115]\t Bias: [2.64200431]\t Cost: 15.438504683931631\n",
            "Iteration: 2197\t Weight1: [9.05668134]\t Weight2: [1.22340525]\t Bias: [2.64195639]\t Cost: 15.438504270175407\n",
            "Iteration: 2198\t Weight1: [9.05672182]\t Weight2: [1.22333952]\t Bias: [2.64190861]\t Cost: 15.438503858584074\n",
            "Iteration: 2199\t Weight1: [9.05676219]\t Weight2: [1.22327395]\t Bias: [2.64186096]\t Cost: 15.438503449146245\n",
            "Iteration: 2200\t Weight1: [9.05680245]\t Weight2: [1.22320855]\t Bias: [2.64181344]\t Cost: 15.438503041850641\n",
            "Iteration: 2201\t Weight1: [9.05684262]\t Weight2: [1.2231433]\t Bias: [2.64176607]\t Cost: 15.438502636686\n",
            "Iteration: 2202\t Weight1: [9.05688268]\t Weight2: [1.22307823]\t Bias: [2.64171883]\t Cost: 15.43850223364114\n",
            "Iteration: 2203\t Weight1: [9.05692263]\t Weight2: [1.22301331]\t Bias: [2.64167172]\t Cost: 15.438501832704942\n",
            "Iteration: 2204\t Weight1: [9.05696249]\t Weight2: [1.22294856]\t Bias: [2.64162475]\t Cost: 15.43850143386632\n",
            "Iteration: 2205\t Weight1: [9.05700224]\t Weight2: [1.22288398]\t Bias: [2.64157791]\t Cost: 15.438501037114282\n",
            "Iteration: 2206\t Weight1: [9.05704188]\t Weight2: [1.22281955]\t Bias: [2.64153121]\t Cost: 15.438500642437864\n",
            "Iteration: 2207\t Weight1: [9.05708143]\t Weight2: [1.22275528]\t Bias: [2.64148464]\t Cost: 15.438500249826177\n",
            "Iteration: 2208\t Weight1: [9.05712088]\t Weight2: [1.22269118]\t Bias: [2.64143821]\t Cost: 15.438499859268395\n",
            "Iteration: 2209\t Weight1: [9.05716022]\t Weight2: [1.22262724]\t Bias: [2.6413919]\t Cost: 15.438499470753706\n",
            "Iteration: 2210\t Weight1: [9.05719946]\t Weight2: [1.22256346]\t Bias: [2.64134573]\t Cost: 15.438499084271427\n",
            "Iteration: 2211\t Weight1: [9.0572386]\t Weight2: [1.22249984]\t Bias: [2.64129969]\t Cost: 15.438498699810857\n",
            "Iteration: 2212\t Weight1: [9.05727764]\t Weight2: [1.22243638]\t Bias: [2.64125378]\t Cost: 15.438498317361407\n",
            "Iteration: 2213\t Weight1: [9.05731658]\t Weight2: [1.22237307]\t Bias: [2.64120801]\t Cost: 15.438497936912508\n",
            "Iteration: 2214\t Weight1: [9.05735542]\t Weight2: [1.22230993]\t Bias: [2.64116236]\t Cost: 15.438497558453687\n",
            "Iteration: 2215\t Weight1: [9.05739416]\t Weight2: [1.22224694]\t Bias: [2.64111685]\t Cost: 15.438497181974489\n",
            "Iteration: 2216\t Weight1: [9.0574328]\t Weight2: [1.22218412]\t Bias: [2.64107146]\t Cost: 15.438496807464508\n",
            "Iteration: 2217\t Weight1: [9.05747134]\t Weight2: [1.22212145]\t Bias: [2.64102621]\t Cost: 15.438496434913432\n",
            "Iteration: 2218\t Weight1: [9.05750978]\t Weight2: [1.22205894]\t Bias: [2.64098108]\t Cost: 15.438496064310977\n",
            "Iteration: 2219\t Weight1: [9.05754812]\t Weight2: [1.22199658]\t Bias: [2.64093608]\t Cost: 15.438495695646907\n",
            "Iteration: 2220\t Weight1: [9.05758637]\t Weight2: [1.22193439]\t Bias: [2.64089121]\t Cost: 15.438495328911078\n",
            "Iteration: 2221\t Weight1: [9.05762451]\t Weight2: [1.22187234]\t Bias: [2.64084647]\t Cost: 15.43849496409335\n",
            "Iteration: 2222\t Weight1: [9.05766256]\t Weight2: [1.22181046]\t Bias: [2.64080186]\t Cost: 15.438494601183654\n",
            "Iteration: 2223\t Weight1: [9.05770051]\t Weight2: [1.22174873]\t Bias: [2.64075737]\t Cost: 15.438494240172018\n",
            "Iteration: 2224\t Weight1: [9.05773836]\t Weight2: [1.22168715]\t Bias: [2.64071301]\t Cost: 15.438493881048428\n",
            "Iteration: 2225\t Weight1: [9.05777611]\t Weight2: [1.22162573]\t Bias: [2.64066878]\t Cost: 15.43849352380301\n",
            "Iteration: 2226\t Weight1: [9.05781377]\t Weight2: [1.22156447]\t Bias: [2.64062467]\t Cost: 15.438493168425925\n",
            "Iteration: 2227\t Weight1: [9.05785133]\t Weight2: [1.22150336]\t Bias: [2.64058069]\t Cost: 15.438492814907349\n",
            "Iteration: 2228\t Weight1: [9.05788879]\t Weight2: [1.2214424]\t Bias: [2.64053684]\t Cost: 15.438492463237546\n",
            "Iteration: 2229\t Weight1: [9.05792615]\t Weight2: [1.22138159]\t Bias: [2.64049311]\t Cost: 15.438492113406799\n",
            "Iteration: 2230\t Weight1: [9.05796342]\t Weight2: [1.22132094]\t Bias: [2.6404495]\t Cost: 15.438491765405486\n",
            "Iteration: 2231\t Weight1: [9.0580006]\t Weight2: [1.22126044]\t Bias: [2.64040602]\t Cost: 15.438491419223986\n",
            "Iteration: 2232\t Weight1: [9.05803768]\t Weight2: [1.22120009]\t Bias: [2.64036267]\t Cost: 15.438491074852758\n",
            "Iteration: 2233\t Weight1: [9.05807466]\t Weight2: [1.2211399]\t Bias: [2.64031943]\t Cost: 15.438490732282327\n",
            "Iteration: 2234\t Weight1: [9.05811155]\t Weight2: [1.22107985]\t Bias: [2.64027632]\t Cost: 15.438490391503244\n",
            "Iteration: 2235\t Weight1: [9.05814834]\t Weight2: [1.22101996]\t Bias: [2.64023334]\t Cost: 15.438490052506086\n",
            "Iteration: 2236\t Weight1: [9.05818504]\t Weight2: [1.22096021]\t Bias: [2.64019047]\t Cost: 15.438489715281518\n",
            "Iteration: 2237\t Weight1: [9.05822164]\t Weight2: [1.22090062]\t Bias: [2.64014773]\t Cost: 15.43848937982027\n",
            "Iteration: 2238\t Weight1: [9.05825815]\t Weight2: [1.22084118]\t Bias: [2.64010511]\t Cost: 15.438489046113059\n",
            "Iteration: 2239\t Weight1: [9.05829456]\t Weight2: [1.22078188]\t Bias: [2.64006261]\t Cost: 15.4384887141507\n",
            "Iteration: 2240\t Weight1: [9.05833089]\t Weight2: [1.22072274]\t Bias: [2.64002023]\t Cost: 15.438488383924055\n",
            "Iteration: 2241\t Weight1: [9.05836711]\t Weight2: [1.22066374]\t Bias: [2.63997798]\t Cost: 15.438488055424004\n",
            "Iteration: 2242\t Weight1: [9.05840325]\t Weight2: [1.2206049]\t Bias: [2.63993584]\t Cost: 15.438487728641496\n",
            "Iteration: 2243\t Weight1: [9.05843929]\t Weight2: [1.2205462]\t Bias: [2.63989382]\t Cost: 15.43848740356753\n",
            "Iteration: 2244\t Weight1: [9.05847524]\t Weight2: [1.22048765]\t Bias: [2.63985193]\t Cost: 15.438487080193132\n",
            "Iteration: 2245\t Weight1: [9.05851109]\t Weight2: [1.22042924]\t Bias: [2.63981015]\t Cost: 15.438486758509404\n",
            "Iteration: 2246\t Weight1: [9.05854686]\t Weight2: [1.22037098]\t Bias: [2.63976849]\t Cost: 15.43848643850749\n",
            "Iteration: 2247\t Weight1: [9.05858253]\t Weight2: [1.22031287]\t Bias: [2.63972695]\t Cost: 15.438486120178547\n",
            "Iteration: 2248\t Weight1: [9.05861811]\t Weight2: [1.22025491]\t Bias: [2.63968553]\t Cost: 15.43848580351381\n",
            "Iteration: 2249\t Weight1: [9.0586536]\t Weight2: [1.22019709]\t Bias: [2.63964423]\t Cost: 15.438485488504575\n",
            "Iteration: 2250\t Weight1: [9.05868899]\t Weight2: [1.22013941]\t Bias: [2.63960304]\t Cost: 15.438485175142127\n",
            "Iteration: 2251\t Weight1: [9.0587243]\t Weight2: [1.22008189]\t Bias: [2.63956197]\t Cost: 15.438484863417862\n",
            "Iteration: 2252\t Weight1: [9.05875951]\t Weight2: [1.2200245]\t Bias: [2.63952102]\t Cost: 15.438484553323166\n",
            "Iteration: 2253\t Weight1: [9.05879464]\t Weight2: [1.21996726]\t Bias: [2.63948018]\t Cost: 15.438484244849505\n",
            "Iteration: 2254\t Weight1: [9.05882967]\t Weight2: [1.21991017]\t Bias: [2.63943947]\t Cost: 15.438483937988394\n",
            "Iteration: 2255\t Weight1: [9.05886461]\t Weight2: [1.21985321]\t Bias: [2.63939886]\t Cost: 15.43848363273137\n",
            "Iteration: 2256\t Weight1: [9.05889947]\t Weight2: [1.21979641]\t Bias: [2.63935837]\t Cost: 15.438483329070019\n",
            "Iteration: 2257\t Weight1: [9.05893423]\t Weight2: [1.21973974]\t Bias: [2.639318]\t Cost: 15.438483026995975\n",
            "Iteration: 2258\t Weight1: [9.0589689]\t Weight2: [1.21968322]\t Bias: [2.63927774]\t Cost: 15.43848272650093\n",
            "Iteration: 2259\t Weight1: [9.05900349]\t Weight2: [1.21962684]\t Bias: [2.6392376]\t Cost: 15.43848242757659\n",
            "Iteration: 2260\t Weight1: [9.05903798]\t Weight2: [1.2195706]\t Bias: [2.63919757]\t Cost: 15.438482130214737\n",
            "Iteration: 2261\t Weight1: [9.05907239]\t Weight2: [1.2195145]\t Bias: [2.63915766]\t Cost: 15.438481834407158\n",
            "Iteration: 2262\t Weight1: [9.05910671]\t Weight2: [1.21945855]\t Bias: [2.63911786]\t Cost: 15.438481540145721\n",
            "Iteration: 2263\t Weight1: [9.05914094]\t Weight2: [1.21940273]\t Bias: [2.63907817]\t Cost: 15.43848124742233\n",
            "Iteration: 2264\t Weight1: [9.05917508]\t Weight2: [1.21934706]\t Bias: [2.63903859]\t Cost: 15.438480956228915\n",
            "Iteration: 2265\t Weight1: [9.05920913]\t Weight2: [1.21929152]\t Bias: [2.63899913]\t Cost: 15.438480666557451\n",
            "Iteration: 2266\t Weight1: [9.0592431]\t Weight2: [1.21923613]\t Bias: [2.63895978]\t Cost: 15.438480378399968\n",
            "Iteration: 2267\t Weight1: [9.05927697]\t Weight2: [1.21918087]\t Bias: [2.63892054]\t Cost: 15.438480091748538\n",
            "Iteration: 2268\t Weight1: [9.05931077]\t Weight2: [1.21912576]\t Bias: [2.63888141]\t Cost: 15.43847980659525\n",
            "Iteration: 2269\t Weight1: [9.05934447]\t Weight2: [1.21907078]\t Bias: [2.6388424]\t Cost: 15.438479522932253\n",
            "Iteration: 2270\t Weight1: [9.05937809]\t Weight2: [1.21901594]\t Bias: [2.63880349]\t Cost: 15.438479240751766\n",
            "Iteration: 2271\t Weight1: [9.05941162]\t Weight2: [1.21896124]\t Bias: [2.6387647]\t Cost: 15.438478960045975\n",
            "Iteration: 2272\t Weight1: [9.05944506]\t Weight2: [1.21890668]\t Bias: [2.63872601]\t Cost: 15.4384786808072\n",
            "Iteration: 2273\t Weight1: [9.05947842]\t Weight2: [1.21885225]\t Bias: [2.63868744]\t Cost: 15.43847840302771\n",
            "Iteration: 2274\t Weight1: [9.05951169]\t Weight2: [1.21879796]\t Bias: [2.63864897]\t Cost: 15.438478126699879\n",
            "Iteration: 2275\t Weight1: [9.05954488]\t Weight2: [1.21874381]\t Bias: [2.63861062]\t Cost: 15.438477851816092\n",
            "Iteration: 2276\t Weight1: [9.05957798]\t Weight2: [1.2186898]\t Bias: [2.63857237]\t Cost: 15.438477578368811\n",
            "Iteration: 2277\t Weight1: [9.05961099]\t Weight2: [1.21863592]\t Bias: [2.63853423]\t Cost: 15.43847730635047\n",
            "Iteration: 2278\t Weight1: [9.05964392]\t Weight2: [1.21858217]\t Bias: [2.6384962]\t Cost: 15.438477035753579\n",
            "Iteration: 2279\t Weight1: [9.05967677]\t Weight2: [1.21852857]\t Bias: [2.63845828]\t Cost: 15.438476766570732\n",
            "Iteration: 2280\t Weight1: [9.05970953]\t Weight2: [1.21847509]\t Bias: [2.63842046]\t Cost: 15.438476498794486\n",
            "Iteration: 2281\t Weight1: [9.0597422]\t Weight2: [1.21842176]\t Bias: [2.63838276]\t Cost: 15.438476232417472\n",
            "Iteration: 2282\t Weight1: [9.0597748]\t Weight2: [1.21836855]\t Bias: [2.63834516]\t Cost: 15.43847596743237\n",
            "Iteration: 2283\t Weight1: [9.05980731]\t Weight2: [1.21831548]\t Bias: [2.63830766]\t Cost: 15.438475703831894\n",
            "Iteration: 2284\t Weight1: [9.05983973]\t Weight2: [1.21826255]\t Bias: [2.63827028]\t Cost: 15.43847544160877\n",
            "Iteration: 2285\t Weight1: [9.05987207]\t Weight2: [1.21820974]\t Bias: [2.638233]\t Cost: 15.438475180755788\n",
            "Iteration: 2286\t Weight1: [9.05990433]\t Weight2: [1.21815707]\t Bias: [2.63819582]\t Cost: 15.438474921265785\n",
            "Iteration: 2287\t Weight1: [9.0599365]\t Weight2: [1.21810454]\t Bias: [2.63815875]\t Cost: 15.438474663131599\n",
            "Iteration: 2288\t Weight1: [9.05996859]\t Weight2: [1.21805213]\t Bias: [2.63812179]\t Cost: 15.438474406346135\n",
            "Iteration: 2289\t Weight1: [9.0600006]\t Weight2: [1.21799986]\t Bias: [2.63808493]\t Cost: 15.43847415090234\n",
            "Iteration: 2290\t Weight1: [9.06003253]\t Weight2: [1.21794772]\t Bias: [2.63804817]\t Cost: 15.438473896793171\n",
            "Iteration: 2291\t Weight1: [9.06006437]\t Weight2: [1.21789571]\t Bias: [2.63801152]\t Cost: 15.438473644011632\n",
            "Iteration: 2292\t Weight1: [9.06009613]\t Weight2: [1.21784383]\t Bias: [2.63797498]\t Cost: 15.438473392550776\n",
            "Iteration: 2293\t Weight1: [9.06012781]\t Weight2: [1.21779209]\t Bias: [2.63793853]\t Cost: 15.438473142403694\n",
            "Iteration: 2294\t Weight1: [9.06015941]\t Weight2: [1.21774047]\t Bias: [2.63790219]\t Cost: 15.438472893563494\n",
            "Iteration: 2295\t Weight1: [9.06019093]\t Weight2: [1.21768898]\t Bias: [2.63786596]\t Cost: 15.438472646023332\n",
            "Iteration: 2296\t Weight1: [9.06022237]\t Weight2: [1.21763763]\t Bias: [2.63782982]\t Cost: 15.438472399776398\n",
            "Iteration: 2297\t Weight1: [9.06025372]\t Weight2: [1.2175864]\t Bias: [2.63779379]\t Cost: 15.438472154815923\n",
            "Iteration: 2298\t Weight1: [9.06028499]\t Weight2: [1.2175353]\t Bias: [2.63775786]\t Cost: 15.43847191113516\n",
            "Iteration: 2299\t Weight1: [9.06031619]\t Weight2: [1.21748433]\t Bias: [2.63772204]\t Cost: 15.438471668727404\n",
            "Iteration: 2300\t Weight1: [9.0603473]\t Weight2: [1.21743349]\t Bias: [2.63768631]\t Cost: 15.438471427585995\n",
            "Iteration: 2301\t Weight1: [9.06037833]\t Weight2: [1.21738278]\t Bias: [2.63765068]\t Cost: 15.438471187704312\n",
            "Iteration: 2302\t Weight1: [9.06040929]\t Weight2: [1.21733219]\t Bias: [2.63761516]\t Cost: 15.438470949075747\n",
            "Iteration: 2303\t Weight1: [9.06044016]\t Weight2: [1.21728174]\t Bias: [2.63757974]\t Cost: 15.43847071169372\n",
            "Iteration: 2304\t Weight1: [9.06047095]\t Weight2: [1.21723141]\t Bias: [2.63754442]\t Cost: 15.438470475551721\n",
            "Iteration: 2305\t Weight1: [9.06050167]\t Weight2: [1.2171812]\t Bias: [2.63750919]\t Cost: 15.438470240643264\n",
            "Iteration: 2306\t Weight1: [9.0605323]\t Weight2: [1.21713113]\t Bias: [2.63747407]\t Cost: 15.438470006961868\n",
            "Iteration: 2307\t Weight1: [9.06056286]\t Weight2: [1.21708118]\t Bias: [2.63743905]\t Cost: 15.43846977450113\n",
            "Iteration: 2308\t Weight1: [9.06059334]\t Weight2: [1.21703135]\t Bias: [2.63740412]\t Cost: 15.438469543254644\n",
            "Iteration: 2309\t Weight1: [9.06062373]\t Weight2: [1.21698166]\t Bias: [2.6373693]\t Cost: 15.438469313216036\n",
            "Iteration: 2310\t Weight1: [9.06065405]\t Weight2: [1.21693208]\t Bias: [2.63733457]\t Cost: 15.438469084379014\n",
            "Iteration: 2311\t Weight1: [9.0606843]\t Weight2: [1.21688263]\t Bias: [2.63729994]\t Cost: 15.438468856737257\n",
            "Iteration: 2312\t Weight1: [9.06071446]\t Weight2: [1.21683331]\t Bias: [2.63726541]\t Cost: 15.43846863028453\n",
            "Iteration: 2313\t Weight1: [9.06074455]\t Weight2: [1.21678411]\t Bias: [2.63723098]\t Cost: 15.438468405014593\n",
            "Iteration: 2314\t Weight1: [9.06077456]\t Weight2: [1.21673504]\t Bias: [2.63719664]\t Cost: 15.438468180921252\n",
            "Iteration: 2315\t Weight1: [9.06080449]\t Weight2: [1.21668609]\t Bias: [2.6371624]\t Cost: 15.438467957998345\n",
            "Iteration: 2316\t Weight1: [9.06083434]\t Weight2: [1.21663726]\t Bias: [2.63712826]\t Cost: 15.438467736239767\n",
            "Iteration: 2317\t Weight1: [9.06086412]\t Weight2: [1.21658856]\t Bias: [2.63709422]\t Cost: 15.438467515639394\n",
            "Iteration: 2318\t Weight1: [9.06089382]\t Weight2: [1.21653998]\t Bias: [2.63706027]\t Cost: 15.438467296191181\n",
            "Iteration: 2319\t Weight1: [9.06092344]\t Weight2: [1.21649152]\t Bias: [2.63702642]\t Cost: 15.438467077889067\n",
            "Iteration: 2320\t Weight1: [9.06095299]\t Weight2: [1.21644318]\t Bias: [2.63699266]\t Cost: 15.438466860727074\n",
            "Iteration: 2321\t Weight1: [9.06098246]\t Weight2: [1.21639497]\t Bias: [2.636959]\t Cost: 15.438466644699245\n",
            "Iteration: 2322\t Weight1: [9.06101186]\t Weight2: [1.21634688]\t Bias: [2.63692544]\t Cost: 15.438466429799623\n",
            "Iteration: 2323\t Weight1: [9.06104118]\t Weight2: [1.21629891]\t Bias: [2.63689196]\t Cost: 15.438466216022304\n",
            "Iteration: 2324\t Weight1: [9.06107042]\t Weight2: [1.21625106]\t Bias: [2.63685859]\t Cost: 15.43846600336141\n",
            "Iteration: 2325\t Weight1: [9.06109959]\t Weight2: [1.21620333]\t Bias: [2.63682531]\t Cost: 15.438465791811103\n",
            "Iteration: 2326\t Weight1: [9.06112868]\t Weight2: [1.21615572]\t Bias: [2.63679212]\t Cost: 15.43846558136558\n",
            "Iteration: 2327\t Weight1: [9.0611577]\t Weight2: [1.21610823]\t Bias: [2.63675903]\t Cost: 15.438465372019047\n",
            "Iteration: 2328\t Weight1: [9.06118665]\t Weight2: [1.21606086]\t Bias: [2.63672602]\t Cost: 15.438465163765713\n",
            "Iteration: 2329\t Weight1: [9.06121552]\t Weight2: [1.21601361]\t Bias: [2.63669312]\t Cost: 15.438464956599919\n",
            "Iteration: 2330\t Weight1: [9.06124431]\t Weight2: [1.21596648]\t Bias: [2.6366603]\t Cost: 15.438464750515957\n",
            "Iteration: 2331\t Weight1: [9.06127303]\t Weight2: [1.21591947]\t Bias: [2.63662758]\t Cost: 15.438464545508142\n",
            "Iteration: 2332\t Weight1: [9.06130168]\t Weight2: [1.21587258]\t Bias: [2.63659495]\t Cost: 15.438464341570842\n",
            "Iteration: 2333\t Weight1: [9.06133025]\t Weight2: [1.21582581]\t Bias: [2.63656242]\t Cost: 15.438464138698471\n",
            "Iteration: 2334\t Weight1: [9.06135875]\t Weight2: [1.21577915]\t Bias: [2.63652997]\t Cost: 15.438463936885448\n",
            "Iteration: 2335\t Weight1: [9.06138717]\t Weight2: [1.21573262]\t Bias: [2.63649762]\t Cost: 15.438463736126227\n",
            "Iteration: 2336\t Weight1: [9.06141553]\t Weight2: [1.2156862]\t Bias: [2.63646536]\t Cost: 15.43846353641529\n",
            "Iteration: 2337\t Weight1: [9.06144381]\t Weight2: [1.21563989]\t Bias: [2.63643319]\t Cost: 15.438463337747152\n",
            "Iteration: 2338\t Weight1: [9.06147201]\t Weight2: [1.21559371]\t Bias: [2.63640111]\t Cost: 15.438463140116369\n",
            "Iteration: 2339\t Weight1: [9.06150014]\t Weight2: [1.21554764]\t Bias: [2.63636912]\t Cost: 15.438462943517484\n",
            "Iteration: 2340\t Weight1: [9.06152821]\t Weight2: [1.21550169]\t Bias: [2.63633722]\t Cost: 15.438462747945122\n",
            "Iteration: 2341\t Weight1: [9.06155619]\t Weight2: [1.21545585]\t Bias: [2.63630541]\t Cost: 15.438462553393899\n",
            "Iteration: 2342\t Weight1: [9.06158411]\t Weight2: [1.21541013]\t Bias: [2.63627369]\t Cost: 15.43846235985848\n",
            "Iteration: 2343\t Weight1: [9.06161195]\t Weight2: [1.21536452]\t Bias: [2.63624206]\t Cost: 15.438462167333542\n",
            "Iteration: 2344\t Weight1: [9.06163973]\t Weight2: [1.21531903]\t Bias: [2.63621052]\t Cost: 15.438461975813803\n",
            "Iteration: 2345\t Weight1: [9.06166743]\t Weight2: [1.21527366]\t Bias: [2.63617907]\t Cost: 15.438461785293962\n",
            "Iteration: 2346\t Weight1: [9.06169506]\t Weight2: [1.2152284]\t Bias: [2.63614771]\t Cost: 15.43846159576886\n",
            "Iteration: 2347\t Weight1: [9.06172261]\t Weight2: [1.21518325]\t Bias: [2.63611644]\t Cost: 15.438461407233238\n",
            "Iteration: 2348\t Weight1: [9.0617501]\t Weight2: [1.21513822]\t Bias: [2.63608525]\t Cost: 15.438461219681924\n",
            "Iteration: 2349\t Weight1: [9.06177752]\t Weight2: [1.2150933]\t Bias: [2.63605415]\t Cost: 15.438461033109801\n",
            "Iteration: 2350\t Weight1: [9.06180486]\t Weight2: [1.2150485]\t Bias: [2.63602314]\t Cost: 15.438460847511701\n",
            "Iteration: 2351\t Weight1: [9.06183214]\t Weight2: [1.21500381]\t Bias: [2.63599222]\t Cost: 15.438460662882557\n",
            "Iteration: 2352\t Weight1: [9.06185934]\t Weight2: [1.21495923]\t Bias: [2.63596139]\t Cost: 15.438460479217307\n",
            "Iteration: 2353\t Weight1: [9.06188648]\t Weight2: [1.21491476]\t Bias: [2.63593064]\t Cost: 15.438460296510858\n",
            "Iteration: 2354\t Weight1: [9.06191354]\t Weight2: [1.21487041]\t Bias: [2.63589998]\t Cost: 15.438460114758247\n",
            "Iteration: 2355\t Weight1: [9.06194054]\t Weight2: [1.21482617]\t Bias: [2.6358694]\t Cost: 15.438459933954444\n",
            "Iteration: 2356\t Weight1: [9.06196746]\t Weight2: [1.21478204]\t Bias: [2.63583891]\t Cost: 15.438459754094522\n",
            "Iteration: 2357\t Weight1: [9.06199432]\t Weight2: [1.21473802]\t Bias: [2.63580851]\t Cost: 15.43845957517351\n",
            "Iteration: 2358\t Weight1: [9.0620211]\t Weight2: [1.21469412]\t Bias: [2.6357782]\t Cost: 15.438459397186527\n",
            "Iteration: 2359\t Weight1: [9.06204782]\t Weight2: [1.21465032]\t Bias: [2.63574796]\t Cost: 15.43845922012864\n",
            "Iteration: 2360\t Weight1: [9.06207447]\t Weight2: [1.21460663]\t Bias: [2.63571782]\t Cost: 15.438459043995039\n",
            "Iteration: 2361\t Weight1: [9.06210105]\t Weight2: [1.21456306]\t Bias: [2.63568776]\t Cost: 15.438458868780877\n",
            "Iteration: 2362\t Weight1: [9.06212756]\t Weight2: [1.2145196]\t Bias: [2.63565778]\t Cost: 15.438458694481312\n",
            "Iteration: 2363\t Weight1: [9.062154]\t Weight2: [1.21447624]\t Bias: [2.63562789]\t Cost: 15.43845852109159\n",
            "Iteration: 2364\t Weight1: [9.06218038]\t Weight2: [1.214433]\t Bias: [2.63559808]\t Cost: 15.43845834860694\n",
            "Iteration: 2365\t Weight1: [9.06220668]\t Weight2: [1.21438986]\t Bias: [2.63556836]\t Cost: 15.438458177022634\n",
            "Iteration: 2366\t Weight1: [9.06223292]\t Weight2: [1.21434684]\t Bias: [2.63553872]\t Cost: 15.438458006333953\n",
            "Iteration: 2367\t Weight1: [9.06225909]\t Weight2: [1.21430392]\t Bias: [2.63550916]\t Cost: 15.438457836536212\n",
            "Iteration: 2368\t Weight1: [9.0622852]\t Weight2: [1.21426111]\t Bias: [2.63547969]\t Cost: 15.438457667624768\n",
            "Iteration: 2369\t Weight1: [9.06231123]\t Weight2: [1.21421841]\t Bias: [2.6354503]\t Cost: 15.43845749959496\n",
            "Iteration: 2370\t Weight1: [9.0623372]\t Weight2: [1.21417582]\t Bias: [2.63542099]\t Cost: 15.438457332442194\n",
            "Iteration: 2371\t Weight1: [9.0623631]\t Weight2: [1.21413333]\t Bias: [2.63539176]\t Cost: 15.438457166161891\n",
            "Iteration: 2372\t Weight1: [9.06238894]\t Weight2: [1.21409096]\t Bias: [2.63536262]\t Cost: 15.43845700074945\n",
            "Iteration: 2373\t Weight1: [9.06241471]\t Weight2: [1.21404868]\t Bias: [2.63533356]\t Cost: 15.438456836200372\n",
            "Iteration: 2374\t Weight1: [9.06244041]\t Weight2: [1.21400652]\t Bias: [2.63530458]\t Cost: 15.438456672510123\n",
            "Iteration: 2375\t Weight1: [9.06246604]\t Weight2: [1.21396447]\t Bias: [2.63527569]\t Cost: 15.4384565096742\n",
            "Iteration: 2376\t Weight1: [9.06249161]\t Weight2: [1.21392252]\t Bias: [2.63524687]\t Cost: 15.43845634768816\n",
            "Iteration: 2377\t Weight1: [9.06251712]\t Weight2: [1.21388067]\t Bias: [2.63521814]\t Cost: 15.438456186547533\n",
            "Iteration: 2378\t Weight1: [9.06254255]\t Weight2: [1.21383893]\t Bias: [2.63518948]\t Cost: 15.438456026247918\n",
            "Iteration: 2379\t Weight1: [9.06256793]\t Weight2: [1.2137973]\t Bias: [2.63516091]\t Cost: 15.438455866784917\n",
            "Iteration: 2380\t Weight1: [9.06259323]\t Weight2: [1.21375577]\t Bias: [2.63513242]\t Cost: 15.43845570815413\n",
            "Iteration: 2381\t Weight1: [9.06261847]\t Weight2: [1.21371435]\t Bias: [2.635104]\t Cost: 15.43845555035122\n",
            "Iteration: 2382\t Weight1: [9.06264365]\t Weight2: [1.21367303]\t Bias: [2.63507567]\t Cost: 15.438455393371868\n",
            "Iteration: 2383\t Weight1: [9.06266876]\t Weight2: [1.21363182]\t Bias: [2.63504742]\t Cost: 15.438455237211748\n",
            "Iteration: 2384\t Weight1: [9.06269381]\t Weight2: [1.21359071]\t Bias: [2.63501924]\t Cost: 15.438455081866602\n",
            "Iteration: 2385\t Weight1: [9.06271879]\t Weight2: [1.21354971]\t Bias: [2.63499115]\t Cost: 15.438454927332135\n",
            "Iteration: 2386\t Weight1: [9.06274371]\t Weight2: [1.21350881]\t Bias: [2.63496314]\t Cost: 15.438454773604121\n",
            "Iteration: 2387\t Weight1: [9.06276856]\t Weight2: [1.21346801]\t Bias: [2.6349352]\t Cost: 15.438454620678355\n",
            "Iteration: 2388\t Weight1: [9.06279335]\t Weight2: [1.21342732]\t Bias: [2.63490734]\t Cost: 15.438454468550626\n",
            "Iteration: 2389\t Weight1: [9.06281808]\t Weight2: [1.21338673]\t Bias: [2.63487956]\t Cost: 15.438454317216772\n",
            "Iteration: 2390\t Weight1: [9.06284274]\t Weight2: [1.21334624]\t Bias: [2.63485186]\t Cost: 15.438454166672628\n",
            "Iteration: 2391\t Weight1: [9.06286733]\t Weight2: [1.21330585]\t Bias: [2.63482424]\t Cost: 15.43845401691408\n",
            "Iteration: 2392\t Weight1: [9.06289187]\t Weight2: [1.21326557]\t Bias: [2.63479669]\t Cost: 15.438453867937008\n",
            "Iteration: 2393\t Weight1: [9.06291634]\t Weight2: [1.21322539]\t Bias: [2.63476922]\t Cost: 15.43845371973735\n",
            "Iteration: 2394\t Weight1: [9.06294075]\t Weight2: [1.21318531]\t Bias: [2.63474183]\t Cost: 15.438453572311003\n",
            "Iteration: 2395\t Weight1: [9.06296509]\t Weight2: [1.21314533]\t Bias: [2.63471452]\t Cost: 15.438453425653957\n",
            "Iteration: 2396\t Weight1: [9.06298937]\t Weight2: [1.21310545]\t Bias: [2.63468728]\t Cost: 15.438453279762156\n",
            "Iteration: 2397\t Weight1: [9.06301359]\t Weight2: [1.21306568]\t Bias: [2.63466012]\t Cost: 15.438453134631636\n",
            "Iteration: 2398\t Weight1: [9.06303775]\t Weight2: [1.213026]\t Bias: [2.63463304]\t Cost: 15.43845299025839\n",
            "Iteration: 2399\t Weight1: [9.06306184]\t Weight2: [1.21298643]\t Bias: [2.63460603]\t Cost: 15.43845284663848\n",
            "Iteration: 2400\t Weight1: [9.06308588]\t Weight2: [1.21294695]\t Bias: [2.63457909]\t Cost: 15.438452703767943\n",
            "Iteration: 2401\t Weight1: [9.06310985]\t Weight2: [1.21290758]\t Bias: [2.63455224]\t Cost: 15.438452561642885\n",
            "Iteration: 2402\t Weight1: [9.06313375]\t Weight2: [1.2128683]\t Bias: [2.63452546]\t Cost: 15.43845242025939\n",
            "Iteration: 2403\t Weight1: [9.0631576]\t Weight2: [1.21282913]\t Bias: [2.63449875]\t Cost: 15.438452279613585\n",
            "Iteration: 2404\t Weight1: [9.06318139]\t Weight2: [1.21279005]\t Bias: [2.63447212]\t Cost: 15.43845213970162\n",
            "Iteration: 2405\t Weight1: [9.06320511]\t Weight2: [1.21275107]\t Bias: [2.63444556]\t Cost: 15.43845200051966\n",
            "Iteration: 2406\t Weight1: [9.06322877]\t Weight2: [1.2127122]\t Bias: [2.63441908]\t Cost: 15.438451862063886\n",
            "Iteration: 2407\t Weight1: [9.06325237]\t Weight2: [1.21267342]\t Bias: [2.63439267]\t Cost: 15.438451724330497\n",
            "Iteration: 2408\t Weight1: [9.06327591]\t Weight2: [1.21263473]\t Bias: [2.63436634]\t Cost: 15.4384515873157\n",
            "Iteration: 2409\t Weight1: [9.06329939]\t Weight2: [1.21259615]\t Bias: [2.63434008]\t Cost: 15.438451451015787\n",
            "Iteration: 2410\t Weight1: [9.06332281]\t Weight2: [1.21255766]\t Bias: [2.63431389]\t Cost: 15.438451315426988\n",
            "Iteration: 2411\t Weight1: [9.06334617]\t Weight2: [1.21251928]\t Bias: [2.63428778]\t Cost: 15.438451180545588\n",
            "Iteration: 2412\t Weight1: [9.06336947]\t Weight2: [1.21248099]\t Bias: [2.63426174]\t Cost: 15.438451046367879\n",
            "Iteration: 2413\t Weight1: [9.06339271]\t Weight2: [1.21244279]\t Bias: [2.63423578]\t Cost: 15.438450912890211\n",
            "Iteration: 2414\t Weight1: [9.06341589]\t Weight2: [1.21240469]\t Bias: [2.63420988]\t Cost: 15.438450780108898\n",
            "Iteration: 2415\t Weight1: [9.06343901]\t Weight2: [1.21236669]\t Bias: [2.63418406]\t Cost: 15.43845064802031\n",
            "Iteration: 2416\t Weight1: [9.06346207]\t Weight2: [1.21232879]\t Bias: [2.63415832]\t Cost: 15.438450516620836\n",
            "Iteration: 2417\t Weight1: [9.06348506]\t Weight2: [1.21229098]\t Bias: [2.63413264]\t Cost: 15.43845038590685\n",
            "Iteration: 2418\t Weight1: [9.063508]\t Weight2: [1.21225327]\t Bias: [2.63410704]\t Cost: 15.438450255874798\n",
            "Iteration: 2419\t Weight1: [9.06353089]\t Weight2: [1.21221565]\t Bias: [2.63408151]\t Cost: 15.4384501265211\n",
            "Iteration: 2420\t Weight1: [9.06355371]\t Weight2: [1.21217813]\t Bias: [2.63405605]\t Cost: 15.438449997842222\n",
            "Iteration: 2421\t Weight1: [9.06357647]\t Weight2: [1.2121407]\t Bias: [2.63403066]\t Cost: 15.438449869834605\n",
            "Iteration: 2422\t Weight1: [9.06359917]\t Weight2: [1.21210337]\t Bias: [2.63400534]\t Cost: 15.43844974249477\n",
            "Iteration: 2423\t Weight1: [9.06362182]\t Weight2: [1.21206613]\t Bias: [2.63398009]\t Cost: 15.438449615819227\n",
            "Iteration: 2424\t Weight1: [9.06364441]\t Weight2: [1.21202899]\t Bias: [2.63395492]\t Cost: 15.438449489804487\n",
            "Iteration: 2425\t Weight1: [9.06366694]\t Weight2: [1.21199194]\t Bias: [2.63392981]\t Cost: 15.438449364447118\n",
            "Iteration: 2426\t Weight1: [9.06368941]\t Weight2: [1.21195498]\t Bias: [2.63390478]\t Cost: 15.438449239743662\n",
            "Iteration: 2427\t Weight1: [9.06371182]\t Weight2: [1.21191812]\t Bias: [2.63387981]\t Cost: 15.438449115690718\n",
            "Iteration: 2428\t Weight1: [9.06373417]\t Weight2: [1.21188136]\t Bias: [2.63385492]\t Cost: 15.438448992284881\n",
            "Iteration: 2429\t Weight1: [9.06375647]\t Weight2: [1.21184468]\t Bias: [2.63383009]\t Cost: 15.43844886952278\n",
            "Iteration: 2430\t Weight1: [9.06377871]\t Weight2: [1.2118081]\t Bias: [2.63380534]\t Cost: 15.438448747401026\n",
            "Iteration: 2431\t Weight1: [9.06380089]\t Weight2: [1.21177161]\t Bias: [2.63378065]\t Cost: 15.438448625916289\n",
            "Iteration: 2432\t Weight1: [9.06382302]\t Weight2: [1.21173521]\t Bias: [2.63375604]\t Cost: 15.438448505065248\n",
            "Iteration: 2433\t Weight1: [9.06384508]\t Weight2: [1.21169891]\t Bias: [2.63373149]\t Cost: 15.438448384844564\n",
            "Iteration: 2434\t Weight1: [9.0638671]\t Weight2: [1.2116627]\t Bias: [2.63370701]\t Cost: 15.43844826525096\n",
            "Iteration: 2435\t Weight1: [9.06388905]\t Weight2: [1.21162658]\t Bias: [2.6336826]\t Cost: 15.438448146281175\n",
            "Iteration: 2436\t Weight1: [9.06391095]\t Weight2: [1.21159055]\t Bias: [2.63365826]\t Cost: 15.438448027931932\n",
            "Iteration: 2437\t Weight1: [9.06393279]\t Weight2: [1.21155461]\t Bias: [2.63363398]\t Cost: 15.438447910199981\n",
            "Iteration: 2438\t Weight1: [9.06395457]\t Weight2: [1.21151877]\t Bias: [2.63360978]\t Cost: 15.43844779308211\n",
            "Iteration: 2439\t Weight1: [9.0639763]\t Weight2: [1.21148301]\t Bias: [2.63358564]\t Cost: 15.438447676575112\n",
            "Iteration: 2440\t Weight1: [9.06399797]\t Weight2: [1.21144735]\t Bias: [2.63356157]\t Cost: 15.438447560675787\n",
            "Iteration: 2441\t Weight1: [9.06401959]\t Weight2: [1.21141177]\t Bias: [2.63353757]\t Cost: 15.43844744538096\n",
            "Iteration: 2442\t Weight1: [9.06404115]\t Weight2: [1.21137629]\t Bias: [2.63351363]\t Cost: 15.438447330687477\n",
            "Iteration: 2443\t Weight1: [9.06406265]\t Weight2: [1.2113409]\t Bias: [2.63348976]\t Cost: 15.438447216592175\n",
            "Iteration: 2444\t Weight1: [9.0640841]\t Weight2: [1.21130559]\t Bias: [2.63346596]\t Cost: 15.43844710309197\n",
            "Iteration: 2445\t Weight1: [9.0641055]\t Weight2: [1.21127038]\t Bias: [2.63344222]\t Cost: 15.438446990183712\n",
            "Iteration: 2446\t Weight1: [9.06412683]\t Weight2: [1.21123525]\t Bias: [2.63341855]\t Cost: 15.438446877864346\n",
            "Iteration: 2447\t Weight1: [9.06414812]\t Weight2: [1.21120022]\t Bias: [2.63339495]\t Cost: 15.438446766130768\n",
            "Iteration: 2448\t Weight1: [9.06416935]\t Weight2: [1.21116527]\t Bias: [2.63337141]\t Cost: 15.438446654979924\n",
            "Iteration: 2449\t Weight1: [9.06419052]\t Weight2: [1.21113041]\t Bias: [2.63334794]\t Cost: 15.438446544408778\n",
            "Iteration: 2450\t Weight1: [9.06421164]\t Weight2: [1.21109564]\t Bias: [2.63332454]\t Cost: 15.438446434414278\n",
            "Iteration: 2451\t Weight1: [9.0642327]\t Weight2: [1.21106096]\t Bias: [2.6333012]\t Cost: 15.438446324993441\n",
            "Iteration: 2452\t Weight1: [9.06425371]\t Weight2: [1.21102636]\t Bias: [2.63327792]\t Cost: 15.438446216143237\n",
            "Iteration: 2453\t Weight1: [9.06427467]\t Weight2: [1.21099186]\t Bias: [2.63325472]\t Cost: 15.43844610786072\n",
            "Iteration: 2454\t Weight1: [9.06429557]\t Weight2: [1.21095744]\t Bias: [2.63323157]\t Cost: 15.438446000142918\n",
            "Iteration: 2455\t Weight1: [9.06431642]\t Weight2: [1.21092311]\t Bias: [2.63320849]\t Cost: 15.438445892986847\n",
            "Iteration: 2456\t Weight1: [9.06433721]\t Weight2: [1.21088886]\t Bias: [2.63318548]\t Cost: 15.438445786389613\n",
            "Iteration: 2457\t Weight1: [9.06435795]\t Weight2: [1.21085471]\t Bias: [2.63316253]\t Cost: 15.438445680348288\n",
            "Iteration: 2458\t Weight1: [9.06437864]\t Weight2: [1.21082064]\t Bias: [2.63313964]\t Cost: 15.438445574859937\n",
            "Iteration: 2459\t Weight1: [9.06439927]\t Weight2: [1.21078665]\t Bias: [2.63311682]\t Cost: 15.438445469921712\n",
            "Iteration: 2460\t Weight1: [9.06441985]\t Weight2: [1.21075275]\t Bias: [2.63309406]\t Cost: 15.438445365530718\n",
            "Iteration: 2461\t Weight1: [9.06444038]\t Weight2: [1.21071894]\t Bias: [2.63307136]\t Cost: 15.438445261684107\n",
            "Iteration: 2462\t Weight1: [9.06446085]\t Weight2: [1.21068522]\t Bias: [2.63304873]\t Cost: 15.438445158379015\n",
            "Iteration: 2463\t Weight1: [9.06448127]\t Weight2: [1.21065158]\t Bias: [2.63302616]\t Cost: 15.438445055612647\n",
            "Iteration: 2464\t Weight1: [9.06450164]\t Weight2: [1.21061802]\t Bias: [2.63300366]\t Cost: 15.43844495338215\n",
            "Iteration: 2465\t Weight1: [9.06452196]\t Weight2: [1.21058455]\t Bias: [2.63298122]\t Cost: 15.438444851684757\n",
            "Iteration: 2466\t Weight1: [9.06454222]\t Weight2: [1.21055117]\t Bias: [2.63295884]\t Cost: 15.438444750517677\n",
            "Iteration: 2467\t Weight1: [9.06456243]\t Weight2: [1.21051787]\t Bias: [2.63293652]\t Cost: 15.438444649878118\n",
            "Iteration: 2468\t Weight1: [9.06458259]\t Weight2: [1.21048465]\t Bias: [2.63291426]\t Cost: 15.438444549763343\n",
            "Iteration: 2469\t Weight1: [9.0646027]\t Weight2: [1.21045152]\t Bias: [2.63289207]\t Cost: 15.438444450170607\n",
            "Iteration: 2470\t Weight1: [9.06462275]\t Weight2: [1.21041847]\t Bias: [2.63286994]\t Cost: 15.438444351097196\n",
            "Iteration: 2471\t Weight1: [9.06464275]\t Weight2: [1.21038551]\t Bias: [2.63284787]\t Cost: 15.438444252540375\n",
            "Iteration: 2472\t Weight1: [9.0646627]\t Weight2: [1.21035263]\t Bias: [2.63282586]\t Cost: 15.43844415449747\n",
            "Iteration: 2473\t Weight1: [9.0646826]\t Weight2: [1.21031984]\t Bias: [2.63280392]\t Cost: 15.438444056965777\n",
            "Iteration: 2474\t Weight1: [9.06470245]\t Weight2: [1.21028712]\t Bias: [2.63278203]\t Cost: 15.438443959942633\n",
            "Iteration: 2475\t Weight1: [9.06472225]\t Weight2: [1.21025449]\t Bias: [2.63276021]\t Cost: 15.438443863425393\n",
            "Iteration: 2476\t Weight1: [9.06474199]\t Weight2: [1.21022195]\t Bias: [2.63273845]\t Cost: 15.438443767411394\n",
            "Iteration: 2477\t Weight1: [9.06476169]\t Weight2: [1.21018948]\t Bias: [2.63271675]\t Cost: 15.438443671898025\n",
            "Iteration: 2478\t Weight1: [9.06478133]\t Weight2: [1.2101571]\t Bias: [2.63269511]\t Cost: 15.438443576882651\n",
            "Iteration: 2479\t Weight1: [9.06480093]\t Weight2: [1.2101248]\t Bias: [2.63267353]\t Cost: 15.438443482362691\n",
            "Iteration: 2480\t Weight1: [9.06482047]\t Weight2: [1.21009258]\t Bias: [2.632652]\t Cost: 15.438443388335559\n",
            "Iteration: 2481\t Weight1: [9.06483996]\t Weight2: [1.21006045]\t Bias: [2.63263054]\t Cost: 15.438443294798672\n",
            "Iteration: 2482\t Weight1: [9.0648594]\t Weight2: [1.21002839]\t Bias: [2.63260914]\t Cost: 15.438443201749463\n",
            "Iteration: 2483\t Weight1: [9.0648788]\t Weight2: [1.20999642]\t Bias: [2.6325878]\t Cost: 15.438443109185403\n",
            "Iteration: 2484\t Weight1: [9.06489814]\t Weight2: [1.20996453]\t Bias: [2.63256652]\t Cost: 15.438443017103952\n",
            "Iteration: 2485\t Weight1: [9.06491743]\t Weight2: [1.20993272]\t Bias: [2.6325453]\t Cost: 15.438442925502585\n",
            "Iteration: 2486\t Weight1: [9.06493667]\t Weight2: [1.20990099]\t Bias: [2.63252414]\t Cost: 15.438442834378794\n",
            "Iteration: 2487\t Weight1: [9.06495586]\t Weight2: [1.20986934]\t Bias: [2.63250303]\t Cost: 15.438442743730079\n",
            "Iteration: 2488\t Weight1: [9.064975]\t Weight2: [1.20983777]\t Bias: [2.63248199]\t Cost: 15.438442653553986\n",
            "Iteration: 2489\t Weight1: [9.0649941]\t Weight2: [1.20980629]\t Bias: [2.632461]\t Cost: 15.438442563848028\n",
            "Iteration: 2490\t Weight1: [9.06501314]\t Weight2: [1.20977488]\t Bias: [2.63244008]\t Cost: 15.438442474609746\n",
            "Iteration: 2491\t Weight1: [9.06503214]\t Weight2: [1.20974355]\t Bias: [2.63241921]\t Cost: 15.438442385836698\n",
            "Iteration: 2492\t Weight1: [9.06505108]\t Weight2: [1.2097123]\t Bias: [2.6323984]\t Cost: 15.438442297526475\n",
            "Iteration: 2493\t Weight1: [9.06506998]\t Weight2: [1.20968113]\t Bias: [2.63237764]\t Cost: 15.438442209676627\n",
            "Iteration: 2494\t Weight1: [9.06508883]\t Weight2: [1.20965004]\t Bias: [2.63235695]\t Cost: 15.43844212228479\n",
            "Iteration: 2495\t Weight1: [9.06510762]\t Weight2: [1.20961903]\t Bias: [2.63233631]\t Cost: 15.438442035348533\n",
            "Iteration: 2496\t Weight1: [9.06512638]\t Weight2: [1.2095881]\t Bias: [2.63231573]\t Cost: 15.438441948865512\n",
            "Iteration: 2497\t Weight1: [9.06514508]\t Weight2: [1.20955724]\t Bias: [2.63229521]\t Cost: 15.438441862833338\n",
            "Iteration: 2498\t Weight1: [9.06516373]\t Weight2: [1.20952647]\t Bias: [2.63227475]\t Cost: 15.438441777249679\n",
            "Iteration: 2499\t Weight1: [9.06518234]\t Weight2: [1.20949577]\t Bias: [2.63225434]\t Cost: 15.438441692112148\n",
            "Iteration: 2500\t Weight1: [9.06520089]\t Weight2: [1.20946515]\t Bias: [2.63223399]\t Cost: 15.438441607418456\n",
            "Iteration: 2501\t Weight1: [9.0652194]\t Weight2: [1.20943461]\t Bias: [2.63221369]\t Cost: 15.43844152316629\n",
            "Iteration: 2502\t Weight1: [9.06523787]\t Weight2: [1.20940415]\t Bias: [2.63219345]\t Cost: 15.438441439353321\n",
            "Iteration: 2503\t Weight1: [9.06525628]\t Weight2: [1.20937376]\t Bias: [2.63217327]\t Cost: 15.438441355977256\n",
            "Iteration: 2504\t Weight1: [9.06527465]\t Weight2: [1.20934345]\t Bias: [2.63215315]\t Cost: 15.438441273035828\n",
            "Iteration: 2505\t Weight1: [9.06529296]\t Weight2: [1.20931322]\t Bias: [2.63213308]\t Cost: 15.438441190526772\n",
            "Iteration: 2506\t Weight1: [9.06531124]\t Weight2: [1.20928306]\t Bias: [2.63211306]\t Cost: 15.438441108447819\n",
            "Iteration: 2507\t Weight1: [9.06532946]\t Weight2: [1.20925298]\t Bias: [2.63209311]\t Cost: 15.438441026796722\n",
            "Iteration: 2508\t Weight1: [9.06534764]\t Weight2: [1.20922298]\t Bias: [2.63207321]\t Cost: 15.438440945571251\n",
            "Iteration: 2509\t Weight1: [9.06536577]\t Weight2: [1.20919306]\t Bias: [2.63205336]\t Cost: 15.438440864769186\n",
            "Iteration: 2510\t Weight1: [9.06538385]\t Weight2: [1.20916321]\t Bias: [2.63203357]\t Cost: 15.438440784388309\n",
            "Iteration: 2511\t Weight1: [9.06540189]\t Weight2: [1.20913343]\t Bias: [2.63201383]\t Cost: 15.438440704426453\n",
            "Iteration: 2512\t Weight1: [9.06541988]\t Weight2: [1.20910373]\t Bias: [2.63199415]\t Cost: 15.438440624881377\n",
            "Iteration: 2513\t Weight1: [9.06543782]\t Weight2: [1.20907411]\t Bias: [2.63197452]\t Cost: 15.438440545750945\n",
            "Iteration: 2514\t Weight1: [9.06545572]\t Weight2: [1.20904456]\t Bias: [2.63195495]\t Cost: 15.438440467032974\n",
            "Iteration: 2515\t Weight1: [9.06547357]\t Weight2: [1.20901509]\t Bias: [2.63193544]\t Cost: 15.438440388725327\n",
            "Iteration: 2516\t Weight1: [9.06549138]\t Weight2: [1.20898569]\t Bias: [2.63191597]\t Cost: 15.438440310825836\n",
            "Iteration: 2517\t Weight1: [9.06550914]\t Weight2: [1.20895637]\t Bias: [2.63189656]\t Cost: 15.4384402333324\n",
            "Iteration: 2518\t Weight1: [9.06552685]\t Weight2: [1.20892712]\t Bias: [2.63187721]\t Cost: 15.438440156242878\n",
            "Iteration: 2519\t Weight1: [9.06554452]\t Weight2: [1.20889795]\t Bias: [2.63185791]\t Cost: 15.438440079555193\n",
            "Iteration: 2520\t Weight1: [9.06556214]\t Weight2: [1.20886885]\t Bias: [2.63183866]\t Cost: 15.438440003267218\n",
            "Iteration: 2521\t Weight1: [9.06557972]\t Weight2: [1.20883983]\t Bias: [2.63181947]\t Cost: 15.438439927376862\n",
            "Iteration: 2522\t Weight1: [9.06559725]\t Weight2: [1.20881087]\t Bias: [2.63180033]\t Cost: 15.438439851882052\n",
            "Iteration: 2523\t Weight1: [9.06561473]\t Weight2: [1.208782]\t Bias: [2.63178124]\t Cost: 15.438439776780754\n",
            "Iteration: 2524\t Weight1: [9.06563217]\t Weight2: [1.20875319]\t Bias: [2.63176221]\t Cost: 15.438439702070879\n",
            "Iteration: 2525\t Weight1: [9.06564957]\t Weight2: [1.20872446]\t Bias: [2.63174323]\t Cost: 15.438439627750412\n",
            "Iteration: 2526\t Weight1: [9.06566692]\t Weight2: [1.2086958]\t Bias: [2.6317243]\t Cost: 15.438439553817284\n",
            "Iteration: 2527\t Weight1: [9.06568422]\t Weight2: [1.20866722]\t Bias: [2.63170542]\t Cost: 15.438439480269507\n",
            "Iteration: 2528\t Weight1: [9.06570148]\t Weight2: [1.2086387]\t Bias: [2.6316866]\t Cost: 15.438439407105054\n",
            "Iteration: 2529\t Weight1: [9.0657187]\t Weight2: [1.20861026]\t Bias: [2.63166783]\t Cost: 15.438439334321933\n",
            "Iteration: 2530\t Weight1: [9.06573587]\t Weight2: [1.2085819]\t Bias: [2.63164911]\t Cost: 15.438439261918134\n",
            "Iteration: 2531\t Weight1: [9.065753]\t Weight2: [1.2085536]\t Bias: [2.63163044]\t Cost: 15.438439189891717\n",
            "Iteration: 2532\t Weight1: [9.06577008]\t Weight2: [1.20852538]\t Bias: [2.63161183]\t Cost: 15.438439118240668\n",
            "Iteration: 2533\t Weight1: [9.06578712]\t Weight2: [1.20849723]\t Bias: [2.63159327]\t Cost: 15.438439046963047\n",
            "Iteration: 2534\t Weight1: [9.06580412]\t Weight2: [1.20846915]\t Bias: [2.63157476]\t Cost: 15.438438976056927\n",
            "Iteration: 2535\t Weight1: [9.06582107]\t Weight2: [1.20844114]\t Bias: [2.6315563]\t Cost: 15.438438905520327\n",
            "Iteration: 2536\t Weight1: [9.06583797]\t Weight2: [1.2084132]\t Bias: [2.63153789]\t Cost: 15.438438835351347\n",
            "Iteration: 2537\t Weight1: [9.06585484]\t Weight2: [1.20838533]\t Bias: [2.63151953]\t Cost: 15.438438765548065\n",
            "Iteration: 2538\t Weight1: [9.06587166]\t Weight2: [1.20835754]\t Bias: [2.63150123]\t Cost: 15.43843869610855\n",
            "Iteration: 2539\t Weight1: [9.06588843]\t Weight2: [1.20832981]\t Bias: [2.63148297]\t Cost: 15.43843862703094\n",
            "Iteration: 2540\t Weight1: [9.06590517]\t Weight2: [1.20830216]\t Bias: [2.63146477]\t Cost: 15.438438558313315\n",
            "Iteration: 2541\t Weight1: [9.06592186]\t Weight2: [1.20827458]\t Bias: [2.63144661]\t Cost: 15.438438489953812\n",
            "Iteration: 2542\t Weight1: [9.0659385]\t Weight2: [1.20824706]\t Bias: [2.63142851]\t Cost: 15.43843842195057\n",
            "Iteration: 2543\t Weight1: [9.06595511]\t Weight2: [1.20821962]\t Bias: [2.63141045]\t Cost: 15.4384383543017\n",
            "Iteration: 2544\t Weight1: [9.06597167]\t Weight2: [1.20819225]\t Bias: [2.63139245]\t Cost: 15.438438287005395\n",
            "Iteration: 2545\t Weight1: [9.06598819]\t Weight2: [1.20816494]\t Bias: [2.6313745]\t Cost: 15.438438220059778\n",
            "Iteration: 2546\t Weight1: [9.06600466]\t Weight2: [1.20813771]\t Bias: [2.6313566]\t Cost: 15.438438153463034\n",
            "Iteration: 2547\t Weight1: [9.06602109]\t Weight2: [1.20811054]\t Bias: [2.63133874]\t Cost: 15.438438087213342\n",
            "Iteration: 2548\t Weight1: [9.06603749]\t Weight2: [1.20808345]\t Bias: [2.63132094]\t Cost: 15.438438021308887\n",
            "Iteration: 2549\t Weight1: [9.06605383]\t Weight2: [1.20805642]\t Bias: [2.63130318]\t Cost: 15.43843795574788\n",
            "Iteration: 2550\t Weight1: [9.06607014]\t Weight2: [1.20802946]\t Bias: [2.63128548]\t Cost: 15.43843789052851\n",
            "Iteration: 2551\t Weight1: [9.0660864]\t Weight2: [1.20800257]\t Bias: [2.63126782]\t Cost: 15.438437825649013\n",
            "Iteration: 2552\t Weight1: [9.06610262]\t Weight2: [1.20797575]\t Bias: [2.63125022]\t Cost: 15.438437761107602\n",
            "Iteration: 2553\t Weight1: [9.0661188]\t Weight2: [1.207949]\t Bias: [2.63123266]\t Cost: 15.438437696902511\n",
            "Iteration: 2554\t Weight1: [9.06613494]\t Weight2: [1.20792231]\t Bias: [2.63121515]\t Cost: 15.438437633032008\n",
            "Iteration: 2555\t Weight1: [9.06615104]\t Weight2: [1.2078957]\t Bias: [2.63119769]\t Cost: 15.43843756949432\n",
            "Iteration: 2556\t Weight1: [9.06616709]\t Weight2: [1.20786915]\t Bias: [2.63118028]\t Cost: 15.438437506287723\n",
            "Iteration: 2557\t Weight1: [9.0661831]\t Weight2: [1.20784267]\t Bias: [2.63116291]\t Cost: 15.43843744341049\n",
            "Iteration: 2558\t Weight1: [9.06619908]\t Weight2: [1.20781625]\t Bias: [2.6311456]\t Cost: 15.4384373808609\n",
            "Iteration: 2559\t Weight1: [9.06621501]\t Weight2: [1.2077899]\t Bias: [2.63112833]\t Cost: 15.438437318637241\n",
            "Iteration: 2560\t Weight1: [9.0662309]\t Weight2: [1.20776363]\t Bias: [2.63111111]\t Cost: 15.43843725673781\n",
            "Iteration: 2561\t Weight1: [9.06624674]\t Weight2: [1.20773741]\t Bias: [2.63109394]\t Cost: 15.438437195160928\n",
            "Iteration: 2562\t Weight1: [9.06626255]\t Weight2: [1.20771127]\t Bias: [2.63107681]\t Cost: 15.43843713390491\n",
            "Iteration: 2563\t Weight1: [9.06627832]\t Weight2: [1.20768519]\t Bias: [2.63105974]\t Cost: 15.438437072968071\n",
            "Iteration: 2564\t Weight1: [9.06629404]\t Weight2: [1.20765917]\t Bias: [2.63104271]\t Cost: 15.438437012348746\n",
            "Iteration: 2565\t Weight1: [9.06630973]\t Weight2: [1.20763323]\t Bias: [2.63102572]\t Cost: 15.438436952045295\n",
            "Iteration: 2566\t Weight1: [9.06632537]\t Weight2: [1.20760735]\t Bias: [2.63100879]\t Cost: 15.43843689205605\n",
            "Iteration: 2567\t Weight1: [9.06634098]\t Weight2: [1.20758153]\t Bias: [2.6309919]\t Cost: 15.438436832379374\n",
            "Iteration: 2568\t Weight1: [9.06635654]\t Weight2: [1.20755578]\t Bias: [2.63097506]\t Cost: 15.438436773013656\n",
            "Iteration: 2569\t Weight1: [9.06637206]\t Weight2: [1.2075301]\t Bias: [2.63095826]\t Cost: 15.438436713957257\n",
            "Iteration: 2570\t Weight1: [9.06638755]\t Weight2: [1.20750448]\t Bias: [2.63094152]\t Cost: 15.43843665520855\n",
            "Iteration: 2571\t Weight1: [9.06640299]\t Weight2: [1.20747893]\t Bias: [2.63092482]\t Cost: 15.43843659676597\n",
            "Iteration: 2572\t Weight1: [9.06641839]\t Weight2: [1.20745344]\t Bias: [2.63090816]\t Cost: 15.43843653862789\n",
            "Iteration: 2573\t Weight1: [9.06643376]\t Weight2: [1.20742802]\t Bias: [2.63089155]\t Cost: 15.438436480792717\n",
            "Iteration: 2574\t Weight1: [9.06644908]\t Weight2: [1.20740266]\t Bias: [2.63087499]\t Cost: 15.438436423258894\n",
            "Iteration: 2575\t Weight1: [9.06646436]\t Weight2: [1.20737737]\t Bias: [2.63085847]\t Cost: 15.438436366024826\n",
            "Iteration: 2576\t Weight1: [9.06647961]\t Weight2: [1.20735214]\t Bias: [2.630842]\t Cost: 15.438436309088969\n",
            "Iteration: 2577\t Weight1: [9.06649481]\t Weight2: [1.20732697]\t Bias: [2.63082557]\t Cost: 15.438436252449756\n",
            "Iteration: 2578\t Weight1: [9.06650998]\t Weight2: [1.20730187]\t Bias: [2.63080919]\t Cost: 15.438436196105643\n",
            "Iteration: 2579\t Weight1: [9.0665251]\t Weight2: [1.20727684]\t Bias: [2.63079286]\t Cost: 15.438436140055085\n",
            "Iteration: 2580\t Weight1: [9.06654019]\t Weight2: [1.20725186]\t Bias: [2.63077657]\t Cost: 15.438436084296548\n",
            "Iteration: 2581\t Weight1: [9.06655524]\t Weight2: [1.20722695]\t Bias: [2.63076032]\t Cost: 15.43843602882853\n",
            "Iteration: 2582\t Weight1: [9.06657025]\t Weight2: [1.20720211]\t Bias: [2.63074412]\t Cost: 15.43843597364948\n",
            "Iteration: 2583\t Weight1: [9.06658522]\t Weight2: [1.20717733]\t Bias: [2.63072797]\t Cost: 15.438435918757941\n",
            "Iteration: 2584\t Weight1: [9.06660015]\t Weight2: [1.20715261]\t Bias: [2.63071186]\t Cost: 15.438435864152364\n",
            "Iteration: 2585\t Weight1: [9.06661505]\t Weight2: [1.20712795]\t Bias: [2.63069579]\t Cost: 15.438435809831288\n",
            "Iteration: 2586\t Weight1: [9.0666299]\t Weight2: [1.20710336]\t Bias: [2.63067977]\t Cost: 15.438435755793197\n",
            "Iteration: 2587\t Weight1: [9.06664472]\t Weight2: [1.20707883]\t Bias: [2.6306638]\t Cost: 15.438435702036658\n",
            "Iteration: 2588\t Weight1: [9.0666595]\t Weight2: [1.20705436]\t Bias: [2.63064787]\t Cost: 15.438435648560183\n",
            "Iteration: 2589\t Weight1: [9.06667424]\t Weight2: [1.20702995]\t Bias: [2.63063198]\t Cost: 15.43843559536229\n",
            "Iteration: 2590\t Weight1: [9.06668894]\t Weight2: [1.20700561]\t Bias: [2.63061613]\t Cost: 15.438435542441553\n",
            "Iteration: 2591\t Weight1: [9.0667036]\t Weight2: [1.20698133]\t Bias: [2.63060033]\t Cost: 15.438435489796513\n",
            "Iteration: 2592\t Weight1: [9.06671823]\t Weight2: [1.20695711]\t Bias: [2.63058458]\t Cost: 15.438435437425754\n",
            "Iteration: 2593\t Weight1: [9.06673282]\t Weight2: [1.20693295]\t Bias: [2.63056886]\t Cost: 15.438435385327816\n",
            "Iteration: 2594\t Weight1: [9.06674737]\t Weight2: [1.20690885]\t Bias: [2.63055319]\t Cost: 15.43843533350129\n",
            "Iteration: 2595\t Weight1: [9.06676188]\t Weight2: [1.20688482]\t Bias: [2.63053757]\t Cost: 15.438435281944752\n",
            "Iteration: 2596\t Weight1: [9.06677636]\t Weight2: [1.20686084]\t Bias: [2.63052199]\t Cost: 15.43843523065681\n",
            "Iteration: 2597\t Weight1: [9.06679079]\t Weight2: [1.20683693]\t Bias: [2.63050645]\t Cost: 15.438435179636043\n",
            "Iteration: 2598\t Weight1: [9.06680519]\t Weight2: [1.20681308]\t Bias: [2.63049095]\t Cost: 15.43843512888108\n",
            "Iteration: 2599\t Weight1: [9.06681956]\t Weight2: [1.20678929]\t Bias: [2.6304755]\t Cost: 15.438435078390508\n",
            "Iteration: 2600\t Weight1: [9.06683388]\t Weight2: [1.20676556]\t Bias: [2.63046009]\t Cost: 15.438435028162976\n",
            "Iteration: 2601\t Weight1: [9.06684817]\t Weight2: [1.20674189]\t Bias: [2.63044472]\t Cost: 15.438434978197087\n",
            "Iteration: 2602\t Weight1: [9.06686243]\t Weight2: [1.20671828]\t Bias: [2.63042939]\t Cost: 15.438434928491501\n",
            "Iteration: 2603\t Weight1: [9.06687664]\t Weight2: [1.20669473]\t Bias: [2.63041411]\t Cost: 15.438434879044836\n",
            "Iteration: 2604\t Weight1: [9.06689082]\t Weight2: [1.20667124]\t Bias: [2.63039887]\t Cost: 15.438434829855765\n",
            "Iteration: 2605\t Weight1: [9.06690496]\t Weight2: [1.20664781]\t Bias: [2.63038367]\t Cost: 15.43843478092292\n",
            "Iteration: 2606\t Weight1: [9.06691907]\t Weight2: [1.20662444]\t Bias: [2.63036851]\t Cost: 15.438434732244993\n",
            "Iteration: 2607\t Weight1: [9.06693314]\t Weight2: [1.20660113]\t Bias: [2.6303534]\t Cost: 15.43843468382063\n",
            "Iteration: 2608\t Weight1: [9.06694717]\t Weight2: [1.20657788]\t Bias: [2.63033832]\t Cost: 15.438434635648516\n",
            "Iteration: 2609\t Weight1: [9.06696117]\t Weight2: [1.20655469]\t Bias: [2.63032329]\t Cost: 15.438434587727341\n",
            "Iteration: 2610\t Weight1: [9.06697513]\t Weight2: [1.20653156]\t Bias: [2.6303083]\t Cost: 15.43843454005578\n",
            "Iteration: 2611\t Weight1: [9.06698905]\t Weight2: [1.20650848]\t Bias: [2.63029335]\t Cost: 15.438434492632561\n",
            "Iteration: 2612\t Weight1: [9.06700294]\t Weight2: [1.20648547]\t Bias: [2.63027845]\t Cost: 15.438434445456355\n",
            "Iteration: 2613\t Weight1: [9.06701679]\t Weight2: [1.20646251]\t Bias: [2.63026358]\t Cost: 15.43843439852591\n",
            "Iteration: 2614\t Weight1: [9.06703061]\t Weight2: [1.20643962]\t Bias: [2.63024876]\t Cost: 15.438434351839923\n",
            "Iteration: 2615\t Weight1: [9.06704439]\t Weight2: [1.20641678]\t Bias: [2.63023397]\t Cost: 15.438434305397115\n",
            "Iteration: 2616\t Weight1: [9.06705813]\t Weight2: [1.206394]\t Bias: [2.63021923]\t Cost: 15.438434259196223\n",
            "Iteration: 2617\t Weight1: [9.06707184]\t Weight2: [1.20637128]\t Bias: [2.63020453]\t Cost: 15.438434213235979\n",
            "Iteration: 2618\t Weight1: [9.06708551]\t Weight2: [1.20634861]\t Bias: [2.63018986]\t Cost: 15.438434167515156\n",
            "Iteration: 2619\t Weight1: [9.06709915]\t Weight2: [1.20632601]\t Bias: [2.63017524]\t Cost: 15.438434122032461\n",
            "Iteration: 2620\t Weight1: [9.06711276]\t Weight2: [1.20630346]\t Bias: [2.63016066]\t Cost: 15.43843407678668\n",
            "Iteration: 2621\t Weight1: [9.06712632]\t Weight2: [1.20628097]\t Bias: [2.63014612]\t Cost: 15.438434031776588\n",
            "Iteration: 2622\t Weight1: [9.06713986]\t Weight2: [1.20625853]\t Bias: [2.63013162]\t Cost: 15.438433987000924\n",
            "Iteration: 2623\t Weight1: [9.06715335]\t Weight2: [1.20623615]\t Bias: [2.63011716]\t Cost: 15.438433942458499\n",
            "Iteration: 2624\t Weight1: [9.06716682]\t Weight2: [1.20621384]\t Bias: [2.63010274]\t Cost: 15.43843389814808\n",
            "Iteration: 2625\t Weight1: [9.06718025]\t Weight2: [1.20619157]\t Bias: [2.63008836]\t Cost: 15.438433854068453\n",
            "Iteration: 2626\t Weight1: [9.06719364]\t Weight2: [1.20616937]\t Bias: [2.63007402]\t Cost: 15.438433810218424\n",
            "Iteration: 2627\t Weight1: [9.067207]\t Weight2: [1.20614722]\t Bias: [2.63005972]\t Cost: 15.438433766596782\n",
            "Iteration: 2628\t Weight1: [9.06722032]\t Weight2: [1.20612512]\t Bias: [2.63004546]\t Cost: 15.438433723202353\n",
            "Iteration: 2629\t Weight1: [9.06723361]\t Weight2: [1.20610309]\t Bias: [2.63003123]\t Cost: 15.438433680033949\n",
            "Iteration: 2630\t Weight1: [9.06724687]\t Weight2: [1.20608111]\t Bias: [2.63001705]\t Cost: 15.438433637090382\n",
            "Iteration: 2631\t Weight1: [9.06726009]\t Weight2: [1.20605918]\t Bias: [2.63000291]\t Cost: 15.438433594370485\n",
            "Iteration: 2632\t Weight1: [9.06727328]\t Weight2: [1.20603732]\t Bias: [2.6299888]\t Cost: 15.4384335518731\n",
            "Iteration: 2633\t Weight1: [9.06728643]\t Weight2: [1.2060155]\t Bias: [2.62997474]\t Cost: 15.438433509597049\n",
            "Iteration: 2634\t Weight1: [9.06729955]\t Weight2: [1.20599375]\t Bias: [2.62996071]\t Cost: 15.438433467541195\n",
            "Iteration: 2635\t Weight1: [9.06731263]\t Weight2: [1.20597205]\t Bias: [2.62994672]\t Cost: 15.438433425704389\n",
            "Iteration: 2636\t Weight1: [9.06732568]\t Weight2: [1.2059504]\t Bias: [2.62993277]\t Cost: 15.438433384085464\n",
            "Iteration: 2637\t Weight1: [9.0673387]\t Weight2: [1.20592881]\t Bias: [2.62991886]\t Cost: 15.438433342683314\n",
            "Iteration: 2638\t Weight1: [9.06735169]\t Weight2: [1.20590727]\t Bias: [2.62990499]\t Cost: 15.438433301496799\n",
            "Iteration: 2639\t Weight1: [9.06736464]\t Weight2: [1.20588579]\t Bias: [2.62989115]\t Cost: 15.438433260524793\n",
            "Iteration: 2640\t Weight1: [9.06737755]\t Weight2: [1.20586437]\t Bias: [2.62987736]\t Cost: 15.438433219766168\n",
            "Iteration: 2641\t Weight1: [9.06739044]\t Weight2: [1.205843]\t Bias: [2.6298636]\t Cost: 15.43843317921983\n",
            "Iteration: 2642\t Weight1: [9.06740329]\t Weight2: [1.20582168]\t Bias: [2.62984988]\t Cost: 15.43843313888467\n",
            "Iteration: 2643\t Weight1: [9.0674161]\t Weight2: [1.20580042]\t Bias: [2.6298362]\t Cost: 15.438433098759564\n",
            "Iteration: 2644\t Weight1: [9.06742889]\t Weight2: [1.20577921]\t Bias: [2.62982255]\t Cost: 15.438433058843438\n",
            "Iteration: 2645\t Weight1: [9.06744164]\t Weight2: [1.20575806]\t Bias: [2.62980894]\t Cost: 15.438433019135202\n",
            "Iteration: 2646\t Weight1: [9.06745435]\t Weight2: [1.20573696]\t Bias: [2.62979537]\t Cost: 15.438432979633774\n",
            "Iteration: 2647\t Weight1: [9.06746704]\t Weight2: [1.20571591]\t Bias: [2.62978184]\t Cost: 15.43843294033806\n",
            "Iteration: 2648\t Weight1: [9.06747969]\t Weight2: [1.20569492]\t Bias: [2.62976835]\t Cost: 15.438432901247001\n",
            "Iteration: 2649\t Weight1: [9.06749231]\t Weight2: [1.20567398]\t Bias: [2.62975489]\t Cost: 15.438432862359527\n",
            "Iteration: 2650\t Weight1: [9.0675049]\t Weight2: [1.2056531]\t Bias: [2.62974147]\t Cost: 15.438432823674573\n",
            "Iteration: 2651\t Weight1: [9.06751745]\t Weight2: [1.20563227]\t Bias: [2.62972809]\t Cost: 15.438432785191088\n",
            "Iteration: 2652\t Weight1: [9.06752997]\t Weight2: [1.20561149]\t Bias: [2.62971474]\t Cost: 15.438432746908013\n",
            "Iteration: 2653\t Weight1: [9.06754246]\t Weight2: [1.20559076]\t Bias: [2.62970143]\t Cost: 15.438432708824326\n",
            "Iteration: 2654\t Weight1: [9.06755492]\t Weight2: [1.20557009]\t Bias: [2.62968816]\t Cost: 15.438432670938958\n",
            "Iteration: 2655\t Weight1: [9.06756734]\t Weight2: [1.20554947]\t Bias: [2.62967492]\t Cost: 15.438432633250905\n",
            "Iteration: 2656\t Weight1: [9.06757973]\t Weight2: [1.2055289]\t Bias: [2.62966172]\t Cost: 15.438432595759116\n",
            "Iteration: 2657\t Weight1: [9.06759209]\t Weight2: [1.20550839]\t Bias: [2.62964856]\t Cost: 15.438432558462566\n",
            "Iteration: 2658\t Weight1: [9.06760442]\t Weight2: [1.20548793]\t Bias: [2.62963543]\t Cost: 15.438432521360232\n",
            "Iteration: 2659\t Weight1: [9.06761672]\t Weight2: [1.20546752]\t Bias: [2.62962234]\t Cost: 15.438432484451143\n",
            "Iteration: 2660\t Weight1: [9.06762898]\t Weight2: [1.20544716]\t Bias: [2.62960928]\t Cost: 15.438432447734261\n",
            "Iteration: 2661\t Weight1: [9.06764122]\t Weight2: [1.20542685]\t Bias: [2.62959626]\t Cost: 15.43843241120857\n",
            "Iteration: 2662\t Weight1: [9.06765342]\t Weight2: [1.2054066]\t Bias: [2.62958328]\t Cost: 15.438432374873102\n",
            "Iteration: 2663\t Weight1: [9.06766559]\t Weight2: [1.2053864]\t Bias: [2.62957033]\t Cost: 15.438432338726843\n",
            "Iteration: 2664\t Weight1: [9.06767773]\t Weight2: [1.20536625]\t Bias: [2.62955742]\t Cost: 15.438432302768831\n",
            "Iteration: 2665\t Weight1: [9.06768983]\t Weight2: [1.20534615]\t Bias: [2.62954454]\t Cost: 15.438432266998062\n",
            "Iteration: 2666\t Weight1: [9.06770191]\t Weight2: [1.2053261]\t Bias: [2.6295317]\t Cost: 15.438432231413575\n",
            "Iteration: 2667\t Weight1: [9.06771395]\t Weight2: [1.2053061]\t Bias: [2.6295189]\t Cost: 15.438432196014379\n",
            "Iteration: 2668\t Weight1: [9.06772596]\t Weight2: [1.20528616]\t Bias: [2.62950613]\t Cost: 15.438432160799548\n",
            "Iteration: 2669\t Weight1: [9.06773795]\t Weight2: [1.20526626]\t Bias: [2.62949339]\t Cost: 15.438432125768067\n",
            "Iteration: 2670\t Weight1: [9.0677499]\t Weight2: [1.20524642]\t Bias: [2.62948069]\t Cost: 15.438432090919019\n",
            "Iteration: 2671\t Weight1: [9.06776182]\t Weight2: [1.20522662]\t Bias: [2.62946803]\t Cost: 15.438432056251454\n",
            "Iteration: 2672\t Weight1: [9.06777371]\t Weight2: [1.20520688]\t Bias: [2.6294554]\t Cost: 15.438432021764404\n",
            "Iteration: 2673\t Weight1: [9.06778557]\t Weight2: [1.20518719]\t Bias: [2.6294428]\t Cost: 15.438431987456942\n",
            "Iteration: 2674\t Weight1: [9.06779739]\t Weight2: [1.20516755]\t Bias: [2.62943024]\t Cost: 15.438431953328122\n",
            "Iteration: 2675\t Weight1: [9.06780919]\t Weight2: [1.20514796]\t Bias: [2.62941772]\t Cost: 15.438431919377015\n",
            "Iteration: 2676\t Weight1: [9.06782096]\t Weight2: [1.20512841]\t Bias: [2.62940522]\t Cost: 15.438431885602705\n",
            "Iteration: 2677\t Weight1: [9.06783269]\t Weight2: [1.20510892]\t Bias: [2.62939277]\t Cost: 15.438431852004273\n",
            "Iteration: 2678\t Weight1: [9.0678444]\t Weight2: [1.20508948]\t Bias: [2.62938034]\t Cost: 15.438431818580778\n",
            "Iteration: 2679\t Weight1: [9.06785607]\t Weight2: [1.20507009]\t Bias: [2.62936796]\t Cost: 15.43843178533133\n",
            "Iteration: 2680\t Weight1: [9.06786772]\t Weight2: [1.20505075]\t Bias: [2.6293556]\t Cost: 15.43843175225502\n",
            "Iteration: 2681\t Weight1: [9.06787933]\t Weight2: [1.20503145]\t Bias: [2.62934328]\t Cost: 15.438431719350948\n",
            "Iteration: 2682\t Weight1: [9.06789092]\t Weight2: [1.20501221]\t Bias: [2.62933099]\t Cost: 15.438431686618204\n",
            "Iteration: 2683\t Weight1: [9.06790248]\t Weight2: [1.20499301]\t Bias: [2.62931874]\t Cost: 15.438431654055892\n",
            "Iteration: 2684\t Weight1: [9.067914]\t Weight2: [1.20497387]\t Bias: [2.62930652]\t Cost: 15.43843162166314\n",
            "Iteration: 2685\t Weight1: [9.0679255]\t Weight2: [1.20495477]\t Bias: [2.62929434]\t Cost: 15.438431589439064\n",
            "Iteration: 2686\t Weight1: [9.06793696]\t Weight2: [1.20493572]\t Bias: [2.62928218]\t Cost: 15.438431557382765\n",
            "Iteration: 2687\t Weight1: [9.0679484]\t Weight2: [1.20491672]\t Bias: [2.62927007]\t Cost: 15.43843152549338\n",
            "Iteration: 2688\t Weight1: [9.0679598]\t Weight2: [1.20489777]\t Bias: [2.62925798]\t Cost: 15.438431493770059\n",
            "Iteration: 2689\t Weight1: [9.06797118]\t Weight2: [1.20487887]\t Bias: [2.62924593]\t Cost: 15.438431462211906\n",
            "Iteration: 2690\t Weight1: [9.06798253]\t Weight2: [1.20486002]\t Bias: [2.62923391]\t Cost: 15.43843143081806\n",
            "Iteration: 2691\t Weight1: [9.06799385]\t Weight2: [1.20484121]\t Bias: [2.62922192]\t Cost: 15.438431399587678\n",
            "Iteration: 2692\t Weight1: [9.06800514]\t Weight2: [1.20482245]\t Bias: [2.62920997]\t Cost: 15.438431368519913\n",
            "Iteration: 2693\t Weight1: [9.0680164]\t Weight2: [1.20480374]\t Bias: [2.62919805]\t Cost: 15.438431337613931\n",
            "Iteration: 2694\t Weight1: [9.06802763]\t Weight2: [1.20478508]\t Bias: [2.62918616]\t Cost: 15.438431306868857\n",
            "Iteration: 2695\t Weight1: [9.06803883]\t Weight2: [1.20476647]\t Bias: [2.62917431]\t Cost: 15.438431276283854\n",
            "Iteration: 2696\t Weight1: [9.06805]\t Weight2: [1.2047479]\t Bias: [2.62916249]\t Cost: 15.438431245858094\n",
            "Iteration: 2697\t Weight1: [9.06806114]\t Weight2: [1.20472938]\t Bias: [2.6291507]\t Cost: 15.43843121559077\n",
            "Iteration: 2698\t Weight1: [9.06807226]\t Weight2: [1.20471091]\t Bias: [2.62913894]\t Cost: 15.43843118548103\n",
            "Iteration: 2699\t Weight1: [9.06808334]\t Weight2: [1.20469248]\t Bias: [2.62912721]\t Cost: 15.438431155528058\n",
            "Iteration: 2700\t Weight1: [9.0680944]\t Weight2: [1.20467411]\t Bias: [2.62911552]\t Cost: 15.438431125731054\n",
            "Iteration: 2701\t Weight1: [9.06810543]\t Weight2: [1.20465578]\t Bias: [2.62910386]\t Cost: 15.438431096089179\n",
            "Iteration: 2702\t Weight1: [9.06811643]\t Weight2: [1.20463749]\t Bias: [2.62909223]\t Cost: 15.43843106660163\n",
            "Iteration: 2703\t Weight1: [9.0681274]\t Weight2: [1.20461925]\t Bias: [2.62908064]\t Cost: 15.438431037267618\n",
            "Iteration: 2704\t Weight1: [9.06813835]\t Weight2: [1.20460106]\t Bias: [2.62906907]\t Cost: 15.438431008086322\n",
            "Iteration: 2705\t Weight1: [9.06814926]\t Weight2: [1.20458292]\t Bias: [2.62905754]\t Cost: 15.438430979056978\n",
            "Iteration: 2706\t Weight1: [9.06816015]\t Weight2: [1.20456482]\t Bias: [2.62904604]\t Cost: 15.438430950178768\n",
            "Iteration: 2707\t Weight1: [9.06817101]\t Weight2: [1.20454677]\t Bias: [2.62903457]\t Cost: 15.438430921450898\n",
            "Iteration: 2708\t Weight1: [9.06818184]\t Weight2: [1.20452877]\t Bias: [2.62902313]\t Cost: 15.438430892872615\n",
            "Iteration: 2709\t Weight1: [9.06819264]\t Weight2: [1.20451081]\t Bias: [2.62901172]\t Cost: 15.43843086444311\n",
            "Iteration: 2710\t Weight1: [9.06820341]\t Weight2: [1.20449289]\t Bias: [2.62900035]\t Cost: 15.438430836161631\n",
            "Iteration: 2711\t Weight1: [9.06821416]\t Weight2: [1.20447503]\t Bias: [2.62898901]\t Cost: 15.438430808027377\n",
            "Iteration: 2712\t Weight1: [9.06822488]\t Weight2: [1.2044572]\t Bias: [2.62897769]\t Cost: 15.438430780039615\n",
            "Iteration: 2713\t Weight1: [9.06823557]\t Weight2: [1.20443943]\t Bias: [2.62896641]\t Cost: 15.438430752197554\n",
            "Iteration: 2714\t Weight1: [9.06824623]\t Weight2: [1.2044217]\t Bias: [2.62895516]\t Cost: 15.438430724500456\n",
            "Iteration: 2715\t Weight1: [9.06825687]\t Weight2: [1.20440401]\t Bias: [2.62894394]\t Cost: 15.438430696947558\n",
            "Iteration: 2716\t Weight1: [9.06826748]\t Weight2: [1.20438637]\t Bias: [2.62893275]\t Cost: 15.438430669538107\n",
            "Iteration: 2717\t Weight1: [9.06827806]\t Weight2: [1.20436878]\t Bias: [2.62892159]\t Cost: 15.438430642271337\n",
            "Iteration: 2718\t Weight1: [9.06828861]\t Weight2: [1.20435123]\t Bias: [2.62891047]\t Cost: 15.438430615146546\n",
            "Iteration: 2719\t Weight1: [9.06829914]\t Weight2: [1.20433372]\t Bias: [2.62889937]\t Cost: 15.438430588162962\n",
            "Iteration: 2720\t Weight1: [9.06830964]\t Weight2: [1.20431626]\t Bias: [2.6288883]\t Cost: 15.438430561319858\n",
            "Iteration: 2721\t Weight1: [9.06832011]\t Weight2: [1.20429885]\t Bias: [2.62887727]\t Cost: 15.4384305346165\n",
            "Iteration: 2722\t Weight1: [9.06833055]\t Weight2: [1.20428148]\t Bias: [2.62886626]\t Cost: 15.438430508052157\n",
            "Iteration: 2723\t Weight1: [9.06834097]\t Weight2: [1.20426415]\t Bias: [2.62885528]\t Cost: 15.43843048162612\n",
            "Iteration: 2724\t Weight1: [9.06835136]\t Weight2: [1.20424687]\t Bias: [2.62884434]\t Cost: 15.438430455337663\n",
            "Iteration: 2725\t Weight1: [9.06836172]\t Weight2: [1.20422963]\t Bias: [2.62883342]\t Cost: 15.438430429186058\n",
            "Iteration: 2726\t Weight1: [9.06837206]\t Weight2: [1.20421243]\t Bias: [2.62882254]\t Cost: 15.438430403170587\n",
            "Iteration: 2727\t Weight1: [9.06838237]\t Weight2: [1.20419528]\t Bias: [2.62881168]\t Cost: 15.438430377290572\n",
            "Iteration: 2728\t Weight1: [9.06839265]\t Weight2: [1.20417818]\t Bias: [2.62880085]\t Cost: 15.438430351545282\n",
            "Iteration: 2729\t Weight1: [9.06840291]\t Weight2: [1.20416111]\t Bias: [2.62879006]\t Cost: 15.438430325934002\n",
            "Iteration: 2730\t Weight1: [9.06841314]\t Weight2: [1.2041441]\t Bias: [2.62877929]\t Cost: 15.43843030045606\n",
            "Iteration: 2731\t Weight1: [9.06842334]\t Weight2: [1.20412712]\t Bias: [2.62876855]\t Cost: 15.438430275110761\n",
            "Iteration: 2732\t Weight1: [9.06843352]\t Weight2: [1.20411019]\t Bias: [2.62875785]\t Cost: 15.438430249897413\n",
            "Iteration: 2733\t Weight1: [9.06844367]\t Weight2: [1.2040933]\t Bias: [2.62874717]\t Cost: 15.43843022481531\n",
            "Iteration: 2734\t Weight1: [9.0684538]\t Weight2: [1.20407645]\t Bias: [2.62873652]\t Cost: 15.438430199863788\n",
            "Iteration: 2735\t Weight1: [9.0684639]\t Weight2: [1.20405965]\t Bias: [2.6287259]\t Cost: 15.438430175042146\n",
            "Iteration: 2736\t Weight1: [9.06847397]\t Weight2: [1.20404289]\t Bias: [2.62871531]\t Cost: 15.438430150349726\n",
            "Iteration: 2737\t Weight1: [9.06848402]\t Weight2: [1.20402618]\t Bias: [2.62870475]\t Cost: 15.438430125785848\n",
            "Iteration: 2738\t Weight1: [9.06849404]\t Weight2: [1.2040095]\t Bias: [2.62869421]\t Cost: 15.438430101349851\n",
            "Iteration: 2739\t Weight1: [9.06850403]\t Weight2: [1.20399287]\t Bias: [2.62868371]\t Cost: 15.43843007704106\n",
            "Iteration: 2740\t Weight1: [9.068514]\t Weight2: [1.20397628]\t Bias: [2.62867323]\t Cost: 15.438430052858807\n",
            "Iteration: 2741\t Weight1: [9.06852394]\t Weight2: [1.20395974]\t Bias: [2.62866279]\t Cost: 15.438430028802433\n",
            "Iteration: 2742\t Weight1: [9.06853386]\t Weight2: [1.20394323]\t Bias: [2.62865237]\t Cost: 15.438430004871293\n",
            "Iteration: 2743\t Weight1: [9.06854375]\t Weight2: [1.20392677]\t Bias: [2.62864198]\t Cost: 15.438429981064724\n",
            "Iteration: 2744\t Weight1: [9.06855362]\t Weight2: [1.20391035]\t Bias: [2.62863162]\t Cost: 15.438429957382096\n",
            "Iteration: 2745\t Weight1: [9.06856346]\t Weight2: [1.20389398]\t Bias: [2.62862129]\t Cost: 15.438429933822736\n",
            "Iteration: 2746\t Weight1: [9.06857327]\t Weight2: [1.20387764]\t Bias: [2.62861098]\t Cost: 15.438429910386025\n",
            "Iteration: 2747\t Weight1: [9.06858306]\t Weight2: [1.20386135]\t Bias: [2.62860071]\t Cost: 15.438429887071312\n",
            "Iteration: 2748\t Weight1: [9.06859282]\t Weight2: [1.20384509]\t Bias: [2.62859046]\t Cost: 15.438429863877976\n",
            "Iteration: 2749\t Weight1: [9.06860256]\t Weight2: [1.20382888]\t Bias: [2.62858024]\t Cost: 15.438429840805355\n",
            "Iteration: 2750\t Weight1: [9.06861228]\t Weight2: [1.20381272]\t Bias: [2.62857005]\t Cost: 15.438429817852835\n",
            "Iteration: 2751\t Weight1: [9.06862196]\t Weight2: [1.20379659]\t Bias: [2.62855989]\t Cost: 15.438429795019802\n",
            "Iteration: 2752\t Weight1: [9.06863163]\t Weight2: [1.2037805]\t Bias: [2.62854975]\t Cost: 15.438429772305634\n",
            "Iteration: 2753\t Weight1: [9.06864127]\t Weight2: [1.20376446]\t Bias: [2.62853964]\t Cost: 15.438429749709686\n",
            "Iteration: 2754\t Weight1: [9.06865088]\t Weight2: [1.20374845]\t Bias: [2.62852956]\t Cost: 15.438429727231362\n",
            "Iteration: 2755\t Weight1: [9.06866047]\t Weight2: [1.20373249]\t Bias: [2.62851951]\t Cost: 15.438429704870053\n",
            "Iteration: 2756\t Weight1: [9.06867003]\t Weight2: [1.20371657]\t Bias: [2.62850948]\t Cost: 15.438429682625134\n",
            "Iteration: 2757\t Weight1: [9.06867957]\t Weight2: [1.20370069]\t Bias: [2.62849949]\t Cost: 15.438429660496015\n",
            "Iteration: 2758\t Weight1: [9.06868908]\t Weight2: [1.20368485]\t Bias: [2.62848952]\t Cost: 15.43842963848208\n",
            "Iteration: 2759\t Weight1: [9.06869857]\t Weight2: [1.20366905]\t Bias: [2.62847957]\t Cost: 15.438429616582743\n",
            "Iteration: 2760\t Weight1: [9.06870804]\t Weight2: [1.20365329]\t Bias: [2.62846966]\t Cost: 15.438429594797382\n",
            "Iteration: 2761\t Weight1: [9.06871748]\t Weight2: [1.20363757]\t Bias: [2.62845977]\t Cost: 15.438429573125427\n",
            "Iteration: 2762\t Weight1: [9.06872689]\t Weight2: [1.20362189]\t Bias: [2.62844991]\t Cost: 15.438429551566273\n",
            "Iteration: 2763\t Weight1: [9.06873629]\t Weight2: [1.20360625]\t Bias: [2.62844007]\t Cost: 15.438429530119349\n",
            "Iteration: 2764\t Weight1: [9.06874565]\t Weight2: [1.20359065]\t Bias: [2.62843027]\t Cost: 15.438429508784045\n",
            "Iteration: 2765\t Weight1: [9.068755]\t Weight2: [1.20357509]\t Bias: [2.62842048]\t Cost: 15.438429487559814\n",
            "Iteration: 2766\t Weight1: [9.06876431]\t Weight2: [1.20355957]\t Bias: [2.62841073]\t Cost: 15.438429466446049\n",
            "Iteration: 2767\t Weight1: [9.06877361]\t Weight2: [1.20354409]\t Bias: [2.628401]\t Cost: 15.438429445442184\n",
            "Iteration: 2768\t Weight1: [9.06878288]\t Weight2: [1.20352865]\t Bias: [2.6283913]\t Cost: 15.43842942454764\n",
            "Iteration: 2769\t Weight1: [9.06879213]\t Weight2: [1.20351325]\t Bias: [2.62838163]\t Cost: 15.43842940376186\n",
            "Iteration: 2770\t Weight1: [9.06880135]\t Weight2: [1.20349789]\t Bias: [2.62837198]\t Cost: 15.438429383084271\n",
            "Iteration: 2771\t Weight1: [9.06881055]\t Weight2: [1.20348257]\t Bias: [2.62836236]\t Cost: 15.438429362514297\n",
            "Iteration: 2772\t Weight1: [9.06881972]\t Weight2: [1.20346729]\t Bias: [2.62835276]\t Cost: 15.438429342051412\n",
            "Iteration: 2773\t Weight1: [9.06882887]\t Weight2: [1.20345204]\t Bias: [2.6283432]\t Cost: 15.438429321695029\n",
            "Iteration: 2774\t Weight1: [9.068838]\t Weight2: [1.20343684]\t Bias: [2.62833365]\t Cost: 15.438429301444591\n",
            "Iteration: 2775\t Weight1: [9.06884711]\t Weight2: [1.20342167]\t Bias: [2.62832414]\t Cost: 15.438429281299571\n",
            "Iteration: 2776\t Weight1: [9.06885619]\t Weight2: [1.20340655]\t Bias: [2.62831465]\t Cost: 15.438429261259387\n",
            "Iteration: 2777\t Weight1: [9.06886524]\t Weight2: [1.20339146]\t Bias: [2.62830518]\t Cost: 15.438429241323526\n",
            "Iteration: 2778\t Weight1: [9.06887428]\t Weight2: [1.20337641]\t Bias: [2.62829574]\t Cost: 15.438429221491415\n",
            "Iteration: 2779\t Weight1: [9.06888329]\t Weight2: [1.2033614]\t Bias: [2.62828633]\t Cost: 15.43842920176253\n",
            "Iteration: 2780\t Weight1: [9.06889227]\t Weight2: [1.20334643]\t Bias: [2.62827694]\t Cost: 15.438429182136343\n",
            "Iteration: 2781\t Weight1: [9.06890124]\t Weight2: [1.2033315]\t Bias: [2.62826758]\t Cost: 15.438429162612291\n",
            "Iteration: 2782\t Weight1: [9.06891018]\t Weight2: [1.2033166]\t Bias: [2.62825825]\t Cost: 15.438429143189872\n",
            "Iteration: 2783\t Weight1: [9.06891909]\t Weight2: [1.20330174]\t Bias: [2.62824894]\t Cost: 15.438429123868529\n",
            "Iteration: 2784\t Weight1: [9.06892799]\t Weight2: [1.20328692]\t Bias: [2.62823965]\t Cost: 15.438429104647755\n",
            "Iteration: 2785\t Weight1: [9.06893686]\t Weight2: [1.20327214]\t Bias: [2.62823039]\t Cost: 15.43842908552703\n",
            "Iteration: 2786\t Weight1: [9.06894571]\t Weight2: [1.2032574]\t Bias: [2.62822116]\t Cost: 15.438429066505808\n",
            "Iteration: 2787\t Weight1: [9.06895453]\t Weight2: [1.20324269]\t Bias: [2.62821195]\t Cost: 15.43842904758359\n",
            "Iteration: 2788\t Weight1: [9.06896333]\t Weight2: [1.20322802]\t Bias: [2.62820277]\t Cost: 15.438429028759868\n",
            "Iteration: 2789\t Weight1: [9.06897211]\t Weight2: [1.20321339]\t Bias: [2.62819361]\t Cost: 15.438429010034108\n",
            "Iteration: 2790\t Weight1: [9.06898087]\t Weight2: [1.2031988]\t Bias: [2.62818448]\t Cost: 15.438428991405813\n",
            "Iteration: 2791\t Weight1: [9.0689896]\t Weight2: [1.20318425]\t Bias: [2.62817537]\t Cost: 15.438428972874469\n",
            "Iteration: 2792\t Weight1: [9.06899832]\t Weight2: [1.20316973]\t Bias: [2.62816628]\t Cost: 15.438428954439566\n",
            "Iteration: 2793\t Weight1: [9.069007]\t Weight2: [1.20315525]\t Bias: [2.62815722]\t Cost: 15.43842893610062\n",
            "Iteration: 2794\t Weight1: [9.06901567]\t Weight2: [1.2031408]\t Bias: [2.62814819]\t Cost: 15.43842891785711\n",
            "Iteration: 2795\t Weight1: [9.06902431]\t Weight2: [1.2031264]\t Bias: [2.62813918]\t Cost: 15.438428899708555\n",
            "Iteration: 2796\t Weight1: [9.06903294]\t Weight2: [1.20311203]\t Bias: [2.6281302]\t Cost: 15.438428881654456\n",
            "Iteration: 2797\t Weight1: [9.06904154]\t Weight2: [1.20309769]\t Bias: [2.62812124]\t Cost: 15.438428863694327\n",
            "Iteration: 2798\t Weight1: [9.06905011]\t Weight2: [1.2030834]\t Bias: [2.6281123]\t Cost: 15.438428845827659\n",
            "Iteration: 2799\t Weight1: [9.06905867]\t Weight2: [1.20306914]\t Bias: [2.62810339]\t Cost: 15.438428828053988\n",
            "Iteration: 2800\t Weight1: [9.0690672]\t Weight2: [1.20305491]\t Bias: [2.6280945]\t Cost: 15.438428810372814\n",
            "Iteration: 2801\t Weight1: [9.06907571]\t Weight2: [1.20304073]\t Bias: [2.62808564]\t Cost: 15.438428792783657\n",
            "Iteration: 2802\t Weight1: [9.0690842]\t Weight2: [1.20302658]\t Bias: [2.6280768]\t Cost: 15.438428775286038\n",
            "Iteration: 2803\t Weight1: [9.06909267]\t Weight2: [1.20301246]\t Bias: [2.62806799]\t Cost: 15.438428757879505\n",
            "Iteration: 2804\t Weight1: [9.06910111]\t Weight2: [1.20299838]\t Bias: [2.6280592]\t Cost: 15.438428740563545\n",
            "Iteration: 2805\t Weight1: [9.06910953]\t Weight2: [1.20298434]\t Bias: [2.62805043]\t Cost: 15.4384287233377\n",
            "Iteration: 2806\t Weight1: [9.06911793]\t Weight2: [1.20297033]\t Bias: [2.62804169]\t Cost: 15.438428706201517\n",
            "Iteration: 2807\t Weight1: [9.06912631]\t Weight2: [1.20295636]\t Bias: [2.62803297]\t Cost: 15.43842868915452\n",
            "Iteration: 2808\t Weight1: [9.06913467]\t Weight2: [1.20294243]\t Bias: [2.62802428]\t Cost: 15.438428672196231\n",
            "Iteration: 2809\t Weight1: [9.06914301]\t Weight2: [1.20292853]\t Bias: [2.62801561]\t Cost: 15.438428655326193\n",
            "Iteration: 2810\t Weight1: [9.06915132]\t Weight2: [1.20291467]\t Bias: [2.62800696]\t Cost: 15.438428638543959\n",
            "Iteration: 2811\t Weight1: [9.06915961]\t Weight2: [1.20290084]\t Bias: [2.62799834]\t Cost: 15.438428621849067\n",
            "Iteration: 2812\t Weight1: [9.06916788]\t Weight2: [1.20288705]\t Bias: [2.62798974]\t Cost: 15.43842860524105\n",
            "Iteration: 2813\t Weight1: [9.06917613]\t Weight2: [1.20287329]\t Bias: [2.62798116]\t Cost: 15.438428588719473\n",
            "Iteration: 2814\t Weight1: [9.06918436]\t Weight2: [1.20285957]\t Bias: [2.62797261]\t Cost: 15.438428572283877\n",
            "Iteration: 2815\t Weight1: [9.06919257]\t Weight2: [1.20284588]\t Bias: [2.62796408]\t Cost: 15.438428555933816\n",
            "Iteration: 2816\t Weight1: [9.06920075]\t Weight2: [1.20283223]\t Bias: [2.62795557]\t Cost: 15.438428539668845\n",
            "Iteration: 2817\t Weight1: [9.06920892]\t Weight2: [1.20281862]\t Bias: [2.62794709]\t Cost: 15.438428523488511\n",
            "Iteration: 2818\t Weight1: [9.06921706]\t Weight2: [1.20280504]\t Bias: [2.62793863]\t Cost: 15.43842850739238\n",
            "Iteration: 2819\t Weight1: [9.06922518]\t Weight2: [1.20279149]\t Bias: [2.62793019]\t Cost: 15.438428491380026\n",
            "Iteration: 2820\t Weight1: [9.06923329]\t Weight2: [1.20277798]\t Bias: [2.62792178]\t Cost: 15.438428475451\n",
            "Iteration: 2821\t Weight1: [9.06924137]\t Weight2: [1.2027645]\t Bias: [2.62791338]\t Cost: 15.43842845960487\n",
            "Iteration: 2822\t Weight1: [9.06924943]\t Weight2: [1.20275106]\t Bias: [2.62790502]\t Cost: 15.438428443841186\n",
            "Iteration: 2823\t Weight1: [9.06925746]\t Weight2: [1.20273765]\t Bias: [2.62789667]\t Cost: 15.438428428159552\n",
            "Iteration: 2824\t Weight1: [9.06926548]\t Weight2: [1.20272427]\t Bias: [2.62788835]\t Cost: 15.438428412559524\n",
            "Iteration: 2825\t Weight1: [9.06927348]\t Weight2: [1.20271094]\t Bias: [2.62788005]\t Cost: 15.438428397040685\n",
            "Iteration: 2826\t Weight1: [9.06928146]\t Weight2: [1.20269763]\t Bias: [2.62787177]\t Cost: 15.438428381602598\n",
            "Iteration: 2827\t Weight1: [9.06928941]\t Weight2: [1.20268436]\t Bias: [2.62786352]\t Cost: 15.438428366244871\n",
            "Iteration: 2828\t Weight1: [9.06929735]\t Weight2: [1.20267112]\t Bias: [2.62785529]\t Cost: 15.438428350967026\n",
            "Iteration: 2829\t Weight1: [9.06930526]\t Weight2: [1.20265792]\t Bias: [2.62784708]\t Cost: 15.438428335768716\n",
            "Iteration: 2830\t Weight1: [9.06931315]\t Weight2: [1.20264475]\t Bias: [2.62783889]\t Cost: 15.438428320649495\n",
            "Iteration: 2831\t Weight1: [9.06932103]\t Weight2: [1.20263161]\t Bias: [2.62783072]\t Cost: 15.438428305608934\n",
            "Iteration: 2832\t Weight1: [9.06932888]\t Weight2: [1.20261851]\t Bias: [2.62782258]\t Cost: 15.438428290646671\n",
            "Iteration: 2833\t Weight1: [9.06933671]\t Weight2: [1.20260544]\t Bias: [2.62781446]\t Cost: 15.438428275762247\n",
            "Iteration: 2834\t Weight1: [9.06934453]\t Weight2: [1.20259241]\t Bias: [2.62780636]\t Cost: 15.438428260955288\n",
            "Iteration: 2835\t Weight1: [9.06935232]\t Weight2: [1.20257941]\t Bias: [2.62779829]\t Cost: 15.438428246225367\n",
            "Iteration: 2836\t Weight1: [9.06936009]\t Weight2: [1.20256644]\t Bias: [2.62779023]\t Cost: 15.438428231572107\n",
            "Iteration: 2837\t Weight1: [9.06936784]\t Weight2: [1.2025535]\t Bias: [2.6277822]\t Cost: 15.438428216995106\n",
            "Iteration: 2838\t Weight1: [9.06937557]\t Weight2: [1.2025406]\t Bias: [2.62777419]\t Cost: 15.438428202493956\n",
            "Iteration: 2839\t Weight1: [9.06938329]\t Weight2: [1.20252773]\t Bias: [2.6277662]\t Cost: 15.438428188068263\n",
            "Iteration: 2840\t Weight1: [9.06939098]\t Weight2: [1.2025149]\t Bias: [2.62775823]\t Cost: 15.438428173717652\n",
            "Iteration: 2841\t Weight1: [9.06939865]\t Weight2: [1.20250209]\t Bias: [2.62775029]\t Cost: 15.43842815944171\n",
            "Iteration: 2842\t Weight1: [9.0694063]\t Weight2: [1.20248932]\t Bias: [2.62774237]\t Cost: 15.438428145240058\n",
            "Iteration: 2843\t Weight1: [9.06941393]\t Weight2: [1.20247659]\t Bias: [2.62773446]\t Cost: 15.438428131112303\n",
            "Iteration: 2844\t Weight1: [9.06942155]\t Weight2: [1.20246388]\t Bias: [2.62772658]\t Cost: 15.438428117058063\n",
            "Iteration: 2845\t Weight1: [9.06942914]\t Weight2: [1.20245121]\t Bias: [2.62771873]\t Cost: 15.438428103076955\n",
            "Iteration: 2846\t Weight1: [9.06943671]\t Weight2: [1.20243857]\t Bias: [2.62771089]\t Cost: 15.438428089168607\n",
            "Iteration: 2847\t Weight1: [9.06944427]\t Weight2: [1.20242596]\t Bias: [2.62770307]\t Cost: 15.438428075332638\n",
            "Iteration: 2848\t Weight1: [9.0694518]\t Weight2: [1.20241339]\t Bias: [2.62769528]\t Cost: 15.43842806156865\n",
            "Iteration: 2849\t Weight1: [9.06945931]\t Weight2: [1.20240085]\t Bias: [2.6276875]\t Cost: 15.438428047876293\n",
            "Iteration: 2850\t Weight1: [9.06946681]\t Weight2: [1.20238834]\t Bias: [2.62767975]\t Cost: 15.438428034255187\n",
            "Iteration: 2851\t Weight1: [9.06947428]\t Weight2: [1.20237586]\t Bias: [2.62767202]\t Cost: 15.438428020704965\n",
            "Iteration: 2852\t Weight1: [9.06948174]\t Weight2: [1.20236341]\t Bias: [2.62766431]\t Cost: 15.438428007225228\n",
            "Iteration: 2853\t Weight1: [9.06948918]\t Weight2: [1.202351]\t Bias: [2.62765662]\t Cost: 15.438427993815655\n",
            "Iteration: 2854\t Weight1: [9.0694966]\t Weight2: [1.20233862]\t Bias: [2.62764895]\t Cost: 15.438427980475865\n",
            "Iteration: 2855\t Weight1: [9.06950399]\t Weight2: [1.20232627]\t Bias: [2.62764131]\t Cost: 15.438427967205467\n",
            "Iteration: 2856\t Weight1: [9.06951137]\t Weight2: [1.20231395]\t Bias: [2.62763368]\t Cost: 15.438427954004132\n",
            "Iteration: 2857\t Weight1: [9.06951873]\t Weight2: [1.20230166]\t Bias: [2.62762607]\t Cost: 15.438427940871492\n",
            "Iteration: 2858\t Weight1: [9.06952607]\t Weight2: [1.2022894]\t Bias: [2.62761849]\t Cost: 15.438427927807178\n",
            "Iteration: 2859\t Weight1: [9.0695334]\t Weight2: [1.20227718]\t Bias: [2.62761092]\t Cost: 15.43842791481086\n",
            "Iteration: 2860\t Weight1: [9.0695407]\t Weight2: [1.20226499]\t Bias: [2.62760338]\t Cost: 15.438427901882154\n",
            "Iteration: 2861\t Weight1: [9.06954798]\t Weight2: [1.20225282]\t Bias: [2.62759586]\t Cost: 15.438427889020728\n",
            "Iteration: 2862\t Weight1: [9.06955525]\t Weight2: [1.20224069]\t Bias: [2.62758836]\t Cost: 15.438427876226209\n",
            "Iteration: 2863\t Weight1: [9.06956249]\t Weight2: [1.20222859]\t Bias: [2.62758087]\t Cost: 15.438427863498287\n",
            "Iteration: 2864\t Weight1: [9.06956972]\t Weight2: [1.20221653]\t Bias: [2.62757341]\t Cost: 15.438427850836588\n",
            "Iteration: 2865\t Weight1: [9.06957693]\t Weight2: [1.20220449]\t Bias: [2.62756597]\t Cost: 15.438427838240758\n",
            "Iteration: 2866\t Weight1: [9.06958412]\t Weight2: [1.20219248]\t Bias: [2.62755855]\t Cost: 15.438427825710473\n",
            "Iteration: 2867\t Weight1: [9.06959129]\t Weight2: [1.20218051]\t Bias: [2.62755115]\t Cost: 15.438427813245406\n",
            "Iteration: 2868\t Weight1: [9.06959845]\t Weight2: [1.20216856]\t Bias: [2.62754377]\t Cost: 15.43842780084518\n",
            "Iteration: 2869\t Weight1: [9.06960558]\t Weight2: [1.20215665]\t Bias: [2.62753641]\t Cost: 15.438427788509474\n",
            "Iteration: 2870\t Weight1: [9.0696127]\t Weight2: [1.20214476]\t Bias: [2.62752906]\t Cost: 15.438427776237962\n",
            "Iteration: 2871\t Weight1: [9.06961979]\t Weight2: [1.20213291]\t Bias: [2.62752174]\t Cost: 15.438427764030305\n",
            "Iteration: 2872\t Weight1: [9.06962687]\t Weight2: [1.20212109]\t Bias: [2.62751444]\t Cost: 15.43842775188617\n",
            "Iteration: 2873\t Weight1: [9.06963393]\t Weight2: [1.20210929]\t Bias: [2.62750716]\t Cost: 15.438427739805205\n",
            "Iteration: 2874\t Weight1: [9.06964098]\t Weight2: [1.20209753]\t Bias: [2.6274999]\t Cost: 15.438427727787108\n",
            "Iteration: 2875\t Weight1: [9.069648]\t Weight2: [1.2020858]\t Bias: [2.62749266]\t Cost: 15.438427715831548\n",
            "Iteration: 2876\t Weight1: [9.06965501]\t Weight2: [1.2020741]\t Bias: [2.62748544]\t Cost: 15.438427703938196\n",
            "Iteration: 2877\t Weight1: [9.069662]\t Weight2: [1.20206243]\t Bias: [2.62747823]\t Cost: 15.438427692106725\n",
            "Iteration: 2878\t Weight1: [9.06966897]\t Weight2: [1.20205078]\t Bias: [2.62747105]\t Cost: 15.438427680336806\n",
            "Iteration: 2879\t Weight1: [9.06967592]\t Weight2: [1.20203917]\t Bias: [2.62746389]\t Cost: 15.438427668628137\n",
            "Iteration: 2880\t Weight1: [9.06968285]\t Weight2: [1.20202759]\t Bias: [2.62745675]\t Cost: 15.438427656980386\n",
            "Iteration: 2881\t Weight1: [9.06968977]\t Weight2: [1.20201604]\t Bias: [2.62744962]\t Cost: 15.438427645393245\n",
            "Iteration: 2882\t Weight1: [9.06969666]\t Weight2: [1.20200451]\t Bias: [2.62744252]\t Cost: 15.438427633866391\n",
            "Iteration: 2883\t Weight1: [9.06970354]\t Weight2: [1.20199302]\t Bias: [2.62743543]\t Cost: 15.438427622399502\n",
            "Iteration: 2884\t Weight1: [9.06971041]\t Weight2: [1.20198156]\t Bias: [2.62742837]\t Cost: 15.438427610992294\n",
            "Iteration: 2885\t Weight1: [9.06971725]\t Weight2: [1.20197012]\t Bias: [2.62742132]\t Cost: 15.438427599644418\n",
            "Iteration: 2886\t Weight1: [9.06972408]\t Weight2: [1.20195872]\t Bias: [2.62741429]\t Cost: 15.4384275883556\n",
            "Iteration: 2887\t Weight1: [9.06973089]\t Weight2: [1.20194734]\t Bias: [2.62740728]\t Cost: 15.438427577125509\n",
            "Iteration: 2888\t Weight1: [9.06973768]\t Weight2: [1.20193599]\t Bias: [2.62740029]\t Cost: 15.438427565953853\n",
            "Iteration: 2889\t Weight1: [9.06974445]\t Weight2: [1.20192468]\t Bias: [2.62739332]\t Cost: 15.438427554840327\n",
            "Iteration: 2890\t Weight1: [9.06975121]\t Weight2: [1.20191339]\t Bias: [2.62738637]\t Cost: 15.438427543784618\n",
            "Iteration: 2891\t Weight1: [9.06975795]\t Weight2: [1.20190213]\t Bias: [2.62737944]\t Cost: 15.438427532786438\n",
            "Iteration: 2892\t Weight1: [9.06976467]\t Weight2: [1.2018909]\t Bias: [2.62737252]\t Cost: 15.43842752184546\n",
            "Iteration: 2893\t Weight1: [9.06977137]\t Weight2: [1.2018797]\t Bias: [2.62736563]\t Cost: 15.438427510961423\n",
            "Iteration: 2894\t Weight1: [9.06977806]\t Weight2: [1.20186852]\t Bias: [2.62735875]\t Cost: 15.438427500134015\n",
            "Iteration: 2895\t Weight1: [9.06978473]\t Weight2: [1.20185738]\t Bias: [2.62735189]\t Cost: 15.43842748936294\n",
            "Iteration: 2896\t Weight1: [9.06979138]\t Weight2: [1.20184626]\t Bias: [2.62734505]\t Cost: 15.438427478647903\n",
            "Iteration: 2897\t Weight1: [9.06979801]\t Weight2: [1.20183518]\t Bias: [2.62733823]\t Cost: 15.438427467988616\n",
            "Iteration: 2898\t Weight1: [9.06980463]\t Weight2: [1.20182412]\t Bias: [2.62733143]\t Cost: 15.438427457384787\n",
            "Iteration: 2899\t Weight1: [9.06981123]\t Weight2: [1.20181309]\t Bias: [2.62732465]\t Cost: 15.438427446836133\n",
            "Iteration: 2900\t Weight1: [9.06981782]\t Weight2: [1.20180208]\t Bias: [2.62731788]\t Cost: 15.438427436342357\n",
            "Iteration: 2901\t Weight1: [9.06982438]\t Weight2: [1.20179111]\t Bias: [2.62731114]\t Cost: 15.438427425903178\n",
            "Iteration: 2902\t Weight1: [9.06983093]\t Weight2: [1.20178017]\t Bias: [2.62730441]\t Cost: 15.43842741551831\n",
            "Iteration: 2903\t Weight1: [9.06983746]\t Weight2: [1.20176925]\t Bias: [2.6272977]\t Cost: 15.438427405187474\n",
            "Iteration: 2904\t Weight1: [9.06984398]\t Weight2: [1.20175836]\t Bias: [2.62729101]\t Cost: 15.438427394910399\n",
            "Iteration: 2905\t Weight1: [9.06985048]\t Weight2: [1.2017475]\t Bias: [2.62728433]\t Cost: 15.438427384686774\n",
            "Iteration: 2906\t Weight1: [9.06985696]\t Weight2: [1.20173666]\t Bias: [2.62727768]\t Cost: 15.43842737451635\n",
            "Iteration: 2907\t Weight1: [9.06986342]\t Weight2: [1.20172586]\t Bias: [2.62727104]\t Cost: 15.438427364398827\n",
            "Iteration: 2908\t Weight1: [9.06986987]\t Weight2: [1.20171508]\t Bias: [2.62726442]\t Cost: 15.438427354333964\n",
            "Iteration: 2909\t Weight1: [9.0698763]\t Weight2: [1.20170433]\t Bias: [2.62725782]\t Cost: 15.43842734432145\n",
            "Iteration: 2910\t Weight1: [9.06988272]\t Weight2: [1.20169361]\t Bias: [2.62725124]\t Cost: 15.43842733436104\n",
            "Iteration: 2911\t Weight1: [9.06988911]\t Weight2: [1.20168291]\t Bias: [2.62724467]\t Cost: 15.438427324452428\n",
            "Iteration: 2912\t Weight1: [9.0698955]\t Weight2: [1.20167224]\t Bias: [2.62723812]\t Cost: 15.43842731459539\n",
            "Iteration: 2913\t Weight1: [9.06990186]\t Weight2: [1.2016616]\t Bias: [2.62723159]\t Cost: 15.438427304789634\n",
            "Iteration: 2914\t Weight1: [9.06990821]\t Weight2: [1.20165099]\t Bias: [2.62722508]\t Cost: 15.438427295034876\n",
            "Iteration: 2915\t Weight1: [9.06991454]\t Weight2: [1.2016404]\t Bias: [2.62721859]\t Cost: 15.438427285330887\n",
            "Iteration: 2916\t Weight1: [9.06992086]\t Weight2: [1.20162984]\t Bias: [2.62721211]\t Cost: 15.438427275677371\n",
            "Iteration: 2917\t Weight1: [9.06992716]\t Weight2: [1.20161931]\t Bias: [2.62720565]\t Cost: 15.438427266074076\n",
            "Iteration: 2918\t Weight1: [9.06993344]\t Weight2: [1.20160881]\t Bias: [2.62719921]\t Cost: 15.438427256520757\n",
            "Iteration: 2919\t Weight1: [9.0699397]\t Weight2: [1.20159833]\t Bias: [2.62719278]\t Cost: 15.438427247017128\n",
            "Iteration: 2920\t Weight1: [9.06994596]\t Weight2: [1.20158788]\t Bias: [2.62718638]\t Cost: 15.438427237562953\n",
            "Iteration: 2921\t Weight1: [9.06995219]\t Weight2: [1.20157746]\t Bias: [2.62717999]\t Cost: 15.438427228157947\n",
            "Iteration: 2922\t Weight1: [9.06995841]\t Weight2: [1.20156706]\t Bias: [2.62717361]\t Cost: 15.438427218801884\n",
            "Iteration: 2923\t Weight1: [9.06996461]\t Weight2: [1.20155669]\t Bias: [2.62716726]\t Cost: 15.438427209494487\n",
            "Iteration: 2924\t Weight1: [9.06997079]\t Weight2: [1.20154635]\t Bias: [2.62716092]\t Cost: 15.43842720023551\n",
            "Iteration: 2925\t Weight1: [9.06997696]\t Weight2: [1.20153603]\t Bias: [2.6271546]\t Cost: 15.438427191024726\n",
            "Iteration: 2926\t Weight1: [9.06998312]\t Weight2: [1.20152574]\t Bias: [2.6271483]\t Cost: 15.438427181861838\n",
            "Iteration: 2927\t Weight1: [9.06998926]\t Weight2: [1.20151547]\t Bias: [2.62714201]\t Cost: 15.438427172746616\n",
            "Iteration: 2928\t Weight1: [9.06999538]\t Weight2: [1.20150524]\t Bias: [2.62713574]\t Cost: 15.438427163678826\n",
            "Iteration: 2929\t Weight1: [9.07000148]\t Weight2: [1.20149502]\t Bias: [2.62712949]\t Cost: 15.43842715465821\n",
            "Iteration: 2930\t Weight1: [9.07000757]\t Weight2: [1.20148484]\t Bias: [2.62712326]\t Cost: 15.438427145684525\n",
            "Iteration: 2931\t Weight1: [9.07001365]\t Weight2: [1.20147468]\t Bias: [2.62711704]\t Cost: 15.438427136757513\n",
            "Iteration: 2932\t Weight1: [9.07001971]\t Weight2: [1.20146455]\t Bias: [2.62711084]\t Cost: 15.438427127876947\n",
            "Iteration: 2933\t Weight1: [9.07002575]\t Weight2: [1.20145444]\t Bias: [2.62710465]\t Cost: 15.438427119042592\n",
            "Iteration: 2934\t Weight1: [9.07003178]\t Weight2: [1.20144436]\t Bias: [2.62709848]\t Cost: 15.438427110254183\n",
            "Iteration: 2935\t Weight1: [9.07003779]\t Weight2: [1.2014343]\t Bias: [2.62709233]\t Cost: 15.438427101511502\n",
            "Iteration: 2936\t Weight1: [9.07004379]\t Weight2: [1.20142427]\t Bias: [2.6270862]\t Cost: 15.438427092814296\n",
            "Iteration: 2937\t Weight1: [9.07004977]\t Weight2: [1.20141427]\t Bias: [2.62708008]\t Cost: 15.438427084162353\n",
            "Iteration: 2938\t Weight1: [9.07005573]\t Weight2: [1.20140429]\t Bias: [2.62707398]\t Cost: 15.4384270755554\n",
            "Iteration: 2939\t Weight1: [9.07006168]\t Weight2: [1.20139434]\t Bias: [2.6270679]\t Cost: 15.438427066993233\n",
            "Iteration: 2940\t Weight1: [9.07006761]\t Weight2: [1.20138441]\t Bias: [2.62706183]\t Cost: 15.43842705847561\n",
            "Iteration: 2941\t Weight1: [9.07007353]\t Weight2: [1.20137451]\t Bias: [2.62705578]\t Cost: 15.438427050002288\n",
            "Iteration: 2942\t Weight1: [9.07007944]\t Weight2: [1.20136464]\t Bias: [2.62704974]\t Cost: 15.43842704157305\n",
            "Iteration: 2943\t Weight1: [9.07008533]\t Weight2: [1.20135479]\t Bias: [2.62704372]\t Cost: 15.438427033187658\n",
            "Iteration: 2944\t Weight1: [9.0700912]\t Weight2: [1.20134496]\t Bias: [2.62703772]\t Cost: 15.438427024845904\n",
            "Iteration: 2945\t Weight1: [9.07009706]\t Weight2: [1.20133516]\t Bias: [2.62703173]\t Cost: 15.438427016547529\n",
            "Iteration: 2946\t Weight1: [9.0701029]\t Weight2: [1.20132539]\t Bias: [2.62702576]\t Cost: 15.438427008292347\n",
            "Iteration: 2947\t Weight1: [9.07010873]\t Weight2: [1.20131564]\t Bias: [2.62701981]\t Cost: 15.43842700008008\n",
            "Iteration: 2948\t Weight1: [9.07011454]\t Weight2: [1.20130591]\t Bias: [2.62701387]\t Cost: 15.438426991910557\n",
            "Iteration: 2949\t Weight1: [9.07012034]\t Weight2: [1.20129621]\t Bias: [2.62700795]\t Cost: 15.43842698378353\n",
            "Iteration: 2950\t Weight1: [9.07012612]\t Weight2: [1.20128654]\t Bias: [2.62700204]\t Cost: 15.438426975698775\n",
            "Iteration: 2951\t Weight1: [9.07013188]\t Weight2: [1.20127689]\t Bias: [2.62699615]\t Cost: 15.438426967656081\n",
            "Iteration: 2952\t Weight1: [9.07013764]\t Weight2: [1.20126727]\t Bias: [2.62699028]\t Cost: 15.438426959655224\n",
            "Iteration: 2953\t Weight1: [9.07014337]\t Weight2: [1.20125767]\t Bias: [2.62698442]\t Cost: 15.438426951695991\n",
            "Iteration: 2954\t Weight1: [9.0701491]\t Weight2: [1.20124809]\t Bias: [2.62697858]\t Cost: 15.438426943778154\n",
            "Iteration: 2955\t Weight1: [9.0701548]\t Weight2: [1.20123854]\t Bias: [2.62697275]\t Cost: 15.438426935901516\n",
            "Iteration: 2956\t Weight1: [9.0701605]\t Weight2: [1.20122901]\t Bias: [2.62696694]\t Cost: 15.438426928065848\n",
            "Iteration: 2957\t Weight1: [9.07016618]\t Weight2: [1.20121951]\t Bias: [2.62696115]\t Cost: 15.438426920270958\n",
            "Iteration: 2958\t Weight1: [9.07017184]\t Weight2: [1.20121003]\t Bias: [2.62695537]\t Cost: 15.438426912516595\n",
            "Iteration: 2959\t Weight1: [9.07017749]\t Weight2: [1.20120058]\t Bias: [2.62694961]\t Cost: 15.438426904802572\n",
            "Iteration: 2960\t Weight1: [9.07018312]\t Weight2: [1.20119115]\t Bias: [2.62694386]\t Cost: 15.438426897128677\n",
            "Iteration: 2961\t Weight1: [9.07018874]\t Weight2: [1.20118175]\t Bias: [2.62693813]\t Cost: 15.438426889494714\n",
            "Iteration: 2962\t Weight1: [9.07019435]\t Weight2: [1.20117237]\t Bias: [2.62693241]\t Cost: 15.438426881900462\n",
            "Iteration: 2963\t Weight1: [9.07019994]\t Weight2: [1.20116301]\t Bias: [2.62692671]\t Cost: 15.438426874345707\n",
            "Iteration: 2964\t Weight1: [9.07020551]\t Weight2: [1.20115368]\t Bias: [2.62692103]\t Cost: 15.438426866830252\n",
            "Iteration: 2965\t Weight1: [9.07021107]\t Weight2: [1.20114437]\t Bias: [2.62691536]\t Cost: 15.438426859353905\n",
            "Iteration: 2966\t Weight1: [9.07021662]\t Weight2: [1.20113509]\t Bias: [2.6269097]\t Cost: 15.438426851916429\n",
            "Iteration: 2967\t Weight1: [9.07022215]\t Weight2: [1.20112583]\t Bias: [2.62690406]\t Cost: 15.438426844517663\n",
            "Iteration: 2968\t Weight1: [9.07022767]\t Weight2: [1.20111659]\t Bias: [2.62689844]\t Cost: 15.438426837157373\n",
            "Iteration: 2969\t Weight1: [9.07023317]\t Weight2: [1.20110738]\t Bias: [2.62689283]\t Cost: 15.438426829835366\n",
            "Iteration: 2970\t Weight1: [9.07023866]\t Weight2: [1.20109819]\t Bias: [2.62688723]\t Cost: 15.438426822551461\n",
            "Iteration: 2971\t Weight1: [9.07024414]\t Weight2: [1.20108902]\t Bias: [2.62688166]\t Cost: 15.438426815305432\n",
            "Iteration: 2972\t Weight1: [9.0702496]\t Weight2: [1.20107988]\t Bias: [2.62687609]\t Cost: 15.438426808097102\n",
            "Iteration: 2973\t Weight1: [9.07025505]\t Weight2: [1.20107076]\t Bias: [2.62687054]\t Cost: 15.438426800926266\n",
            "Iteration: 2974\t Weight1: [9.07026048]\t Weight2: [1.20106167]\t Bias: [2.62686501]\t Cost: 15.43842679379274\n",
            "Iteration: 2975\t Weight1: [9.0702659]\t Weight2: [1.20105259]\t Bias: [2.62685949]\t Cost: 15.438426786696311\n",
            "Iteration: 2976\t Weight1: [9.07027131]\t Weight2: [1.20104355]\t Bias: [2.62685399]\t Cost: 15.438426779636796\n",
            "Iteration: 2977\t Weight1: [9.0702767]\t Weight2: [1.20103452]\t Bias: [2.6268485]\t Cost: 15.438426772614017\n",
            "Iteration: 2978\t Weight1: [9.07028207]\t Weight2: [1.20102552]\t Bias: [2.62684303]\t Cost: 15.438426765627758\n",
            "Iteration: 2979\t Weight1: [9.07028744]\t Weight2: [1.20101654]\t Bias: [2.62683757]\t Cost: 15.438426758677842\n",
            "Iteration: 2980\t Weight1: [9.07029278]\t Weight2: [1.20100758]\t Bias: [2.62683212]\t Cost: 15.438426751764089\n",
            "Iteration: 2981\t Weight1: [9.07029812]\t Weight2: [1.20099865]\t Bias: [2.62682669]\t Cost: 15.438426744886282\n",
            "Iteration: 2982\t Weight1: [9.07030344]\t Weight2: [1.20098974]\t Bias: [2.62682128]\t Cost: 15.438426738044262\n",
            "Iteration: 2983\t Weight1: [9.07030875]\t Weight2: [1.20098085]\t Bias: [2.62681588]\t Cost: 15.438426731237827\n",
            "Iteration: 2984\t Weight1: [9.07031404]\t Weight2: [1.20097199]\t Bias: [2.62681049]\t Cost: 15.438426724466785\n",
            "Iteration: 2985\t Weight1: [9.07031932]\t Weight2: [1.20096315]\t Bias: [2.62680512]\t Cost: 15.438426717730987\n",
            "Iteration: 2986\t Weight1: [9.07032459]\t Weight2: [1.20095433]\t Bias: [2.62679977]\t Cost: 15.438426711030216\n",
            "Iteration: 2987\t Weight1: [9.07032984]\t Weight2: [1.20094554]\t Bias: [2.62679442]\t Cost: 15.438426704364305\n",
            "Iteration: 2988\t Weight1: [9.07033508]\t Weight2: [1.20093676]\t Bias: [2.6267891]\t Cost: 15.438426697733066\n",
            "Iteration: 2989\t Weight1: [9.07034031]\t Weight2: [1.20092801]\t Bias: [2.62678378]\t Cost: 15.43842669113633\n",
            "Iteration: 2990\t Weight1: [9.07034552]\t Weight2: [1.20091928]\t Bias: [2.62677849]\t Cost: 15.43842668457389\n",
            "Iteration: 2991\t Weight1: [9.07035072]\t Weight2: [1.20091058]\t Bias: [2.6267732]\t Cost: 15.4384266780456\n",
            "Iteration: 2992\t Weight1: [9.0703559]\t Weight2: [1.20090189]\t Bias: [2.62676793]\t Cost: 15.438426671551257\n",
            "Iteration: 2993\t Weight1: [9.07036107]\t Weight2: [1.20089323]\t Bias: [2.62676268]\t Cost: 15.438426665090713\n",
            "Iteration: 2994\t Weight1: [9.07036623]\t Weight2: [1.2008846]\t Bias: [2.62675743]\t Cost: 15.43842665866376\n",
            "Iteration: 2995\t Weight1: [9.07037138]\t Weight2: [1.20087598]\t Bias: [2.62675221]\t Cost: 15.43842665227023\n",
            "Iteration: 2996\t Weight1: [9.07037651]\t Weight2: [1.20086738]\t Bias: [2.62674699]\t Cost: 15.438426645909962\n",
            "Iteration: 2997\t Weight1: [9.07038163]\t Weight2: [1.20085881]\t Bias: [2.62674179]\t Cost: 15.438426639582783\n",
            "Iteration: 2998\t Weight1: [9.07038673]\t Weight2: [1.20085026]\t Bias: [2.62673661]\t Cost: 15.438426633288516\n",
            "Iteration: 2999\t Weight1: [9.07039182]\t Weight2: [1.20084173]\t Bias: [2.62673144]\t Cost: 15.438426627026985\n",
            "Weight2: [1.20084173]Weight1: [9.07039182] Bias: [2.62673144]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfkv905tVI5t",
        "colab_type": "code",
        "outputId": "351efc16-5270-4fcc-d2ef-1754b2264aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.scatter(X_train, y_train, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train, z_train), color='blue')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f79a1d4e5c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5hd873H8fdXIlchIiMNQVxDiAhD\nXOIaUbdKjtLSlrhU3AWlOLQ9Ws6hx109KgTT0pAmCIqTiBCiQm7ITRISJE0yI3KRIJeZ7/njt6Zk\nsvfMnpm999prz+f1PPPM3nutvdf3YfKZ3/zW72LujoiIJM9mcRcgIiINowAXEUkoBbiISEIpwEVE\nEkoBLiKSUM3zebGOHTt6165d83lJEZHEmzx58hfuXlLz9bwGeNeuXZk0aVI+Lykiknhm9mmq19WF\nIiKSUApwEZGEUoCLiCSUAlxEJKEU4CIiCaUAFxFJKAW4iEh9vf46jB0LMa/mqgAXEamPoUPhpJPg\nlFPggQdiLSWvE3lERBJvyhT49tvQ+p48OdZSFOAiIvVx7bUwYQJUVsKNN8ZaigJcRKQ+unaFadPi\nrgJQH7iISGIpwEVEEkoBLiKSUApwEZEcmj0b3n03N5+tm5giIjngDv37wwsvhOdVVWCW3WsowEVE\nsuzDD2Hffb97/txz2Q9vyLALxcwGm9l0M5thZldGr3UwszFmNjf6vnX2yxMRSQ53OPXU78K7pATW\nrg0t8VyoM8DNbB/gAuAgoCdwspntBlwPjHX33YGx0XMRkSZp+nTYbDN49tnwfORIKC+HFi1yd81M\nWuB7ARPd/Wt33wC8AZwK9AfKonPKgAG5KVFEpHC5w+mnQ48e4XmHDmGm/amn5v7amQT4dOBwM9vG\nzNoAJwI7AJ3cfXF0zhKgU6o3m9kgM5tkZpMqKiqyUrSISCGYMSO0ukeMCM+HD4dly6Bly/xcv86b\nmO4+y8xuB0YDa4BpQGWNc9zMUq6r6O5DgCEApaWl8a69KCLSSIsXw957w/Ll37225ZawdCm0apXf\nWjK6ienuQ939AHc/AlgOzAGWmllngOh7ee7KFBGJ3+WXw3bbbRzew4bBypX5D2/IcBihmW3r7uVm\ntiOh//tgYGdgIHBb9H1UzqoUEYnRrFnQvfvGr7VtG25StmlTx5vnz4ePPoJjjsn6Hc1MZ2KONLOZ\nwAvApe6+ghDc/cxsLnBs9FxEpGi4wwknbBreTzwBq1dnEN4ffxzubp52WrjTmWUZtcDd/fAUry0D\n+ma9IhGRAjB+PBx55MavtWgBX34ZWt8ZmTUrfF+zBiZOzGp9oLVQREQ2sn497L77puFdVhYm5WQc\n3gD9+kGfPtCxI9xzT1brBE2lFxH5t+HD4ac/3fi1Zs3CTct27RrwgS1bwiuvZKW2VNQCF5Em76uv\nwlolNcN76FDYsKGB4Z0HCnARadLuuiuM465pxQo477z811Mf6kIRkSZp8eIwprumhx6CQYPyX09D\nqAUuIvGZNw+6dYNevcJUxjypnpBT07JlyQlvUICLSJwefRTmzg3D7aoXFMmhmTNDX/ef/rTx6w88\nEMZ8d+iQ8xKySgEuIvE58cQwUmPzzeHoo3N2Gfdwqb333vRYRQVccknOLp1T6gMXkfj06QNffBHG\n6uVoMZFUE3KqPfxwGKKdVApwEYlXvWbGZG7dOthnn9BDk8rChbD99jm5dN6oC0VEis7w4aFnJlV4\nV/d3Jz28QS1wESkiq1ZB+/YhoFP55pt4ln3NFbXARaQo3HUXbLVV6vAeNy68XkzhDWqBi0jCpZuQ\nA+Ee6fjxYehgMVILXEQSyR2uuCJ9eC/4uJI3yz7BqipTn1AEFOAikjgzZ4bNhO+/f9Njt9wSwn2n\nc4+BvfaCk07Kf4F5kumWalcBvwQc+BA4F+gMPAVsA0wGznL3dTmqU0SEqir40Y/gpZdSH1+9OhqV\n6A5vvRXe8Prr+Swxr+psgZvZ9sAVQKm77wM0A84AbgfudvfdCBsdn5/LQkWkaRs/Psz3SRXer7wS\nMvvfQ8rNwl3NXXaBe+/Na535lGkXSnOgtZk1B9oAi4FjgOrFC8qAAdkvT0SaurVrw3pXqWZT7rZb\naGT/8Icp3jh4cNiT8sILc15jXOoMcHdfBNwBfEYI7pWELpMV7r4hOm0hkHJYvJkNMrNJZjapoqIi\nO1WLSJPw9NNh6N+cOZsemzs3fBXrCJNMZNKFsjXQH9gZ2A5oCxyf6QXcfYi7l7p7aUlJSYMLFZGm\nY+XK0F1yxhmbHrvsstBdsttu+a+r0GTShXIsMN/dK9x9PfAMcBjQPupSAegCLMpRjSLShNx5Z5hN\nWVW16bGVK1OPPGmqMgnwz4CDzayNmRnQF5gJjANOi84ZCIzKTYki0hQsWhS6Q665ZtNjZWWh1Z1q\n67OmLJM+8ImEm5VTCEMINwOGANcBV5vZPMJQwqE5rFNEipR72CGnS5fUxysr4eyz81tTUmQ0Dtzd\nfwf8rsbLnwAHZb0iEWkyZswIS76m8vbbcMgh+a0nabQWiojkXWUl7L8/fPDBpsd69oRp0/JfUxIp\nwEUkr954A446KvWxBQtgp53yWU2yaS0UEcmLb78NNylThfcFF0Trlyi860UBLiI59+ij0Lp16mNf\nfglDhuS3nmKhABeRnFmxIrS6z0+xUtKdd4ZW99Zb578uNmwIBdx9d3icUOoDF5GcuOgieOih1MdW\nrYJ27fJbz0YeeQRuuin8dtlii9CHk0AKcBHJqs8+S9+XPXw4nH56futJqW3bsKB49eOEUoCLSFa4\nQ9euIcBrat8ePv88NHYLwi9+ETrlzeDUU+OupsEU4CLSaG++CUcckfrYq69C3775radOZnDaaXWf\nV+AU4CLSYOvXQ4sWqY8deiiMHp3oHoqCp1EoItIg992XPrzHj4cJExTeuaYWuIjUy8qVoU87lTPP\nDAM82rTJb01NlVrgIpKxk05KH94TJsDf/qbwzicFuIjUadascN8v1YbCl10GX38d+rwlv9SFIiJp\nuX83XDoVLfkar0z2xOxmZtO+97XKzK40sw5mNsbM5kbf45gQKyI58tRT6cP72mtDq1vhHa86W+Du\n/hGwH4CZNSPsffkscD0w1t1vM7Pro+fX5bBWEcmDNWvST7hp1w7GjIHevfNbk6RW3z7wvsDH7v4p\nYaf6suj1MmBANgsTkfwbNCh9eN9wA5SXK7wLSX37wM8AhkWPO7n74ujxEqBTqjeY2SBgEMCOO+7Y\nkBpFJMfmzIFu3VIf22WX0J1y4IH5rUnqlnEL3MxaAKcAf695zN0d8FTvc/ch7l7q7qUlJSUNLlRE\nsq+yEjp0SB/eN94IM2cqvAtVfbpQTgCmuPvS6PlSM+sMEH0vz3ZxIpI7zzwDzZvD8uWbHttnH5g0\nCW65BVq2zH9tkpn6BPiZfNd9AvA8MDB6PBAYla2iRCR3Vq4MY7p//OPUx3/7W5g8GQ44IL91Sf1l\nFOBm1hboBzzzvZdvA/qZ2Vzg2Oi5iBQod7jiivQzKXv2hClT4Oab069xIoUlo5uY7r4G2KbGa8sI\no1JEpMDNnAl7753++M03w/XXK7iTRlPpRQrJ8uVh8ezLLsvKx61bF0aRpAvvXr1g2rTQbaLwTh4F\nuEghefPN8PXAA2FGTSM8/XS4ATl//qbHmjWDP/wBJk4MXSeSTFoLRaSQ/PCHcPnlYVxfAxfTLi+H\nTilnZQT77w+PPw49ejSsRCkcaoGLFJKWLeHOO8OUyHqqqoJLL00f3i1awK23wjvvKLyLhVrgIkVg\n0qTaJ9sceCA89ljtNzIledQCF0mwNWvCTcp04d2iBdx2W1j2VeFdfBTgIgk1dGhYeCrVTUoIi05N\nnQrXXRdmXErx0f9WkYT57DPYaaf0x1u2DFPgr7oqjDaR4qUWuEhCbNgA555be3gfckgY133NNQrv\npkAtcJEEGDcOjjkm/fFWrcIIk8GDFdxNiQJcpIAtXw7du8OSJenPOewwePRR2GOP/NUlhUFdKCIF\nyD0MB+/QIXV4t2kDrVvDPffAG28ovJsqtcBFCszs2bDXXqmPdeoES5eGpV4ffRR22y2/tUlhUQtc\npEB8+y0MGJA6vFu1gi23hK++gvvug9dfV3iLAlykIIwaFbpERqXYFqVnzxDuvXrBBx+EpVI2079c\nIfMNHdqb2Qgzm21ms8zsEDPrYGZjzGxu9H3rXBcrUmyWLAmt6wEDNj12yCHQrh3MmxcWJ3ztNdh1\n1/zXKIUr09/j9wKvuPueQE9gFnA9MNbddwfGRs9FJAOVlXDTTdC5M6xdu+nxww+Hf/4TSkvhww/h\nkkvU6pZN1fkjYWZbAUcAQwHcfZ27rwD6A2XRaWVAijaESJG6+OJwR/Hll+v91smTw9T2W2/d9NjJ\nJ4cRJlOnwoMPwquvws47Z6FeKUqZ/E7fGagAHjOzqWb2SLRHZid3XxydswRIuYilmQ0ys0lmNqmi\noiI7VYvEqbIS/vznsPD2vfdm/LavvoIjjwyt6pq22CIE9YsvwvHHw/TpcNFFanVL7TL58WgO7A88\n6O69gDXU6C5xdwc81ZvdfYi7l7p7aUlJSWPrFYlfs2ZhD7I99wz9IHVwh7KyMIpk/PhNj/foAatX\nh77wMWNg5Mjap8uLVMskwBcCC919YvR8BCHQl5pZZ4Doe3luShQpQDffDLNmQZ8+tZ62YEFoRZ9z\nzqbHWrcOXSmffgp33w3vvw/HHpuTaqVI1Rng7r4E+NzMukUv9QVmAs8DA6PXBgIpBkCJNE3r14d9\nidP1X7dvD998A2edBXPmwJVXwuab57dGSb5MZ2JeDjxpZi2AT4BzCeE/3MzOBz4FfpKbEkWS5fXX\n4eijaz9njz3g/vvhoIPyUpIUqYwC3N2nASluvdA3u+WIJNcXX4SblDNnpj9n223DDjkDB+oGpTSe\nfoREGsk9TG8vKUkf3s2bhw0W5swJa3orvCUbtJiVSCPMnFn3XpPHHhtGG3bvnp+apOlQO0CkAb7+\nGn72s9rDu2tXeOYZGD1a4S25oRa4SD2NGAGnn57+eKtWcMMNcO21YaigSK4owEUytGgRdOlS+zk/\n/nHYiEETcSQf1IUiUocNG+BXv6o9vLt3D+uWjBih8Jb8UQtcpBbvvgu9e6c/vtVWYVLmJZdoIo7k\nn1rgUlxWr4YVKxr9MStXho0Uagvv888PwwIHD1Z4SzwU4FI8Vq2CHXYIfR2ff96gj3CHv/41THX/\n4IPU5/TuHVrmjzwSJuaIxEVdKFI81q0LuyO4hz3I6mnePNh99/THt9kG7rgDzj5bE3GkMOjHUIpH\nx45hIe2pU2tP4hrWrg2zJGt7y9VXw8cfh1UFFd5SKNQCl+Kyyy71Ov2116BvLSv69OsXZlGm2ile\nJG4KcGmSKirCzjdTpqQ+vtlmYWOF/v3BLL+1iWRKfwxKk+IODz0Ubj6mC+/f/z4MZhkwQOEthU0t\ncGkyPvoo7IKWzgknhI2ENRFHkkItcCl6a9fCFVfUHt5jx8JLLym8JVkyaoGb2QLgK6AS2ODupWbW\nAXga6AosAH7i7stzU6ZIw9S1O85dd8Hll4f1ukWSpj4t8KPdfT93r96Z53pgrLvvDoylxk71InFa\ntixsV5YuvHv0gPLyMHxQ4S1J1ZgulP5AWfS4DBjQ+HJEGsc9zJDs2BHeey/1Oe+9F2ZZlpTktzaR\nbMs0wB0YbWaTzWxQ9Fond18cPV4CdEr1RjMbZGaTzGxSRUVFI8sVSW/u3DD874ILUh+/+WaorITS\nVLu7iiRQpn889nH3RWa2LTDGzGZ//6C7u5l5qje6+xBgCEBpaWnKc0QaY926sHnCffelP2flSthy\ny/zVJJIPGbXA3X1R9L0ceBY4CFhqZp0Bou/luSpSJJ0334SWLdOH99tvh24VhbcUozoD3Mzamlm7\n6sfAccB04HlgYHTaQGBUrooUqWn58tAVcsQRqY//5CdQVQWHHJLfukTyKZMulE7AsxampDUH/ubu\nr5jZe8BwMzsf+BT4Se7KFAnc4fHH4bzz0p/z5Zew9dZ5K0kkNnUGuLt/AvRM8foyoJZlgESy65NP\nYNdd0x9/9tkw/T1jX34Z7nwedJDmzEsiaSamFLz168OuN+nCe7vtwuiSeoV3VVUYDH700fCb32Sl\nTpF80xQGKWhvvw2HHZb++KJFIcDrrbIydKRXVoYPEUkgtcClIK1YAb16pQ/vP/4x9Ic3KLwhbGL5\n1lvwv/8bFvwWSSC1wKWgVO9JOXBg+nO+/TYMHWy0/fcPXyIJpQCXgrFgAey8c/rjkycrb0W+T10o\nErsNG8Jyr+nC+7TTwj1HhbfIxtQCl1hNnAgHH5z+eEVFWJhKRDalFrjEYtWqMIovXXiXlYX+cIW3\nSHpqgUteucMTT8DZZ6c+3qZNGIGy+eb5rUskiRTgkjeffw477pj++NSpsN9++atHJOnUhSI5V1kZ\nti1LF97nnBNuUiq8RepHLXDJqffeC0uNpPPFF7DNNvmrR6SYqAXelEyeDJ06wUUX5fxSq1dDt27p\nw/svfwn94QpvkYZTgDclb70Vdvt97rmcXubJJ6FdO5gzZ9NjW20VFqc666ycliDSJKgLpSkZNCgs\nm9qnT04+ftEi6NIl/fFp06DnJgsT12HdOhgypPaFUUSaqIxb4GbWzMymmtmL0fOdzWyimc0zs6fN\nrEXuypSsaN06THnM8pTGykq45JL04T1wYOguqXd4AwwbBlddBccd16gaRYpRfVrgg4FZQPXugrcD\nd7v7U2b2Z+B84MEs1ycFbsoUOOCA9MeXLYMOHRpxgd69Q7/9kUc24kNEilNGLXAz6wKcBDwSPTfg\nGGBEdEoZUJ/l9CXh1qwJa5ekC+/qmZSNCm+APfeEhQtDx7qIbCTTFvg9wK+BdtHzbYAV7r4her4Q\n2D7VG81sEDAIYMfaZnFIYjzxRPqbkG3bwsqV0KxZfmsSaYoy2ZX+ZKDc3Sc35ALuPsTdS929tKSk\npCEfIQVi8eJwDzRdeE+bFoYPKrxF8iOTLpTDgFPMbAHwFKHr5F6gvZlVt+C7ANqXqkhVVYUBLOl2\nvzn77EbcpBSRBstkV/obgBsAzOwo4Bp3/7mZ/R04jRDqA4FROaxTYjJ1au2DVhp9k1JEGqwxE3mu\nA642s3mEPvGh2SlJCsHXX8MPfpA+vB9/PEs3KUWkweo1kcfdXwdejx5/AtSyyoUk1V/+kn5Pys02\nC3Nr1M8tEj/NxJR/W7o0tLrTadBMShHJGa2FIlRVhSVd04X3mWfqJqVIIVILvInTTUqR5FILvIn6\n9lvYeuv04f3oo7pJKVLo1AJvgh5/HM49N/3x9euhuX4yRAqe/pk2IRUVsO226Y9rT0qRZFEXShPg\nHlrd6WZSHndcOEfhLZIsaoEXuY8+Cjuovf566uPak1IkudQCL1Jr18LNN4fVWFOF9/33a09KkaRT\nC7wIvfEGXHhhaH2nopuUIsVBLfAismwZnH8+HHVU6vB+993Q6lZ4ixQH/VMuAu5hw5qrrgp92jXt\ntBPMnx/W8haR4qEAT7h58+Dii+HVV1Mfr6iAjh3zW5OI5Ie6UBJq3Tq49VbYZ5/U4X3ttaFlrvAW\nKV5qgSfQW2+Fm5QzZ6Y+vnYttGiR35pEJP8y2ROzlZm9a2bvm9kMM7s5en1nM5toZvPM7GkzU2Tk\n2PLlIbgPPxxmz970+D/+EVrdCm+RpiGTLpS1wDHu3hPYDzjezA4GbgfudvfdgOXA+bkrs2lzh2HD\nwpjuodG+R1VVG59TVQUnnpj/2kQkPnUGuAero6ebR19O2Nx4RPR6GTAgJxU2Rf/8Jzz0ELgzfz6c\ncAL87Gdh/HZl5canzp8fAj4rI0zuvx8GDIDy8ix8mIjkWkY3Mc2smZlNA8qBMcDHwAp33xCdshDY\nPs17B5nZJDObVFFRkY2ai9+FF7L+osu4/dfL2HtvmDAhvLx8+XenHHNMCO6uXbN43WuvhRdfhOee\ny+KHikiuZBTg7l7p7vsBXQj7YO6Z6QXcfYi7l7p7aUlJSQPLbFreGTyMA7ZfyvV3dKRVK1i9euPj\nq1fD2LE5uPDdd8N//AecemoOPlxEsq1ewwjdfQUwDjgEaG9m1aNYugCLslxbk7NyJVxyCRx6wd58\nURV2Uvh+q/t//ie0utu2zVEBF18Mf/+7xh6KJESdwwjNrARY7+4rzKw10I9wA3MccBrwFDAQGJXL\nQouZO4wcCVdcETYWdofFizc+p7Iy7AgvIlItk0joDIwzsw+A94Ax7v4icB1wtZnNA7YBhuauzOL1\n6afwox/B6aeH4X81R5dUDw1UeItITXW2wN39A6BXitc/IfSHSwNs2AD33gu//W0YQWIWwrzaL38J\nDz8cX30iUvjUrovBe+/BgQfCNddASQmsWRNa2RAC3V3hLSJ101T6PFq1Cm66Cf70pxDc8F2r2yzc\nsNxqq/jqE5FkUQs8T557Drp3D+F9ySUbz5V5/vnQ963wFpH6UAs8xz7/HC6/HEaNgn33DaNNDjww\nLPO6bBmMHq0blCLSMArwHKmsDK3tm24Kj//4R7jySth883D86afjrU9Ekk9tvxyYMgV69w6B3acP\nzJgRZqlXh3edPv88rBkrIlILBXgWrV4Nv/pV6CJZuDC0sl96CXbeuZ4f1L9/WDN2/vyc1CkixUFd\nKFnywgtw6aWh8XzRRWHae/v2DfywX/86bC3fpUtWaxSR4qIAb6R//StMgR85kn+vHHjooY380DPO\nCF8iIrVQF0oDVVbCAw+ETRb+8Q/47/8Ofd+NDm8RkQypBd4A778ftjabOBH69YMHH4Rdd427KhFp\natQCr4c1a0L39AEHwCefwJNPwv/9n8JbROKhFniGXn45zKBcsCAsNHX77dChQ9xViUhTphZ4HZYs\nCfcTTzwRWrUKg0MefljhLSLxU4CnUVUV9hXec8+wjsnvfw/TpsERR8RdmYhIoABPYfr0MI/mootg\n//3hgw/gN7+Bli2zdIHVq+Hqq8O6siIiDVRngJvZDmY2zsxmmtkMMxscvd7BzMaY2dzo+9a5Lze3\nvvkG/vM/oVcv+OgjKCsLmwfvsUeWLzRhQthA+I47svzBItKUZNIC3wD8yt27AwcDl5pZd+B6YKy7\n7w6MjZ4n1pgxsM8+YQblL34Bs2fD2WeHdbqz7thj4amnQoiLiDRQnQHu7ovdfUr0+CtgFrA90B8o\ni04rAwbkqshcKi+Hn/8cjjsOmjeH116Dxx7L8cbszZrBT38K222Xw4uISLGrVx+4mXUl7I85Eejk\n7tV7py8BOqV5zyAzm2RmkyoqKhpRanZVVcHQoeEm5YgR8LvfhQk6Rx8dd2UiIpnJOMDNbAtgJHCl\nu6/6/jF3d8BTvc/dh7h7qbuXllTvIxazWbPgqKPCeO4ePUJw/9d/hWGCIiJJkVGAm9nmhPB+0t2f\niV5eamado+OdgfJ07y8U334bNg3u2TOMNBk6FMaNC61wEZGkyWQUigFDgVnuftf3Dj0PDIweDwRG\nZb+87HnttbCl2R/+ELqfZ8+G887TdmYiklyZxNdhwFnAMWY2Lfo6EbgN6Gdmc4Fjo+cF54sv4Jxz\noG/f0O89ejT89a+w7bZxVyYi0jh1roXi7m8B6QbT9c1uOdnjHsZxX3MNrFwJN94Yvlq3jrsyEZHs\nSEYHwqBBYWrkhg0ZnT5nTmhxn3sudOsWpsDfcovCW0SKSzIC/J13wuLba9fWetratWHNkh49wuYK\nDz0Eb74ZdsoRESk2yVhOtjq827ZNe8r48WGThdmzw+qBd98NP/hBHmsUEcmzZLTAW7dOu0Pwl1+G\n8dxHHhky/uWXYdgwhbeIFL9kBHgK7vDEE2EM9+OPh51ypk+H44+PuzIRkfxIRhdKDfPmwcUXw6uv\nQu/e4fu++8ZdlYhIfiWqBb5uXdj9vUcPePfdsCv8hAkKbxFpmhLTAp8wIdyknDEDTj8d7rlHi/mJ\nSNOWiBb4tddCnz7w1VfwwgswfLjCW0QkEQG+yy5hB7IZM+Dkk+OuRkSkMCSiC+Xii+OuQESk8CSi\nBS4iIptSgIuIJJQCXEQkoRTgIiIJlcmOPI+aWbmZTf/eax3MbIyZzY2+b53bMkVEpKZMWuCPAzVX\nGLkeGOvuuwNjo+ciIpJHdQa4u48Hvqzxcn+gLHpcBgzIcl0iIlKHhvaBd3L3xdHjJUCndCea2SAz\nm2RmkyoqKhp4ORERqanRE3nc3c3Mazk+BBgCYGYVZvZphh/dEfiisfXlQCHWVYg1geqqj0KsCQqz\nrkKsCXJb106pXmxogC81s87uvtjMOgPlmbzJ3UsyvYCZTXL30gbWlzOFWFch1gSqqz4KsSYozLoK\nsSaIp66GdqE8DwyMHg8ERmWnHBERyVQmwwiHAf8EupnZQjM7H7gN6Gdmc4Fjo+ciIpJHdXahuPuZ\naQ71zXItNQ3J8ec3VCHWVYg1geqqj0KsCQqzrkKsCWKoy9zT3n8UEZECpqn0IiIJpQAXEUmoggvw\nVGuvxM3MdjCzcWY208xmmNnguGsCMLNWZvaumb0f1XVz3DVVM7NmZjbVzF6Mu5ZqZrbAzD40s2lm\nNinueqqZWXszG2Fms81slpkdEnM93aL/RtVfq8zsyjhrqmZmV0U/69PNbJiZtSqAmgZH9czI93+n\ngusDN7MjgNXAX9x9n7jrAYjGund29ylm1g6YDAxw95kx12VAW3dfbWabA28Bg939nTjrAjCzq4FS\nYEt3L4iN8MxsAVDq7gU1CcTMyoA33f0RM2sBtHH3FXHXBeEXMbAI6O3umU7Cy1Ut2xN+xru7+zdm\nNhx4yd0fj7GmfYCngIOAdcArwEXuPi8f1y+4FniatVdi5e6L3X1K9PgrYBawfbxVhVmw7r46erp5\n9BX7b2Qz6wKcBDwSdy2Fzsy2Ao4AhgK4+7pCCe9IX+DjuMP7e5oDrc2sOdAG+FfM9ewFTHT3r919\nA/AGcGq+Ll5wAV7ozKwr0AuYGG8lQdRVMY0wG3aMuxdCXfcAvwaq4i6kBgdGm9lkMxsUdzGRnYEK\n4LGoy+kRM2sbd1HfcwYwLO4iANx9EXAH8BmwGFjp7qPjrYrpwOFmto2ZtQFOBHbI18UV4PVgZlsA\nI4Er3X1V3PUAuHulu+8HdL1F8NkAAAHSSURBVAEOiv6ki42ZnQyUu/vkOOtIo4+77w+cAFwaddfF\nrTmwP/Cgu/cC1lAgyzNH3TmnAH+PuxaAaN+B/oRfetsBbc3sF3HW5O6zgNuB0YTuk2lAZb6urwDP\nUNTHPBJ40t2fibuemqI/u8ex6drt+XYYcErU3/wUcIyZPRFvSUHUgsPdy4FnCf2WcVsILPzeX04j\nCIFeCE4Aprj70rgLiRwLzHf3CndfDzwDHBpzTbj7UHc/wN2PAJYDc/J1bQV4BqKbhUOBWe5+V9z1\nVDOzEjNrHz1uDfQDZsdZk7vf4O5d3L0r4c/v19w91lYSgJm1jW5AE3VRHEf48zdW7r4E+NzMukUv\n9QVivTn+PWdSIN0nkc+Ag82sTfRvsi/hflSszGzb6PuOhP7vv+Xr2o1eTjbborVXjgI6mtlC4Hfu\nPjTeqjgMOAv4MOpvBvhPd38pxpoAOgNl0UiBzYDh7l4ww/YKTCfg2fDvnubA39z9lXhL+rfLgSej\nLotPgHNjrqf6l1w/4MK4a6nm7hPNbAQwBdgATKUwptWPNLNtgPXApfm8CV1wwwhFRCQz6kIREUko\nBbiISEIpwEVEEkoBLiKSUApwEZGEUoCLiCSUAlxEJKH+H5um1Fc7Lp56AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Cb6LzTfUTq",
        "colab_type": "code",
        "outputId": "61c6435d-26f5-4fa8-92ce-1a5e5fe9d876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "# Visualising the Training set results\n",
        "plt.scatter(X_train, y_train, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train,z_train), color='blue')\n",
        "plt.title('Hours vs Scores (Training set)')\n",
        "plt.xlabel('Hours')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.plot(regressor.cost_trend, color='blue')\n",
        "plt.title('Cost Flow')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.scatter(X_test, y_test, z_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train, z_train), color='blue')\n",
        "plt.title('Hours vs Scores (Test set)')\n",
        "plt.xlabel('Hours')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxUxbn/8c9XFkFEEUWCoqJxX+KG\nW8RdjEsUYzRqjOKSEJe4RhOTmOSamETvdTf+ckUxkmhc4h5jvCLuJqKAuAGCEVQQYURAQWUZnt8f\ndSaO0M3MwJzunu7v+/Xq13SfOsvTA/N0dVWdKkUEZmZWO1YqdwBmZlZaTvxmZjXGid/MrMY48ZuZ\n1RgnfjOzGuPEb2ZWY5z4zUpE0paSRkpSDuduJ2mupPVbc99ykdRZ0huS1ix3LNXIib9KSZosaf8l\ntp0o6dlyxdSaJHWUdIWkKVkSmyzp6nLH1YRfA5dHRGQxNzwWS/q00evjWnriiKiPiFUj4p3W3LdU\nJD0r6cSG1xHxKTAU+FHZgqpiTvy2wiS1L8NlfwL0BXYGugJ7A6Nb8wKt+b4k9QL2Ae4HyBLvqhGx\nKvAOcGijbbflGUsbchtwkqQO5Q6k2jjx1zBJW0h6UtJsSa9LOqxR2ZOSvtvo9Re+LUgKSWdImghM\nVHKVpBmSPpL0qqStC1zzaEkjl9h2rqQHs+cHSxor6WNJUyWdXyT8nYD7IuK9SCZHxJ8anXM9SfdK\nqpM0U9Lvs+0rSbpI0ttZrH+StHpW1id7X6dIegd4PNu+q6R/Zr+nlyXtvcTv5a0s3knLqK33B0ZH\nxGdFypf8PV0i6U5Jt0v6GPiOpN0kPZ/FMU3StQ1JUVL7LPY+2etbs/J/ZLH9S9KGLd03Kz9I0gRJ\ncyRdJ+m5xrXzJeLeVdLo7P/AdEn/06hs90bxj5G0Z7b9MmA34H+zbzxXA0TE28A80oe7taaI8KMK\nH8BkYP8ltp0IPJs97wC8CfwU6AjsC3wMbJaVPwl8t9Cx2esAhgHdgc7A14BRQDdAwBZArwJxrZJd\nZ5NG214EjsmeTwP2yJ6vAexQ5P1dRKopnw5sA6hRWTvgZeAqoAvQCeiXlZ2cve+NgFWBe4E/Z2V9\nsvf1p+y4zsC6wEzgYFJFqX/2uke2z0eNfme9gK2KxPs/wPUt+Le6BFgAHJpdtzPpw24XoH0W/wTg\nB9n+7bPY+2SvbwU+IH0r6gDcCdy6HPuunf17DcjKzgMWAicWeS8vAsdmz7sCu2TP18t+b1/L3s+B\n2TXXzMqfLXRO4GHg9HL/PVXbwzX+6nZ/VruaLWk28P8ale1KSnyXRsSCiHgceAg4tgXn/11EfBip\nPXYh6Q99c1ISHhcR05Y8ICI+AR5ouI6kTbJjHsx2WQhsKWm1iJgVEcWab34HXAYcB4wEpkoamJXt\nDKwDXBAR8yLis4ho+LZyHHBlRLwVEXNJTUbHLNGU8l/ZcZ8C3wEejoiHI2JxRAzLrndwtu9iYGtJ\nnSNiWkS8XiTebqQE2hLPRsTfsut+GhEvRsSIiFgUEW8Bg4G9lnH83RExMiIWkppNtluOfb8OjImI\nB7Kyq0gJu5iFwCaS1oyIjyNiRLb9BODBiPi/7P08QvpwPrCJ38HHpN+dtSIn/up2eER0a3iQascN\n1gHejYjFjba9TarhNte7DU+yD47fA9cDMyQNlrRakeP+wucfMN8G7s8+EAC+SUqqb0t6StJuhU4Q\nqYPy+ojYnZQYfgPcLGkLUu3y7YhYVODQdbL32eBtUg24Z6H3BWwAHLXEB2g/0reZecDRwKnANEl/\nl7R5kfc8i/TB2BKN40DS5tk13pf0EfArYK1lHP9+o+efkD7oW7rvOnzx3zmAKcs4z0nAlsAbkl6Q\n1PABuQFw7BK/x12z8y9LV2B2E/tYCznx1673gPUkNf4/sD4wNXs+j9Qs0+BLBc7xhaldI+LaiNiR\n9Ie/KXBBkWsPA3pI2o70AfCXRud4MSIGkJoY7gfuauqNZLXh60nJdUtSolpfhTtE3yMloQbrA4uA\n6UXe17ukpqBujR5dIuLS7Nr/FxH9Sc0844Ebi4T5Cul30hJLTp17A/AasHFErAb8gtSslqdpQO+G\nF5LEMioHEfFGRBxD+ve7ArhHUifS7/GPBX6PDX0AxaYJ3oL0zcBakRN/7RpBqtn9SFKHrMPyUOCO\nrHwMcISkVSRtDJyyrJNJ2knSLlln4zzgM1IzyFKyJoO/ktq9u5M+CBqGaB4nafVsn4+KnUPSOZL2\nVhrv3T5r5ukKvAS8QEpYl0rqIqmTpN2zQ28HzpW0oaRVgd8Cdxb5dgCp/ftQSV9TGv/eKbtub0k9\nJQ2Q1AWYD8wtFm/2HnfIkuDy6grMAeZl32y+vwLnaq6HSHEfmn2Qnk3q3yhI0vGS1sq+Sc4hJfTF\nwJ+Bb0jq3+j3uI+khhr/dFK/ReNzrU/65vFi67+t2ubEX6MioqHj8CBSm+3/A06IiPHZLleROhen\nk8ZTLzXEcAmrkWq7s0jNJzNJib2YvwD7A39dIukeD0zOmjJOJbXJF/IJqUb5fhb/GcA3s7b7+uy9\nbUzqAJ5CapIBuJmUhJ4GJpE+oM4sFmREvEvq2PwpUEequV5A+ttZidTZ+R7wIam9/bQi55lOGiU0\noNi1muGHwEBSu/cNpE7YXGVxHw1cSfo3/TLpw3V+kUMOBsZlI5EuB47O+pAmA98Afk76Pb5Dej8N\nOehqPm8KujLbdhzpW8KCVn9jNU6pyc7M8iZpS9KH6M7RRv/wJLUjfdAdGRHP5HidzqRvnbtHxLI6\nk205OPGb2TJJOhB4HviUNArqu8CXI6JYrd8qnJt6zKwp/YC3SE00XwO+4aTftrnGb2ZWY1zjNzOr\nMW1i4qe11lor+vTpU+4wzMzalFGjRn0QEUsNv20Tib9Pnz6MHDmy6R3NzOw/JL1daLubeszMaowT\nv5lZjXHiNzOrMU78ZmY1xonfzKzGOPGbmdUYJ34zs1J58kkYPhzKPGOCE7+ZWSkMGQKHHAKHHQbX\nX1/WUNrEDVxmZm3e6NHw2Weptj9qVFlDceI3MyuFCy6A556D+nr42c/KGooTv5lZKfTpA2PGlDsK\nwG38ZmY1x4nfzKzGOPGbmdUYJ34zswo0fjy88EI+53bnrplZBYmAAQPgb39LrxcvBql1r+HEb2ZW\nIV59Fb7ylc9f339/6yd9yLmpR9LZkl6T9Lqkc7Jt3SUNkzQx+7lGnjGYmVW6CDjiiM+Tfo8eMH9+\nqvnnIbfEL2lr4HvAzsC2wNclbQxcCAyPiE2A4dlrM7Oa9NprsNJKcN996fU998CMGdCxY37XzLPG\nvwUwIiI+iYhFwFPAEcAAYGi2z1Dg8BxjMDOrSBFw1FGwzTbpdffuaUaHI47I/9p5Jv7XgD0krSlp\nFeBgYD2gZ0RMy/Z5H+hZ6GBJgySNlDSyrq4uxzDNzErr9ddTLf/uu9Pru+6CmTNh5ZVLc/3cOncj\nYpyky4BHgXnAGKB+iX1CUsH5SSNiMDAYoG/fvuWdw9TMbAVNmwZbbQWzZn2+bbXVYPp06NSptLHk\n2rkbEUMiYseI2BOYBUwApkvqBZD9nJFnDGZm5XbmmbDOOl9M+rffDnPmlD7pQ87DOSWtHREzJK1P\nat/fFdgQGAhcmv18IM8YzMzKZdw42HLLL27r0iV13q6yShMHT5oEb7wB++7b6j29ed+5e4+kscDf\ngDMiYjYp4feXNBHYP3ttZlY1IuCgg5ZO+rfeCnPnNiPp//vfqdf3yCNTD3Ary7XGHxF7FNg2E9gv\nz+uamZXL00/DXnt9cVvHjvDhh6m23yzjxqWf8+bBiBGtGh94rh4zs1axcCFsssnSSX/o0HQzVrOT\nPkD//tCvH6y1Flx9davGCZ6ywcxshd11Fxx99Be3tWuXOnO7dl2OE668MjzySKvEVohr/GZmy+nj\nj9NcOksm/SFDYNGi5Uz6JeDEb2a2HK68Mo3DX9Ls2XDyyaWPpyXc1GNm1gLTpqUx+Uu64QYYNKj0\n8SwP1/jNrO15803YbDPYfvt062uJNNyItaSZM9tO0gcnfjNri26+GSZOTMMeGya8ydHYsakt//e/\n/+L2669PY/a7d889hFblxG9mbc/BB6eRLx06wD775HaZiHSprbZauqyuDk4/PbdL58pt/GbW9vTr\nBx98kMZM5jTZTaEbsRrceGMaYt9WOfGbWdvUojuimm/BAth669SSVMiUKbDuurlcumTc1GNmlrnr\nrtSCVCjpN7Tnt/WkD67xm5nx0UfQrVtK7IV8+ml5pk/Oi2v8ZlbTrrwSVl+9cNJ/4om0vZqSPrjG\nb2Y1qtiNWJD6jp9+Og3hrEau8ZtZTYmAs84qnvQn/7ueZ4a+hRbXF96hCjjxm1nNGDs2LXJ+3XVL\nl11ySfpQ2OCkfWGLLeCQQ0ofYInkvfTiucB3gQBeBU4CegF3AGsCo4DjI2JBnnGYWW1bvBgOPRQe\nfrhw+dy52ejQCHj22XTAk0+WMsSSyq3GL2ld4Cygb0RsDbQDjgEuA66KiI1JC7CfklcMZmZPP53u\n8yqU9B95JOX6/9wSIKXe3o02gmuuKWmcpZR3U097oLOk9sAqwDRgX6Bhco2hwOE5x2BmNWj+/DSP\nW6G7bzfeOFXqv/a1AgeefXZa8/b73889xnLJLfFHxFTgcuAdUsKfQ2ramR0Ri7LdpgAFb4eQNEjS\nSEkj6+rq8grTzKrQnXemIZgTJixdNnFielTriJ3myLOpZw1gALAhsA7QBTiwucdHxOCI6BsRfXv0\n6JFTlGZWTebMSc06xxyzdNkPfpCadTbeuPRxVZo8m3r2ByZFRF1ELATuBXYHumVNPwC9gak5xmBm\nNeKKK9Ldt4sXL102Z07hkTy1Ks/E/w6wq6RVJAnYDxgLPAEcme0zEHggxxjMrMpNnZqabc4/f+my\noUNTLb/QEom1LM82/hGkTtzRpKGcKwGDgR8D50l6kzSkc0heMZhZ9YpIK2L17l24vL4eTjihtDG1\nFbmO44+IXwK/XGLzW8DOeV7XzKrb66+nqZML+ec/YbfdShtPW+O5esyszaivhx12gFdeWbps221h\nzJjSx9QWOfGbWZvw1FOw996FyyZPhg02KGU0bZvn6jGzivbZZ6nztlDS/973svl1nPRbxInfzCrW\nzTdD586Fyz78EAYPLm081cKJ38wqzuzZqZZ/SoGZvK64ItXy11ij9HGxaFEK4Kqr0vM2ym38ZlZR\nTj0VbrihcNlHH0HXrqWN5wtuugkuuih9Kq26ampraoOc+M2sIrzzTvG2+rvugqOOKm08BXXpkib0\nb3jeRjnxm1lZRUCfPinxL6lbN3j33VS5rgjf+U7qdJDgiCPKHc1yc+I3s7J55hnYc8/CZY89Bvvt\nV9p4miTBkUc2vV+Fc+I3s5JbuBA6dixc9tWvwqOPtumWlIrnUT1mVlLXXls86T/9NDz3nJN+3lzj\nN7OSmDMntdkXcuyxacDMKquUNqZa5Rq/meXukEOKJ/3nnoO//MVJv5Sc+M0sN+PGpf7QQgud/+AH\n8MknqU3fSstNPWbW6iI+H+5eiKdOLq8819zdTNKYRo+PJJ0jqbukYZImZj/LceO1meXkjjuKJ/0L\nLki1fCf98sqtxh8RbwDbAUhqR1pb9z7gQmB4RFwq6cLs9Y/zisPMSmPevOI3WnXtCsOGwS67lDYm\nK6xUbfz7Af+OiLeBAcDQbPtQ4PASxWBmORk0qHjS/8lPYMYMJ/1KUqo2/mOA27PnPSNiWvb8faBn\noQMkDQIGAay//vq5B2hmLTdhAmy2WeGyjTZKzT477VTamKxpudf4JXUEDgP+umRZRAQQhY6LiMER\n0Tci+vbo0SPnKM2sJerroXv34kn/Zz+DsWOd9CtVKZp6DgJGR8T07PV0Sb0Asp8zShCDmbWSe++F\n9u1h1qyly7beGkaOhEsugZVXLn1s1jylSPzH8nkzD8CDwMDs+UDggRLEYGYraM6cNCb/m98sXP6L\nX8CoUbDjjqWNy1ou18QvqQvQH7i30eZLgf6SJgL7Z6/NrEJFwFlnFb/zdtttYfRouPji4nPwWGXJ\ntXM3IuYBay6xbSZplI+ZVbixY2GrrYqXX3wxXHihE35b4ykbzKrBrFlp8vof/KBVTrdgQRqVUyzp\nb789jBmTmnec9NseJ36zavDMM+lx/fXpTqoVcOedqWN20qSly9q1g1//GkaMSE081jZ5rh6zavC1\nr8GZZ6bxlcs5mf2MGdCz4F01yQ47wC23wDbbLF+IVjlc4zerBiuvDFdckW6hbaHFi+GMM4on/Y4d\n4Te/geefd9KvFq7xm9WwkSOXfZPVTjvBH/+47A5ea3tc4zerQfPmpc7bYkm/Y0e49NI0fbKTfvVx\n4jerMUOGpAnVCnXeQppM7aWX4Mc/TnfoWvXxP6tZjXjnHdhgg+LlK6+cplo499w0eseql2v8ZlVu\n0SI46aRlJ/3ddkvj8s8/30m/FrjGb1bFnngC9t23eHmnTmnEztlnO+HXEid+syo0axZsuSW8/37x\nfXbfHW6+GTbdtHRxWWVwU49ZFYlIw/m7dy+c9FdZBTp3hquvhqeectKvVa7xm1WJ8eNhiy0Kl/Xs\nCdOnpymTb74ZNt64tLFZZXGN36yN++wzOPzwwkm/UydYbTX4+GO49lp48kknfXPiN2vTHnggNd08\nUGA5o223TR8K228Pr7ySpvJZyX/xRv4LsXSTdLek8ZLGSdpNUndJwyRNzH6ukWcMZtXo/fdTbf7w\nw5cu22036NoV3nwzTdb5+OPw5S+XPkarXHl//l8DPBIRmwPbAuOAC4HhEbEJMDx7bWbNUF8PF10E\nvXrB/PlLl++xB/zrX9C3L7z6Kpx+umv5trTc/ktIWh3YExgCEBELImI2MAAYmu02FChQZzGrUqed\nlnpa//GPFh86alSaQuE3v1m67OtfTyN2XnoJ/vAHeOwx2HDDVojXqlKedYENgTrgj5JeknRTtgZv\nz4iYlu3zPlBwMlhJgySNlDSyrq4uxzDNSqS+Hv73f9PE99dc0+zDPv4Y9tor1eKXtOqqKcE/9BAc\neCC89hqceqpr+bZszfrvIekoSV2z5xdJulfSDk0c1h7YAfhDRGwPzGOJZp2ICCAKHRwRgyOib0T0\n7dGjR3PCNKts7dqltQo33zy11zQhAoYOTaNynn566fJttoG5c1Nb/7BhcM89y56WwaxBc+sFP4+I\njyX1A/YnNd/8oYljpgBTImJE9vpu0gfBdEm9ALKfM1oetlkbdfHFMG4c9Ou3zN0mT0619hNPXLqs\nc+fU5PP223DVVfDyy7D//rlEa1WquYm/Pvt5CDA4Iv4OLHOJ5Yh4H3hX0mbZpv2AscCDwMBs20Cg\nwEA0s9q0cGFaL71Y+3y3bvDpp3D88TBhApxzDnToUNoYre1r7p27UyXdAPQHLpO0Ms370DgTuE1S\nR+At4KTsuLsknQK8DXyr5WGbVZ8nn4R99ln2PptuCtddBzvvXJKQrEo1N/F/CzgQuDwiZmdNNBc0\ndVBEjAEKdEmxX/NDNKtuH3yQOm/Hji2+z9prpxWxBg50x62tuGb9F4qIT0ht8Q0Nk4uAiXkFZVYL\nItI0Cj16FE/67dunhVEmTEhz6jvpW2toVo1f0i9JNffNgD8CHYBbgd3zC82seo0d2/Ratvvvn0Z9\nbrllaWKy2tHc+sM3gMNIQzKJiPeArnkFZVatPvkEvv3tZSf9Pn3g3nvh0Ued9C0fzW3jXxARISkA\nshuxzKwF7r4bjjqqeHmnTvCTn8AFF6Qhm2Z5aW7ivysb1dNN0veAk4Eb8wvLrHpMnQq9ey97n29+\nMy2g4huwrBSa27l7OekGrHtI7fy/iIjr8gzMrK1btAh++MNlJ/0tt0zz6tx9t5O+lU6TNX5J7YDH\nImIfYFj+IZm1fS+8ALvsUrx89dXTTbynn+4bsKz0mqzxR0Q9sDibbdOsOs2dC7Nnr/Bp5sxJC6As\nK+mfckoannn22U76Vh7NbeOfC7wqaRjZyB6AiDgrl6jMSumjj1I7y8KFaR6d9dZr8Ski4NZb4YQT\niu+zyy7prtuddlqBWM1aQXMT/73Zw6z6LFiQVjWJSGsVttCbb8ImmxQvX3NNuPzy9KHgG7CsEjQr\n8UfE0Gy+nU2zTW9ExML8wjIrobXWShPZL1iw7Ay+hPnz4cIL4eqri+9z3nlpJubV3VBqFaS5d+7u\nTVotazIgYD1JAyOiwCzhZm3QRhu1aPfHH4f9ljHjVP/+6a7bLbZYwbjMctDcpp4rgAMi4g0ASZsC\ntwM75hWYWSWqq0srXY0eXbh8pZXSgigDBoBU2tjMmqu5LY4dGpI+QERMIM3XY1YTIuCGG9IsmcWS\n/q9+lQYHHX64k75VtubW+EdKuok0MRvAccDIfEIyqyxvvJFWSyzmoIPSAue+AcvaiubW+E8jrZ51\nVvYYm20zq1rz58NZZy076Q8fDg8/7KRvbUtza/ztgWsi4kr4z928Kzd1kKTJwMekpRsXRURfSd2B\nO4E+pM7ib0XErBZHbpajplbDuvJKOPPMNF++WVvT3Br/cKDxfIGdgceaeew+EbFdRDSsxHUhMDwi\nNsnOe2Ezz2OWu5kz07KGxZL+NtvAjBlpcRQnfWurmpv4O0XE3IYX2fNVlvOaA0hDQ8l+Hr6c5zFr\nNRFw001pSP+LLxbe58UX4ZVX0opZZm1ZcxP/PEk7NLyQ1Bf4tBnHBfCopFGSBmXbekbEtOz5+0DP\nQgdKGiRppKSRdXV1zQzTrOUmTkzDML/3vcLlF18M9fXQt9Dq0WZtUHO/rJ4D/FXSe9nrXsDRzTiu\nX0RMlbQ2MEzS+MaFjRd3WVJEDAYGA/Tt27fgPmYrYsGCtOjJtdcW32fOHFhttdLFZFYKy6zxS9pJ\n0pci4kVgc1Kn7ELgEWBSUyePiKnZzxnAfcDOwHRJvbLz9yIt4m5WUs88AyuvXDzp//OfqfnHSd+q\nUVNNPTcAC7LnuwE/Ba4HZpHVxouR1EVS14bnwAHAa8CDwMBst4HAA8sVudlymDUrNdnsuWfh8m99\nCxYvht12K21cZqXUVFNPu4j4MHt+NDA4Iu4B7pE0poljewL3Kd3C2B74S0Q8IulF0lKOpwBvA99a\n/vDNmicCbrkFTj65+D4ffghrrFGykMzKpsnEL6l9RCwC9gMGNSpb5rER8RawbYHtM7NzmZXEW2/B\nl79cvPy++9I0C8324YepR3jnnT03g7VJTTX13A48JekB0iieZwAkbQzMyTk2sxWycGFa5apY0l9n\nnTRap0VJf/HiNJh/n33g5z9vlTjNSq2pWvtvJA0njeJ5NCIaRtesBJyZd3Bmy+uf/4Tddy9ePnVq\nSvwtVl+fOgrq69NJzNqgJodzRsTzBbZNyCccsxUze3aqjI8p0gP13/+dhnAutw4d4Nln0+PEE1fg\nRGbl45vOrSpEwJ//DAMHFt/ns8/SEM4VtsMO6WHWRjnxW5s3eTJsuGHx8lGjnKfNGvPSz9ZmLVqU\npk0ulvSPPDL1xTrpm32Ra/zWJo0YAbvuWry8ri5NuGZmS3ON39qUjz5KoymLJf2hQ1N7v5O+WXGu\n8VubEAG33gonnFC4fJVV0oieDl4J2qxJTvxW8d59F9Zfv3j5Sy/BdtuVLh6zts5NPVax6uvT8obF\nkv6JJ6bOWyd9s5Zxjd8q0osvpqlwivngA1hzzdLFY1ZNXOO3po0aBT17wqmn5n6puXNhs82KJ/0/\n/Sm19zvpmy0/J35r2rPPplXI778/18vcdht07QoTCkwIsvrqadK144/PNQSzmuCmHmvaoEFp+uF+\n/XI5/dSp0Lt38fIxY2DbpSb4bsKCBTB4MGy//bJnazOrQbnX+CW1k/SSpIey1xtKGiHpTUl3SuqY\ndwy2gjp3TrfItvItsPX1cPrpxZP+wIGpWafFSR/g9tvh3HPhgANWKEazalSKGv/ZwDigYfXSy4Cr\nIuIOSf8LnAL8oQRxWAUZPRp23LF4+cyZ0L37Clxgl11Sv8Ree63AScyqU641fkm9gUOAm7LXAvYF\n7s52GQq0ZBkMa+PmzUtz6xRL+g133q5Q0gfYfHOYMiV1HJjZF+Rd478a+BHQNXu9JjA7W8oRYAqw\nbqEDJQ0iW+px/WXdvWNtxq23Fu+c7dIF5syBdu1KG5NZLcqtxi/p68CMiBi1PMdHxOCI6BsRfXv0\n6NHK0VkpTZuW+oaLJf0xY9IwTid9s9LIs6lnd+AwSZOBO0hNPNcA3SQ1fNPoDXj9uiq1eHEaEFRs\nicMTTliBzlszW265NfVExE+AnwBI2hs4PyKOk/RX4EjSh8FA4IG8YrDyeemlZQ8CWuHOWzNbbuW4\ngevHwHmS3iS1+Q8pQwyWk08+gS99qXjSv+WWVuq8NbPlVpIbuCLiSeDJ7PlbwDJmYbG26k9/Kr7m\n7UorpXuq3I5vVn6+c9dW2PTpqZZfzHLdeWtmufFcPbbcFi9OUyMXS/rHHuvOW7NK5Bq/LRd33pq1\nXa7xW4t89hmssUbxpH/zze68Nat0rvFbs91yC5x0UvHyhQuhvf9HmVU8/5lak+rqYO21i5d7zVuz\ntsVNPVZURKrlF7vz9oAD0j5O+mZti2v8VtAbb6SVFp98snC517w1a7tc47cvmD8fLr44zWpcKOlf\nd53XvDVr61zjt/946in4/vdTbb8Qd96aVQfX+I2ZM+GUU2DvvQsn/RdeSLV8J32z6uA/5RoWkRao\nOvfc1Ga/pA02gEmT0lz6ZlY9nPhr1JtvwmmnwWOPFS6vq4O11iptTGZWGm7qqTELFsBvfgNbb104\n6V9wQfom4KRvVr1c468hzz6bOm/Hji1cPn8+dOxY2pjMrPTyXHO3k6QXJL0s6XVJF2fbN5Q0QtKb\nku6U5FSTs1mzUsLfYw8YP37p8r//PdXynfTNakOeTT3zgX0jYltgO+BASbsClwFXRcTGwCzglBxj\nqGkRcPvtaUz+kGyds8WLv7jP4sVw8MGlj83Myie3xB/J3Oxlh+wRpEXX7862DwUOzyuGmvOvf8EN\nN0AEkybBQQfBt7+dxt/X139x10mT0gdDq4zYue46OPxwmDGjFU5mZnnLtXNXUjtJY4AZwDDg38Ds\niFiU7TIFWLfIsYMkjZQ0siJ3qcYAAAyFSURBVK6uLs8wq8f3v8/CU3/AZT+ayVZbwXPPpc2zZn2+\ny777poTfp08rXveCC+Chh+D++1vxpGaWl1wTf0TUR8R2QG/SOrubt+DYwRHRNyL69ujRI7cYq8nz\nZ9/OjutO58LL16JTJ5g794vlc+fC8OE5XPiqq+Ab34Ajjsjh5GbW2koynDMiZgNPALsB3SQ1jCbq\nDUwtRQzVbM4cOP10+Or3tuKDxWkFlMa1/N/9LtXyu3TJKYDTToO//tVjQM3aiNyGc0rqASyMiNmS\nOgP9SR27TwBHAncAA4EH8oqh2kXAPffAWWelBc8jYNq0L+5TXw8r+W4NM2skz5TQC3hC0ivAi8Cw\niHgI+DFwnqQ3gTWBITnGULXefhsOPRSOOioNw1xytE7DEE0nfTNbUm41/oh4Bdi+wPa3SO39thwW\nLYJrroFf/CKNyJHSh0CD734XbryxfPGZWeVzfbANefFF2GknOP986NED5s1LtXpIHwQRTvpm1jRP\n2dAGfPQRXHQR/P73KeHD57V8KXXkrr56+eIzs7bFNf4Kd//9sOWWKemffvoX75F68MHUtu+kb2Yt\n4Rp/hXr3XTjzTHjgAfjKV9LonZ12StMlz5wJjz7qjlszWz5O/BWmvj7V7i+6KD3/7/+Gc86BDh1S\n+Z13ljc+M2v7XGesIKNHwy67pETfrx+8/nqaDaEh6Tfp3XfT3MtmZsvgxF8B5s6FH/4wNeVMmZJq\n9Q8/DBtu2MITDRiQ5l6eNCmXOM2sOripp8z+9jc444xUWT/11DS9Qrduy3myH/0InnoKevdu1RjN\nrLo48ZfJe++lqRbuuYf/zKT51a+u4EmPOSY9zMyWwU09JVZfD9dfnxZH+fvf4be/TW37K5z0zcya\nyTX+Enr55bQE4ogR0L8//OEP8OUvlzsqM6s1rvGXwLx5qfl9xx3hrbfgttvg//7PSd/MysM1/pz9\n4x/pjtvJk9MEapddBt27lzsqM6tlrvHn5P33Uz/rwQdDp05psM2NNzrpm1n5OfG3ssWL03rnm2+e\n5tn51a9gzBjYc89yR2Zmljjxt6LXXkv3T516KuywA7zyCvz857Dyyq10gblz4bzz0vzMZmbLKbfE\nL2k9SU9IGivpdUlnZ9u7SxomaWL2c428YiiVTz+Fn/4Utt8e3ngDhg5Ni5pvumkrX+i559LC5pdf\n3sonNrNakmeNfxHww4jYEtgVOEPSlsCFwPCI2AQYnr1us4YNg623Tnfcfuc7MH48nHBCmie/1e2/\nP9xxR0r+ZmbLKbfEHxHTImJ09vxjYBywLjAAGJrtNhQ4PK8Y8jRjBhx3HBxwALRvD48/Dn/8I6y1\nVo4XbdcOjj4a1lknx4uYWbUrSRu/pD6k9XdHAD0jYlpW9D7Qs8gxgySNlDSyrq6uFGE2y+LFMGRI\n6ry9+2745S/TjVn77FPuyMzMmif3xC9pVeAe4JyI+KhxWUQEEIWOi4jBEdE3Ivr2aFhvsMzGjYO9\n907j8bfZJiX8//qvNFzTzKytyDXxS+pASvq3RcS92ebpknpl5b2AGcWOrxSffZYWM9922zRyZ8gQ\neOKJVOs3M2tr8hzVI2AIMC4irmxU9CAwMHs+EHggrxhaw+OPp6UPf/3r1Lw+fjycfLKXPTSztivP\n9LU7cDywr6Qx2eNg4FKgv6SJwP7Z64rzwQdw4omw336pXf/RR+HPf4a11y53ZGZmKya3uXoi4lmg\n2KDG/fK67oqKSOPwzz8f5syBn/0sPTp3LndkZmato7obLAYNSrfSLlrUrN0nTEg1/JNOgs02S1Mt\nXHKJk76ZVZfqTvzPP58mv58/f5m7zZ+f5tTZZpu0KMoNN8Azz6SVsczMqk11T8vckPS7dCm6y9NP\np8VRxo9Ps2ledRV86UsljNHMrMSqu8bfuXPRlcs//DCNx99rr/TZ8I9/wO23O+mbWfWr7sRfQATc\nemsag3/LLWllrNdegwMPLHdkZmalUd1NPUt480047TR47DHYZZf08ytfKXdUZmalVRM1/gUL4Le/\nTZ23L7wA11+fZjh20jezWlT1Nf7nnkudt6+/DkcdBVdf7cktzay2VXWN/4ILoF8/+Phj+Nvf4K67\nnPTNzKo68W+0UVqp8PXX4etfL3c0ZmaVoaqbek47rdwRmJlVnqqu8ZuZ2dKc+M3MaowTv5lZjXHi\nNzOrMXmuwHWzpBmSXmu0rbukYZImZj/XyOv6ZmZWWJ41/luAJWfAuRAYHhGbAMOz12ZmVkK5Jf6I\neBr4cInNA4Ch2fOhwOF5Xd/MzAordRt/z4iYlj1/H+hZbEdJgySNlDSyrq6uNNGZmdWAst3AFREh\nKZZRPhgYDCCpTtLbzTz1WsAHrRBia6vEuCoxJnBcLVGJMUFlxlWJMUG+cW1QaGOpE/90Sb0iYpqk\nXsCM5hwUET2aewFJIyOi73JHmJNKjKsSYwLH1RKVGBNUZlyVGBOUJ65SN/U8CAzMng8EHijx9c3M\nal6ewzlvB/4FbCZpiqRTgEuB/pImAvtnr83MrIRya+qJiGOLFO2X1zUzg3M+//KqxLgqMSZwXC1R\niTFBZcZViTFBGeJSRNH+VTMzq0KessHMrMY48ZuZ1ZiqSfyF5gYqN0nrSXpC0lhJr0s6u9wxAUjq\nJOkFSS9ncV1c7pgaSGon6SVJD5U7lgaSJkt6VdIYSSPLHU8DSd0k3S1pvKRxknYrczybZb+jhsdH\nks4pZ0wNJJ2b/V9/TdLtkjpVQExnZ/G8XurfU9W08UvaE5gL/Ckiti53PADZvQq9ImK0pK7AKODw\niBhb5rgEdImIuZI6AM8CZ0fE8+WMC0DSeUBfYLWIqIgFMyVNBvpGREXd/CNpKPBMRNwkqSOwSkTM\nLndckD7AganALhHR3Jsv84plXdL/8S0j4lNJdwEPR8QtZYxpa+AOYGdgAfAIcGpEvFmK61dNjb/I\n3EBlFRHTImJ09vxjYBywbnmjSndNR8Tc7GWH7FH2GoCk3sAhwE3ljqXSSVod2BMYAhARCyol6Wf2\nA/5d7qTfSHugs6T2wCrAe2WOZwtgRER8EhGLgKeAI0p18apJ/JVOUh9ge2BEeSNJsiaVMaS7p4dF\nRCXEdTXwI2BxuQNZQgCPSholaVC5g8lsCNQBf8yaxm6S1KXcQTVyDHB7uYMAiIipwOXAO8A0YE5E\nPFreqHgN2EPSmpJWAQ4G1ivVxZ34S0DSqsA9wDkR8VG54wGIiPqI2A7oDeycffUsG0lfB2ZExKhy\nxlFEv4jYATgIOCNrViy39sAOwB8iYntgHhUyzXnW7HQY8NdyxwKQrfsxgPRhuQ7QRdJ3yhlTRIwD\nLgMeJTXzjAHqS3V9J/6cZW3o9wC3RcS95Y5nSVnzwBMsvXZCqe0OHJa1p98B7Cvp1vKGlGQ1RiJi\nBnAfqV223KYAUxp9U7ub9EFQCQ4CRkfE9HIHktkfmBQRdRGxELgX+GqZYyIihkTEjhGxJzALmFCq\nazvx5yjrRB0CjIuIK8sdTwNJPSR1y553BvoD48sZU0T8JCJ6R0QfUjPB4xFR1loZgKQuWcc8WVPK\nAaSv6WUVEe8D70raLNu0H1DWQQONHEuFNPNk3gF2lbRK9je5H6m/rawkrZ39XJ/Uvv+XUl27bNMy\nt7ZsbqC9gbUkTQF+GRFDyhsVuwPHA69m7ekAP42Ih8sYE0AvYGg28mIl4K6IqJjhkxWmJ3Bfyhe0\nB/4SEY+UN6T/OBO4LWtaeQs4qczxNHw49ge+X+5YGkTECEl3A6OBRcBLVMb0DfdIWhNYCJxRys75\nqhnOaWZmzeOmHjOzGuPEb2ZWY5z4zcxqjBO/mVmNceI3M6sxTvxmGUlzl3h9oqTflyses7w48Zvl\nLJsYzKxiOPGbNYOkPpIel/SKpOHZ3ZZIukXSkY32m5v93FvSM5IeBMZmdwD/PVsD4TVJR5fprZhV\nz527Zq2gc6M7rAG6Aw9mz68DhkbEUEknA9cChzdxvh2ArSNikqRvAu9FxCHwn2mVzcrCNX6zz30a\nEds1PIBfNCrbjc/nUvkz0K8Z53shIiZlz18F+ku6TNIeETGn9cI2axknfrMVs4js70jSSkDHRmXz\nGp5ExATSN4BXgUskNf5QMSspJ36z5vknadZQgOOAZ7Lnk4Eds+eHkVYzW4qkdYBPIuJW4H+onCmU\nrQa5jd+sec4krXZ1AWnlq4aZMG8EHpD0MmlBjXlFjt8G+B9Ji0mzMZ6Wc7xmRXl2TjOzGuOmHjOz\nGuPEb2ZWY5z4zcxqjBO/mVmNceI3M6sxTvxmZjXGid/MrMb8f/1I1Q8Ehs10AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrGIc/GZmFePgNzOrmP8PgASqxqLXMr8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIq43yKPfUTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}